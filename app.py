from InquirerPy import inquirer
from InquirerPy.base.control import Choice
import requests
import pandas as pd
import os
from rich import print
from rich.progress import track
import time
import logging

# Configura√ß√£o do logger
logging.basicConfig(filename='app.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class ExcelFilter:
    def __init__(self):
        self.df = None
        self.filepath = None
        self.headers = None
        
    def load_excel(self, filepath):
        """Carrega o arquivo Excel e extrai os cabe√ßalhos"""
        try:
            self.filepath = filepath
            self.df = pd.read_excel(filepath)
            self.headers = list(self.df.columns)
            return True
        except Exception as e:
            print(f"Erro ao carregar arquivo: {e}")
            return False

    def get_unique_values(self, column):
        """Retorna valores √∫nicos de uma coluna espec√≠fica"""
        return self.df[column].unique().tolist()

    def filter_and_save(self, column, value, output_path):
        """Filtra o DataFrame e salva em novo arquivo"""
        filtered_df = self.df[self.df[column] == value]
        output_file = os.path.join(output_path, f'filtered_{os.path.basename(self.filepath)}')
        filtered_df.to_excel(output_file, index=False)
        return output_file

    def filter_and_save_multiple(self, filters, output_path):
        """Filtra o DataFrame com m√∫ltiplos crit√©rios e salva em novo arquivo"""
        print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Filtragem M√∫ltipla ‚ïê‚ïê‚ïó[/bold yellow]\n")
        
        filtered_df = self.df.copy()
        total_inicial = len(filtered_df)
        
        steps = len(filters)
        step_size = 100 // steps
        
        for column, value in filters.items():
            for _ in track(range(step_size), description=f"[cyan]Aplicando filtro para {column}...[/cyan]"):
                time.sleep(0.01)
            filtered_df = filtered_df[filtered_df[column] == value]
        
        output_file = os.path.join(output_path, f'filtered_{os.path.basename(self.filepath)}')
        filtered_df.to_excel(output_file, index=False)
        
        print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
        print(f"[white]‚ñ∫ Registros originais:[/white]    {total_inicial:,}")
        print(f"[white]‚ñ∫ Registros ap√≥s filtros:[/white] {len(filtered_df):,}")
        print(f"[white]‚ñ∫ Registros filtrados:[/white]    {total_inicial - len(filtered_df):,}")
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![/bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[/dim]\n")
        
        return output_file

    def get_unique_values_filtered(self, column, current_filters):
        """Retorna valores √∫nicos de uma coluna com filtros aplicados"""
        filtered_df = self.df.copy()
        for col, val in current_filters.items():
            filtered_df = filtered_df[filtered_df[col] == val]
        return filtered_df[column].unique().tolist()

    def keep_columns(self, columns, output_path):
        """Mant√©m apenas as colunas selecionadas"""
        print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Sele√ß√£o de Colunas ‚ïê‚ïê‚ïó[/bold yellow]\n")
        
        total_colunas = len(self.df.columns)
        
        for _ in track(range(100), description="[cyan]Processando colunas...[/cyan]"):
            time.sleep(0.01)
        
        filtered_df = self.df[columns].copy()
        output_file = os.path.join(output_path, f'kept_columns_{os.path.basename(self.filepath)}')
        filtered_df.to_excel(output_file, index=False)
        
        print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
        print(f"[white]‚ñ∫ Total de colunas original:[/white] {total_colunas:,}")
        print(f"[white]‚ñ∫ Colunas mantidas:[/white]        {len(columns):,}")
        print(f"[white]‚ñ∫ Colunas removidas:[/white]       {total_colunas - len(columns):,}")
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![/bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[/dim]\n")
        
        return output_file

    def remove_columns(self, columns, output_path):
        """Remove as colunas selecionadas"""
        print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Remo√ß√£o de Colunas ‚ïê‚ïê‚ïó[/bold yellow]\n")
        
        total_colunas = len(self.df.columns)
        
        for _ in track(range(100), description="[cyan]Processando colunas...[/cyan]"):
            time.sleep(0.01)
        
        filtered_df = self.df.drop(columns=columns).copy()
        output_file = os.path.join(output_path, f'removed_columns_{os.path.basename(self.filepath)}')
        filtered_df.to_excel(output_file, index=False)
        
        print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
        print(f"[white]‚ñ∫ Total de colunas original:[/white] {total_colunas:,}")
        print(f"[white]‚ñ∫ Colunas removidas:[/white]        {len(columns):,}")
        print(f"[white]‚ñ∫ Colunas restantes:[/white]        {len(filtered_df.columns):,}")
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![/bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[/dim]\n")
        
        return output_file

    def filter_numeric_greater_than(self, column, value, output_path):
        """Filtra valores num√©ricos maiores que o valor especificado"""
        filtered_df = self.df[self.df[column] > value]
        output_file = os.path.join(output_path, f'numeric_filtered_{os.path.basename(self.filepath)}')
        filtered_df.to_excel(output_file, index=False)
        return output_file

    def filter_numeric_between(self, column, min_value, max_value, output_path):
        """Filtra valores num√©ricos entre dois valores"""
        filtered_df = self.df[(self.df[column] >= min_value) & (self.df[column] <= max_value)]
        output_file = os.path.join(output_path, f'numeric_filtered_{os.path.basename(self.filepath)}')
        filtered_df.to_excel(output_file, index=False)
        return output_file

    def is_numeric_column(self, column):
        """Verifica se uma coluna √© num√©rica"""
        return pd.api.types.is_numeric_dtype(self.df[column])

    @staticmethod
    def unify_excel_files(directory_path, output_path):
        """Unifica arquivos Excel baseado no CPF"""
        all_files = [f for f in os.listdir(directory_path) if f.endswith(('.xlsx', '.xls'))]
        if not all_files:
            print("Nenhum arquivo Excel encontrado no diret√≥rio.")
            return None

        dfs = []
        for file in all_files:
            df = pd.read_excel(os.path.join(directory_path, file))
            if 'CPF' not in df.columns:
                print(f"Arquivo {file} n√£o cont√©m a coluna 'CPF'. Ignorando...")
                continue
            dfs.append(df)

        if not dfs:
            print("Nenhum arquivo v√°lido encontrado.")
            return None

        unified_df = pd.concat(dfs, ignore_index=True)
        unified_df = unified_df.drop_duplicates(subset=['CPF'], keep='first')
        
        output_file = os.path.join(output_path, 'unified_excel.xlsx')
        unified_df.to_excel(output_file, index=False)
        return output_file

    def normalize_cpf(self, cpf):
        """Normaliza o CPF removendo caracteres especiais e espa√ßos"""
        # Converte para string primeiro
        cpf_str = str(cpf)
        return ''.join(filter(str.isdigit, cpf_str))

    def unify_excel_files_with_cpf(self, base_file_path, second_file_path, base_cpf_column, second_cpf_column, output_path):
        """Unifica dois arquivos Excel baseado no CPF"""
        print("\n[bold yellow]‚ïî‚ïêÔøΩÔøΩ Iniciando Unifica√ß√£o por CPF ‚ïê‚ïê‚ïó[/bold yellow]\n")
        
        base_df = pd.read_excel(base_file_path)
        second_df = pd.read_excel(second_file_path)
        total_base = len(base_df)
        total_second = len(second_df)

        # Normaliza os CPFs
        for _ in track(range(33), description="[cyan]Normalizando CPFs do arquivo base...[/cyan]"):
            time.sleep(0.01)
        base_df[base_cpf_column] = base_df[base_cpf_column].apply(self.normalize_cpf)
        
        for _ in track(range(33), description="[cyan]Normalizando CPFs do segundo arquivo...[/cyan]"):
            time.sleep(0.01)
        second_df[second_cpf_column] = second_df[second_cpf_column].apply(self.normalize_cpf)
        
        # Realiza o merge
        for _ in track(range(34), description="[cyan]Unificando arquivos...[/cyan]"):
            time.sleep(0.01)
        merged_df = pd.merge(base_df, second_df, left_on=base_cpf_column, right_on=second_cpf_column, how='inner')
        
        output_file = os.path.join(output_path, 'unified_by_cpf.xlsx')
        merged_df.to_excel(output_file, index=False)
        
        print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
        print(f"[white]‚ñ∫ Registros no arquivo base:[/white]    {total_base:,}")
        print(f"[white]‚ñ∫ Registros no segundo arquivo:[/white] {total_second:,}")
        print(f"[white]‚ñ∫ Registros ap√≥s unifica√ß√£o:[/white]    {len(merged_df):,}")
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![/bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[/dim]\n")
        
        return output_file

    def filter_cpf_removal(self, base_file_path, removal_file_path, base_cpf_column, removal_cpf_column, output_path):
        """Remove do arquivo base os CPFs que existem no arquivo de remo√ß√£o"""
        print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Remo√ß√£o de CPFs ‚ïê‚ïê‚ïó[/bold yellow]\n")
        
        base_df = pd.read_excel(base_file_path)
        removal_df = pd.read_excel(removal_file_path)
        total_base = len(base_df)
        
        # Normaliza os CPFs
        for _ in track(range(33), description="[cyan]Normalizando CPFs do arquivo base...[/cyan]"):
            time.sleep(0.01)
        base_df[base_cpf_column] = base_df[base_cpf_column].apply(self.normalize_cpf)
        
        for _ in track(range(33), description="[cyan]Normalizando CPFs do arquivo de remo√ß√£o...[/cyan]"):
            time.sleep(0.01)
        removal_df[removal_cpf_column] = removal_df[removal_cpf_column].apply(self.normalize_cpf)
        
        # Remove as linhas
        for _ in track(range(34), description="[cyan]Removendo CPFs...[/cyan]"):
            time.sleep(0.01)
        filtered_df = base_df[~base_df[base_cpf_column].isin(removal_df[removal_cpf_column])].copy()
        
        # Formata os CPFs
        filtered_df[base_cpf_column] = filtered_df[base_cpf_column].apply(self.format_cpf)
        
        output_file = os.path.join(output_path, f'cpf_filtered_{os.path.basename(base_file_path)}')
        filtered_df.to_excel(output_file, index=False)
        
        print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
        print(f"[white]‚ñ∫ Registros originais:[/white]    {total_base:,}")
        print(f"[white]‚ñ∫ Registros ap√≥s remo√ß√£o:[/white] {len(filtered_df):,}")
        print(f"[white]‚ñ∫ Registros removidos:[/white]    {total_base - len(filtered_df):,}")
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![/bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[/dim]\n")
        
        return output_file

    

    def filter_cpf_duplicates(self, file_path, cpf_column, output_path):
        """Remove CPFs duplicados mantendo apenas a primeira ocorr√™ncia"""
        print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Remo√ß√£o de Duplicatas ‚ïê‚ïê‚ïó[/bold yellow]\n")
        
        df = pd.read_excel(file_path)
        total = len(df)
        
        # Normaliza os CPFs
        for _ in track(range(50), description="[cyan]Normalizando CPFs...[/cyan]"):
            time.sleep(0.01)
        df[cpf_column] = df[cpf_column].apply(self.normalize_cpf)
        
        # Remove duplicatas
        for _ in track(range(50), description="[cyan]Removendo duplicatas...[/cyan]"):
            time.sleep(0.01)
        filtered_df = df.drop_duplicates(subset=[cpf_column], keep='first').copy()
        
        # Formata os CPFs
        filtered_df[cpf_column] = filtered_df[cpf_column].apply(self.format_cpf)
        
        output_file = os.path.join(output_path, f'unique_cpf_{os.path.basename(file_path)}')
        filtered_df.to_excel(output_file, index=False)
        
        duplicatas = total - len(filtered_df)
        
        print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
        print(f"[white]‚ñ∫ Registros originais:[/white]    {total:,}")
        print(f"[white]‚ñ∫ Registros √∫nicos:[/white]      {len(filtered_df):,}")
        print(f"[white]‚ñ∫ Duplicatas removidas:[/white]  {duplicatas:,}")
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![/bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[/dim]\n")
        
        return output_file

    def format_cpf(self, cpf):
        """Formata o CPF para ter 11 d√≠gitos, adicionando zeros √† esquerda se necess√°rio"""
        # Primeiro normaliza o CPF para ter apenas d√≠gitos
        cpf_clean = self.normalize_cpf(cpf)
        # Adiciona zeros √† esquerda se necess√°rio para ter 11 d√≠gitos
        return cpf_clean.zfill(11)

def filter_single_excel():
    filter_system = ExcelFilter()
    
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Filtro √önico ‚ïê‚ïê‚ïó[/bold yellow]\n")
    
    excel_path = inquirer.text(
        message="Digite o caminho do arquivo Excel:"
    ).execute()
    
    if not filter_system.load_excel(excel_path):
        print("[bold red]‚úó Erro ao carregar arquivo![/bold red]\n")
        return
    
    selected_header = inquirer.select(
        message="Selecione o cabe√ßalho para filtrar:",
        choices=filter_system.headers
    ).execute()
    
    unique_values = filter_system.get_unique_values(selected_header)
    
    selected_value = inquirer.select(
        message=f"Selecione o valor para filtrar em '{selected_header}':",
        choices=unique_values
    ).execute()
    
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo filtrado:"
    ).execute()
    
    total_registros = len(filter_system.df)
    
    for _ in track(range(100), description="[cyan]Aplicando filtro...[/cyan]"):
        time.sleep(0.01)
    
    filtered_df = filter_system.df[filter_system.df[selected_header] == selected_value].copy()
    output_file = filter_system.filter_and_save(selected_header, selected_value, output_dir)
    
    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Registros originais:[/white]    {total_registros:,}")
    print(f"[white]‚ñ∫ Registros filtrados:[/white]    {len(filtered_df):,}")
    print(f"[white]‚ñ∫ Registros removidos:[/white]    {total_registros - len(filtered_df):,}")
    print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![/bold green]")
    print(f"[dim]üìÅ Arquivo salvo em: {output_file}[/dim]\n")

def filter_multiple_excel():
    filter_system = ExcelFilter()
    
    excel_path = inquirer.text(
        message="Digite o caminho do arquivo Excel:"
    ).execute()
    
    if not filter_system.load_excel(excel_path):
        return
    
    filters = {}
    while True:
        # Pergunta se quer adicionar mais um filtro
        should_continue = inquirer.confirm(
            message="Deseja adicionar um filtro?",
            default=True
        ).execute()
        
        if not should_continue:
            break
            
        # Seleciona o cabe√ßalho
        selected_header = inquirer.select(
            message="Selecione o cabe√ßalho para filtrar:",
            choices=filter_system.headers
        ).execute()
        
        # Obt√©m valores √∫nicos considerando filtros anteriores
        unique_values = filter_system.get_unique_values_filtered(selected_header, filters)
        
        if not unique_values:
            print("N√£o h√° valores dispon√≠veis com os filtros atuais.")
            break
            
        # Seleciona o valor
        selected_value = inquirer.select(
            message=f"Selecione o valor para filtrar em '{selected_header}':",
            choices=unique_values
        ).execute()
        
        filters[selected_header] = selected_value
    
    if filters:
        output_dir = inquirer.text(
            message="Digite o caminho para salvar o arquivo filtrado:"
        ).execute()
        
        output_file = filter_system.filter_and_save_multiple(filters, output_dir)
        print(f"\nArquivo filtrado salvo em: {output_file}")

def select_columns():
    """Fun√ß√£o auxiliar para selecionar m√∫ltiplas colunas"""
    filter_system = ExcelFilter()
    
    excel_path = inquirer.text(
        message="Digite o caminho do arquivo Excel:"
    ).execute()
    
    if not filter_system.load_excel(excel_path):
        return None, None
    
    selected_columns = []
    while True:
        should_continue = inquirer.confirm(
            message="Deseja selecionar uma coluna?",
            default=True
        ).execute()
        
        if not should_continue:
            break
        
        remaining_columns = [col for col in filter_system.headers if col not in selected_columns]
        if not remaining_columns:
            print("Todas as colunas j√° foram selecionadas.")
            break
            
        selected_header = inquirer.select(
            message="Selecione a coluna:",
            choices=remaining_columns
        ).execute()
        
        selected_columns.append(selected_header)
        
    return filter_system, selected_columns

def keep_selected_columns():
    filter_system, selected_columns = select_columns()
    
    if not filter_system or not selected_columns:
        return
    
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo:"
    ).execute()
    
    output_file = filter_system.keep_columns(selected_columns, output_dir)
    print(f"\nArquivo salvo com as colunas selecionadas em: {output_file}")

def remove_selected_columns():
    filter_system, selected_columns = select_columns()
    
    if not filter_system or not selected_columns:
        return
    
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo:"
    ).execute()
    
    output_file = filter_system.remove_columns(selected_columns, output_dir)
    print(f"\nArquivo salvo sem as colunas selecionadas em: {output_file}")

def filter_numeric():
    """Fun√ß√£o para filtrar valores num√©ricos"""
    filter_system = ExcelFilter()
    
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Filtro Num√©rico ‚ïê‚ïê‚ïó[/bold yellow]\n")
    
    excel_path = inquirer.text(
        message="Digite o caminho do arquivo Excel:"
    ).execute()
    
    if not filter_system.load_excel(excel_path):
        print("[bold red]‚úó Erro ao carregar arquivo![/bold red]\n")
        return

    # Filtra apenas colunas num√©ricas
    numeric_columns = [col for col in filter_system.headers if filter_system.is_numeric_column(col)]
    if not numeric_columns:
        print("[bold red]‚úó N√£o h√° colunas num√©ricas neste arquivo![/bold red]\n")
        return

    selected_header = inquirer.select(
        message="Selecione a coluna num√©rica para filtrar:",
        choices=numeric_columns
    ).execute()

    filter_type = inquirer.select(
        message="Selecione o tipo de filtro:",
        choices=[
            Choice("1", "Maior que"),
            Choice("2", "Entre valores")
        ]
    ).execute()

    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo filtrado:"
    ).execute()

    total_registros = len(filter_system.df)

    if filter_type == "1":
        value = float(inquirer.text(
            message="Digite o valor m√≠nimo:"
        ).execute())
        
        for _ in track(range(100), description="[cyan]Aplicando filtro...[/cyan]"):
            time.sleep(0.01)
            
        filtered_df = filter_system.df[filter_system.df[selected_header] > value].copy()
        output_file = filter_system.filter_numeric_greater_than(selected_header, value, output_dir)
        
        print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
        print(f"[white]‚ñ∫ Registros originais:[/white]    {total_registros:,}")
        print(f"[white]‚ñ∫ Registros > {value}:[/white]    {len(filtered_df):,}")
        print(f"[white]‚ñ∫ Registros removidos:[/white]    {total_registros - len(filtered_df):,}")
        
    else:
        min_value = float(inquirer.text(
            message="Digite o valor m√≠nimo:"
        ).execute())
        max_value = float(inquirer.text(
            message="Digite o valor m√°ximo:"
        ).execute())
        
        for _ in track(range(100), description="[cyan]Aplicando filtro...[/cyan]"):
            time.sleep(0.01)
            
        filtered_df = filter_system.df[(filter_system.df[selected_header] >= min_value) & 
                                     (filter_system.df[selected_header] <= max_value)].copy()
        output_file = filter_system.filter_numeric_between(selected_header, min_value, max_value, output_dir)
        
        print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
        print(f"[white]‚ñ∫ Registros originais:[/white]    {total_registros:,}")
        print(f"[white]‚ñ∫ Registros entre {min_value} e {max_value}:[/white]    {len(filtered_df):,}")
        print(f"[white]‚ñ∫ Registros removidos:[/white]    {total_registros - len(filtered_df):,}")

    print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![/bold green]")
    print(f"[dim]üìÅ Arquivo salvo em: {output_file}[/dim]\n")

def unify_excel_files():
    """Fun√ß√£o para unificar arquivos Excel"""
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Unifica√ß√£o de Arquivos ‚ïê‚ïê‚ïó[/bold yellow]\n")
    print("[white]‚ñ∫ Requisitos: os arquivos precisam ter colunas com mesmo nome[/white]")
    print("[white]‚ñ∫ Coluna obrigat√≥ria: 'CPF'[/white]\n")
    
    directory_path = inquirer.text(
        message="Digite o caminho da pasta com os arquivos Excel:"
    ).execute()
    
    if not os.path.isdir(directory_path):
        print("[bold red]‚úó Diret√≥rio inv√°lido![/bold red]\n")
        return

    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo unificado:"
    ).execute()

    for _ in track(range(100), description="[cyan]Unificando arquivos...[/cyan]"):
        time.sleep(0.01)

    output_file = ExcelFilter.unify_excel_files(directory_path, output_dir)
    
    if output_file:
        print("\n[bold green]‚úì Processo conclu√≠do com sucesso![/bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[/dim]\n")
    else:
        print("[bold red]‚úó Erro ao unificar arquivos![/bold red]\n")

def unify_excel_files_with_cpf():
    """Fun√ß√£o para unificar arquivos Excel com base no CPF"""
    filter_system = ExcelFilter()

    base_file_path = inquirer.text(
        message="Digite o caminho do arquivo base (.xlsx):"
    ).execute()

    if not filter_system.load_excel(base_file_path):
        return

    # Seleciona a coluna de CPF do arquivo base
    base_cpf_column = inquirer.select(
        message="Selecione a coluna de CPF do arquivo base:",
        choices=filter_system.headers
    ).execute()

    second_file_path = inquirer.text(
        message="Digite o caminho do segundo arquivo (.xlsx):"
    ).execute()

    if not filter_system.load_excel(second_file_path):
        return

    # Seleciona a coluna de CPF do segundo arquivo
    second_cpf_column = inquirer.select(
        message="Selecione a coluna de CPF do segundo arquivo:",
        choices=filter_system.headers
    ).execute()

    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo unificado:"
    ).execute()

    output_file = filter_system.unify_excel_files_with_cpf(base_file_path, second_file_path, base_cpf_column, second_cpf_column, output_dir)
    print(f"\nArquivo unificado salvo em: {output_file}")

def adicionar_coluna_idade():

    import pandas as pd
    import os
    from datetime import datetime
    from pytz import timezone
    from InquirerPy import inquirer
    from rich import print

    """
    Recebe um arquivo CSV, permite a sele√ß√£o de uma coluna de data de nascimento
    e adiciona uma nova coluna "idade" calculada com base na data atual (Brasil - S√£o Paulo).
    - Detecta automaticamente o delimitador do CSV.
    - Ignora linhas problem√°ticas ao carregar o arquivo.
    - Trata a coluna "idade" como string para evitar formata√ß√£o decimal.
    """
    print("\n[bold yellow]‚ïî‚ïê‚ïê Adicionar Coluna de Idade ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o caminho do arquivo CSV
    file_path = inquirer.text(
        message="Digite o caminho do arquivo CSV:"
    ).execute()

    # Tenta detectar o delimitador automaticamente
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            first_line = file.readline()
            delimiter = ";" if ";" in first_line else ","
    except Exception as e:
        print(f"[bold red]‚úó Erro ao ler o arquivo: {e}[bold red]\n")
        return

    print(f"[cyan]‚úì Delimitador detectado: '{delimiter}'[cyan]")

    try:
        # L√™ o CSV ignorando erros e pulando linhas inconsistentes
        df = pd.read_csv(file_path, dtype=str, sep=delimiter, on_bad_lines="skip", encoding="utf-8")
        
        if df.empty:
            print("[bold red]‚úó O arquivo CSV est√° vazio ou n√£o cont√©m dados v√°lidos.[bold red]\n")
            return
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo CSV: {e}[bold red]\n")
        return

    # Seleciona a coluna de data de nascimento
    date_column = inquirer.select(
        message="Selecione a coluna de Data de Nascimento:",
        choices=df.columns.tolist()
    ).execute()

    print("\n[cyan]Calculando idades...[/cyan]")

    # Define o fuso hor√°rio do Brasil - S√£o Paulo
    brasil_tz = timezone("America/Sao_Paulo")
    today = datetime.now(brasil_tz).date()  # Obt√©m a data atual no fuso hor√°rio correto

    # Fun√ß√£o para calcular idade
    def calcular_idade(data_nascimento):
        try:
            data_nasc = datetime.strptime(data_nascimento, "%d/%m/%Y").date()
            idade = today.year - data_nasc.year - ((today.month, today.day) < (data_nasc.month, data_nasc.day))
            return str(idade)  # Converte para string para evitar valores decimais
        except Exception:
            return None  # Retorna None caso a data seja inv√°lida

    # Aplica a fun√ß√£o de c√°lculo de idade
    df["idade"] = df[date_column].apply(calcular_idade)

    # Exclui linhas com idade vazia (datas inv√°lidas)
    df = df.dropna(subset=["idade"])

    # Converte a coluna "idade" explicitamente para string
    df["idade"] = df["idade"].astype(str)

    # Pergunta o diret√≥rio para salvar o arquivo final
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o novo arquivo CSV:"
    ).execute()

    # Define o caminho do arquivo de sa√≠da
    output_file = os.path.join(output_dir, f'arquivo_com_idade_{os.path.basename(file_path)}')

    print("\n[cyan]Salvando arquivo final...[/cyan]")
    try:
        # Salva o arquivo atualizado garantindo que a coluna "idade" seja string
        df.to_csv(output_file, index=False, encoding="utf-8", sep=delimiter, quoting=1)
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[bold red]\n")


def filter_cpf_removal():
    """Fun√ß√£o para remover CPFs de um arquivo base que existem em outro arquivo"""
    filter_system = ExcelFilter()
    
    # Arquivo base
    base_file_path = inquirer.text(
        message="Digite o caminho do arquivo base (.xlsx):"
    ).execute()
    
    if not filter_system.load_excel(base_file_path):
        return
        
    # Seleciona coluna CPF do arquivo base
    base_cpf_column = inquirer.select(
        message="Selecione a coluna de CPF do arquivo base:",
        choices=filter_system.headers
    ).execute()
    
    # Arquivo de remo√ß√£o
    removal_file_path = inquirer.text(
        message="Digite o caminho do arquivo com CPFs a serem removidos (.xlsx):"
    ).execute()
    
    if not filter_system.load_excel(removal_file_path):
        return
        
    # Seleciona coluna CPF do arquivo de remo√ß√£o
    removal_cpf_column = inquirer.select(
        message="Selecione a coluna de CPF do arquivo de remo√ß√£o:",
        choices=filter_system.headers
    ).execute()
    
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo filtrado:"
    ).execute()
    
    output_file = filter_system.filter_cpf_removal(base_file_path, removal_file_path, 
                                                 base_cpf_column, removal_cpf_column, output_dir)
    print(f"\nArquivo filtrado salvo em: {output_file}")

def filter_cpf_duplicates():
    """Fun√ß√£o para remover CPFs duplicados"""
    filter_system = ExcelFilter()
    
    file_path = inquirer.text(
        message="Digite o caminho do arquivo (.xlsx):"
    ).execute()
    
    if not filter_system.load_excel(file_path):
        return
        
    cpf_column = inquirer.select(
        message="Selecione a coluna de CPF:",
        choices=filter_system.headers
    ).execute()
    
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo filtrado:"
    ).execute()
    
    output_file = filter_system.filter_cpf_duplicates(file_path, cpf_column, output_dir)
    print(f"\nArquivo com CPFs √∫nicos salvo em: {output_file}")

def filter_phone_numbers_csv():
    """Fun√ß√£o para verificar n√∫meros de telefone com prefixo '55' e exatamente 11 d√≠gitos em arquivos CSV."""
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Filtro de N√∫meros de Telefone (CSV) ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Solicita o caminho do arquivo CSV
    csv_path = inquirer.text(
        message="Digite o caminho do arquivo CSV:"
    ).execute()

    try:
        # Carrega o arquivo CSV em um DataFrame
        df = pd.read_csv(csv_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar arquivo CSV: {e}[/bold red]\n")
        return

    # Lista os cabe√ßalhos e solicita ao usu√°rio para selecionar a coluna de telefone
    selected_header = inquirer.select(
        message="Selecione a coluna que cont√©m os n√∫meros de telefone:",
        choices=df.columns.tolist()
    ).execute()

    # Inicializa contadores
    total_registros = len(df)
    registros_removidos = 0

    # Processa cada linha e remove as inv√°lidas
    indices_to_drop = []
    for index in track(df.index, description="[cyan]Filtrando registros...[cyan]", total=total_registros):
        value = str(df.at[index, selected_header]).strip()

        # Remove caracteres n√£o num√©ricos
        clean_value = ''.join(filter(str.isdigit, value))

        # Verifica se o n√∫mero √© v√°lido
        if len(clean_value) != 13 or not clean_value.startswith('55'):
            indices_to_drop.append(index)
            registros_removidos += 1

    # Remove os √≠ndices coletados
    df.drop(indices_to_drop, inplace=True)

    # Calcula total de registros ap√≥s remo√ß√£o
    registros_restantes = len(df)

    # Exibe resumo da opera√ß√£o
    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Registros originais:[/white]    {total_registros:,}")
    print(f"[white]‚ñ∫ Registros removidos:[/white]    {registros_removidos:,}")
    print(f"[white]‚ñ∫ Registros restantes:[/white]   {registros_restantes:,}")

    # Solicita o diret√≥rio de sa√≠da
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo filtrado:"
    ).execute()

    # Salva o arquivo alterado com prefixo no nome
    output_file = os.path.join(output_dir, f'filtro_cel_num_{os.path.basename(csv_path)}')
    try:
        df.to_csv(output_file, index=False)
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[/bold red]\n")

def adjust_cpfs_to_11_digits():
    """Fun√ß√£o para ajustar CPFs em um arquivo Excel, garantindo que todos tenham 11 d√≠gitos."""
    filter_system = ExcelFilter()

    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Ajuste de CPFs ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Solicita o caminho do arquivo Excel
    excel_path = inquirer.text(
        message="Digite o caminho do arquivo Excel:"
    ).execute()

    if not filter_system.load_excel(excel_path):
        print("[bold red]‚úó Erro ao carregar arquivo![/bold red]\n")
        return

    # Lista os cabe√ßalhos e solicita ao usu√°rio para selecionar a coluna de CPF
    selected_header = inquirer.select(
        message="Selecione a coluna que cont√©m os CPFs:",
        choices=filter_system.headers
    ).execute()

    # Converte a coluna para string antes de normalizar os CPFs
    filter_system.df[selected_header] = filter_system.df[selected_header].astype(str)

    # Inicializa contadores
    total_registros = len(filter_system.df)
    registros_normalizados = 0

    # Ajusta os CPFs na coluna selecionada
    for index in track(filter_system.df.index, description="[cyan]Ajustando CPFs...[cyan]", total=total_registros):
        value = str(filter_system.df.at[index, selected_header]).strip()

        # Remove caracteres n√£o num√©ricos
        clean_value = ''.join(filter(str.isdigit, value))

        # Ajusta para 11 d√≠gitos adicionando zeros √† esquerda
        if clean_value and len(clean_value) <= 11:
            normalized_cpf = clean_value.zfill(11)
            filter_system.df.at[index, selected_header] = normalized_cpf
            registros_normalizados += 1

    # Exibe resumo da opera√ß√£o
    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Registros originais:[/white]       {total_registros:,}")
    print(f"[white]‚ñ∫ CPFs ajustados:[/white]          {registros_normalizados:,}")

    # Solicita o diret√≥rio de sa√≠da
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo com CPFs ajustados:"
    ).execute()

    # Salva o arquivo alterado com prefixo no nome
    output_file = os.path.join(output_dir, f'cpfs_ajustados_{os.path.basename(excel_path)}')
    try:
        filter_system.df.to_excel(output_file, index=False)
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[/bold red]\n")

def format_values_to_money():
    """
    Formata valores de uma coluna para o formato monet√°rio (123400 -> 1234,00).
    """
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Formata√ß√£o Monet√°ria ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o caminho do arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[bold red]\n")
        return

    # Seleciona a coluna de valores
    selected_column = inquirer.select(
        message="Selecione a coluna com os valores a formatar:",
        choices=df.columns.tolist()
    ).execute()

    print("\n[cyan]Formatando valores...[/cyan]")

    # Formata os valores para o padr√£o monet√°rio
    def format_money(value):
        try:
            # Divide por 100 e converte para string no formato monet√°rio
            formatted_value = f"{int(value) / 100:,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")
            return formatted_value
        except (ValueError, TypeError):
            return value  # Retorna o valor original se n√£o for poss√≠vel formatar

    # Aplica a formata√ß√£o
    for _ in track(range(100), description="[cyan]Processando valores...[/cyan]"):
        df[selected_column] = df[selected_column].apply(format_money)

    # Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo formatado:"
    ).execute()

    # Adiciona o prefixo ao nome do arquivo de sa√≠da
    output_file = os.path.join(output_dir, f"format_money_{os.path.basename(file_path)}")

    try:
        df.to_excel(output_file, index=False)
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[bold red]\n")

def filter_and_format_rgs():
    """Fun√ß√£o para filtrar RGS inv√°lidos e formatar os v√°lidos para 10 d√≠gitos."""

    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Filtragem e Formata√ß√£o de RGs ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o arquivo base
    base_file_path = inquirer.text(
        message="Digite o caminho do arquivo base (.xlsx):"
    ).execute()

    try:
        base_df = pd.read_excel(base_file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo base: {e}[/bold red]\n")
        return

    # Seleciona a coluna de RG no arquivo base
    rg_column = inquirer.select(
        message="Selecione a coluna de RG:",
        choices=base_df.columns.tolist()
    ).execute()

    print("\n[cyan]Verificando e filtrando RGs inv√°lidos...[/cyan]")
    for _ in track(range(100), description="[cyan]Processando RGs...[/cyan]"):
        time.sleep(0.01)

    # Verifica RGs inv√°lidos
    def is_valid_rg(value):
        if pd.isna(value):  # Verifica valores nulos
            return False
        value = str(value).strip()
        if not value.isdigit():  # Verifica se cont√©m apenas d√≠gitos
            return False
        if len(value) < 5:  # Verifica se tem pelo menos 5 d√≠gitos
            return False
        return True

    # Filtra os registros v√°lidos e inv√°lidos
    base_df['RG_VALIDO'] = base_df[rg_column].apply(is_valid_rg)
    invalid_rgs = base_df[~base_df['RG_VALIDO']].copy()
    valid_rgs = base_df[base_df['RG_VALIDO']].copy()

    # Formata os RGs v√°lidos para 10 d√≠gitos
    print("\n[cyan]Formatando RGs v√°lidos para 10 d√≠gitos...[/cyan]")
    valid_rgs[rg_column] = valid_rgs[rg_column].astype(str).str.zfill(10)

    # Exibe resumo da opera√ß√£o
    total_registros = len(base_df)
    total_validos = len(valid_rgs)
    total_invalidos = len(invalid_rgs)

    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Registros originais:[/white]    {total_registros:,}")
    print(f"[white]‚ñ∫ RGs v√°lidos:[/white]           {total_validos:,}")
    print(f"[white]‚ñ∫ RGs inv√°lidos:[/white]         {total_invalidos:,}")

    # Recebe o diret√≥rio de sa√≠da
    output_dir = inquirer.text(
        message="Digite o caminho para salvar os arquivos filtrados:"
    ).execute()

    # Salva os arquivos filtrados
    valid_output_file = os.path.join(output_dir, f'valid_rgs_{os.path.basename(base_file_path)}')
    invalid_output_file = os.path.join(output_dir, f'invalid_rgs_{os.path.basename(base_file_path)}')

    try:
        valid_rgs.drop(columns=['RG_VALIDO'], inplace=True)
        invalid_rgs.drop(columns=['RG_VALIDO'], inplace=True)

        valid_rgs.to_excel(valid_output_file, index=False)
        invalid_rgs.to_excel(invalid_output_file, index=False)

        print("\n[bold green]‚úì Processo conclu√≠do com sucesso![/bold green]")
        print(f"[dim]üìÅ RGs v√°lidos salvos em: {valid_output_file}[/dim]")
        print(f"[dim]üìÅ RGs inv√°lidos salvos em: {invalid_output_file}[/dim]\n")

    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar os arquivos: {e}[/bold red]\n")

def formatar_coluna_data():
    """Fun√ß√£o para formatar colunas de data em um arquivo Excel."""
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Formata√ß√£o de Datas ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[/bold red]\n")
        return

    # Seleciona a coluna de data
    date_column = inquirer.select(
        message="Selecione a coluna de data:",
        choices=df.columns.tolist()
    ).execute()

    print("\n[cyan]Formatando dados...[/cyan]")

    for _ in track(range(100), description="[cyan]Processando...[/cyan]"):
        pass

    # Converte as datas para o formato dd/MM/YYYY
    try:
        df[date_column] = pd.to_datetime(df[date_column], errors='coerce').dt.strftime('%d/%m/%Y')
    except Exception as e:
        print(f"[bold red]‚úó Erro ao formatar as datas: {e}[/bold red]\n")
        return

    # Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo formatado:"
    ).execute()

    output_file = os.path.join(output_dir, f"data_formatada_{os.path.basename(file_path)}")

    try:
        df.to_excel(output_file, index=False)
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[/bold red]\n")


def dois_unify_excel_files_with_cpf():
    """
    Unifica 2 arquivos (XLSX ou CSV) por CPF:
      1) Pergunta o caminho do arquivo base.
      2) Seleciona a coluna de CPF.
      3) Pergunta o caminho do segundo arquivo.
      4) Seleciona a coluna de CPF do segundo.
      5) Normaliza CPFs (removendo n√£o d√≠gitos e zfill(11)).
      6) Faz merge (inner) e salva o arquivo final (XLSX) num caminho escolhido.
    """

    import os
    import pandas as pd
    import time
    from InquirerPy import inquirer
    from rich import print
    from rich.progress import track

    # --------------------- Fun√ß√£o auxiliar de carregamento --------------------- #
    def load_file_generic(file_path):
        """Carrega XLSX ou CSV (tentando ; depois ,) e retorna DataFrame como string."""
        if file_path.lower().endswith(".xlsx"):
            return pd.read_excel(file_path, engine="openpyxl", dtype=str)
        elif file_path.lower().endswith(".csv"):
            try:
                return pd.read_csv(file_path, sep=';', dtype=str)
            except:
                return pd.read_csv(file_path, sep=',', dtype=str)
        else:
            raise ValueError("Formato de arquivo n√£o suportado! Use .xlsx ou .csv.")

    # --------------------- Fun√ß√£o de normaliza√ß√£o de CPF --------------------- #
    def normalize_cpf(cpf):
        """Remove caracteres n√£o num√©ricos e zera √† esquerda para 11 d√≠gitos."""
        if pd.isna(cpf):
            return ""
        digits = "".join(ch for ch in str(cpf) if ch.isdigit())
        return digits.zfill(11)

    # 1) Recebe e carrega arquivo base
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Unifica√ß√£o por CPF ‚ïê‚ïê‚ïó[/bold yellow]\n")

    base_file_path = inquirer.text(
        message="Digite o caminho do arquivo base (.xlsx ou .csv):"
    ).execute()

    if not os.path.isfile(base_file_path):
        print(f"[bold red]‚úó O caminho '{base_file_path}' n√£o √© v√°lido![bold red]")
        return

    try:
        base_df = load_file_generic(base_file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar arquivo base: {e}[/bold red]")
        return

    if base_df.empty:
        print("[bold red]‚úó O arquivo base est√° vazio ou n√£o cont√©m dados v√°lidos.[/bold red]")
        return

    # Seleciona a coluna de CPF do arquivo base
    base_cpf_column = inquirer.select(
        message="Selecione a coluna de CPF do arquivo base:",
        choices=base_df.columns.tolist()
    ).execute()

    total_base = len(base_df)

    # 2) Recebe e carrega o segundo arquivo
    second_file_path = inquirer.text(
        message="Digite o caminho do segundo arquivo (.xlsx ou .csv):"
    ).execute()

    if not os.path.isfile(second_file_path):
        print(f"[bold red]‚úó O caminho '{second_file_path}' n√£o √© v√°lido![bold red]")
        return

    try:
        second_df = load_file_generic(second_file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o segundo arquivo: {e}[/bold red]")
        return

    if second_df.empty:
        print("[bold red]‚úó O segundo arquivo est√° vazio ou n√£o cont√©m dados v√°lidos.[/bold red]")
        return

    # Seleciona a coluna de CPF do segundo arquivo
    second_cpf_column = inquirer.select(
        message="Selecione a coluna de CPF do segundo arquivo:",
        choices=second_df.columns.tolist()
    ).execute()

    total_second = len(second_df)

    # 3) Pergunta onde salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo unificado:"
    ).execute()

    if not os.path.isdir(output_dir):
        print(f"[bold red]‚úó O caminho '{output_dir}' n√£o √© uma pasta v√°lida![bold red]")
        return

    print("\n[bold yellow]‚ïî‚ïê‚ïê Normalizando e Unificando CPF ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # 4) Normaliza os CPFs (com barra de progresso)
    for _ in track(range(33), description="[cyan]Normalizando CPFs do arquivo base...[/cyan]"):
        time.sleep(0.01)
    base_df[base_cpf_column] = base_df[base_cpf_column].apply(normalize_cpf)

    for _ in track(range(33), description="[cyan]Normalizando CPFs do segundo arquivo...[/cyan]"):
        time.sleep(0.01)
    second_df[second_cpf_column] = second_df[second_cpf_column].apply(normalize_cpf)

    # 5) Faz merge (INNER) => s√≥ CPFs existentes nos 2 arquivos
    for _ in track(range(34), description="[cyan]Unificando arquivos...[/cyan]"):
        time.sleep(0.01)

    merged_df = pd.merge(base_df, second_df, left_on=base_cpf_column, right_on=second_cpf_column, how='inner')

    # 6) Salva o arquivo final como XLSX (por padr√£o)
    #    Se preferir salvar no formato do arquivo base, √© poss√≠vel, mas aqui manteremos XLSX
    import os
    output_file = os.path.join(output_dir, "unified_by_cpf.xlsx")
    try:
        merged_df.to_excel(output_file, index=False, engine="openpyxl")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar arquivo unificado: {e}[/bold red]")
        return

    # 7) Exibe resumo
    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Registros no arquivo base:[/white]    {total_base:,}")
    print(f"[white]‚ñ∫ Registros no segundo arquivo:[/white] {total_second:,}")
    print(f"[white]‚ñ∫ Registros ap√≥s unifica√ß√£o:[/white]    {len(merged_df):,}")
    print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![/bold green]")
    print(f"[dim]üìÅ Arquivo salvo em: {output_file}[/dim]\n")


def unifique_one():
    """
    Unifica todas as planilhas .xlsx de uma pasta em um √∫nico arquivo.
    """
    print("\n[bold yellow]‚ïî‚ïê‚ïê Unifica√ß√£o de Planilhas ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o caminho da pasta com as planilhas
    folder_path = inquirer.text(
        message="Digite o caminho da pasta contendo as planilhas .xlsx:"
    ).execute()

    if not os.path.exists(folder_path):
        print(f"[bold red]‚úó A pasta especificada n√£o existe: {folder_path}[bold red]\n")
        return

    # Lista todas as planilhas .xlsx na pasta
    files = [f for f in os.listdir(folder_path) if f.endswith(".xlsx")]
    if not files:
        print(f"[bold red]‚úó N√£o foram encontradas planilhas .xlsx na pasta: {folder_path}[bold red]\n")
        return

    print(f"[cyan]Encontradas {len(files)} planilhas para unifica√ß√£o...[/cyan]\n")

    # Unifica todas as planilhas em um √∫nico DataFrame
    unified_df = pd.DataFrame()
    for file in files:
        try:
            file_path = os.path.join(folder_path, file)
            df = pd.read_excel(file_path)
            unified_df = pd.concat([unified_df, df], ignore_index=True)
            print(f"[green]‚úì Unificada: {file}[green]")
        except Exception as e:
            print(f"[bold red]‚úó Erro ao unificar {file}: {e}[bold red]")

    # Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo unificado:"
    ).execute()

    if not os.path.exists(output_dir):
        print(f"[bold red]‚úó A pasta especificada para salvar n√£o existe: {output_dir}[bold red]\n")
        return

    # Caminho do arquivo de sa√≠da
    output_file = os.path.join(output_dir, "unifique_one_result.xlsx")

    # Salva o arquivo unificado
    try:
        unified_df.to_excel(output_file, index=False)
        print(f"\n[bold green]‚úì Arquivo unificado salvo com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo unificado: {e}[bold red]\n")

def filter_remove_by_name():
    """Fun√ß√£o para filtrar e remover registros por nome."""

    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Filtragem e Remo√ß√£o por Nome ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o arquivo base
    base_file_path = inquirer.text(
        message="Digite o caminho do arquivo base (.xlsx):"
    ).execute()

    try:
        base_df = pd.read_excel(base_file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo base: {e}[/bold red]\n")
        return

    # Seleciona a coluna de nome no arquivo base
    base_name_column = inquirer.select(
        message="Selecione a coluna de NOME no arquivo base:",
        choices=base_df.columns.tolist()
    ).execute()

    # Recebe o arquivo de blacklist
    blacklist_file_path = inquirer.text(
        message="Digite o caminho do arquivo de blacklist (.xlsx):"
    ).execute()

    try:
        blacklist_df = pd.read_excel(blacklist_file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo de blacklist: {e}[/bold red]\n")
        return

    # Seleciona a coluna de nome no arquivo de blacklist
    blacklist_name_column = inquirer.select(
        message="Selecione a coluna de NOME no arquivo de blacklist:",
        choices=blacklist_df.columns.tolist()
    ).execute()

    # Converte os nomes para caixa alta
    print("\n[cyan]Normalizando nomes para caixa alta...[/cyan]")
    for _ in track(range(100), description="[cyan]Processando...[/cyan]"):
        time.sleep(0.01)

    base_df[base_name_column] = base_df[base_name_column].str.upper().fillna("")
    blacklist_df[blacklist_name_column] = blacklist_df[blacklist_name_column].str.upper().fillna("")

    # Filtra os registros
    print("\n[cyan]Removendo registros encontrados na blacklist...[/cyan]")
    blacklist_names = set(blacklist_df[blacklist_name_column].tolist())
    filtered_df = base_df[~base_df[base_name_column].isin(blacklist_names)].copy()

    # Exibe resumo da opera√ß√£o
    total_registros = len(base_df)
    registros_removidos = total_registros - len(filtered_df)

    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Registros originais:[/white]    {total_registros:,}")
    print(f"[white]‚ñ∫ Registros removidos:[/white]    {registros_removidos:,}")
    print(f"[white]‚ñ∫ Registros restantes:[/white]   {len(filtered_df):,}")

    # Recebe o diret√≥rio de sa√≠da
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo filtrado:"
    ).execute()

    # Salva o arquivo filtrado com o prefixo
    output_file = os.path.join(output_dir, f'filtra_name_remove_{os.path.basename(base_file_path)}')
    try:
        filtered_df.to_excel(output_file, index=False)
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![/bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[/dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[/bold red]\n")

def filter_agencies():
    """Fun√ß√£o para filtrar ag√™ncias banc√°rias com base em crit√©rios espec√≠ficos."""
    
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Filtro de Ag√™ncias ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o arquivo Excel
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[/bold red]\n")
        return

    # Seleciona a coluna de ag√™ncia
    agency_column = inquirer.select(
        message="Selecione a coluna de ag√™ncia banc√°ria:",
        choices=df.columns.tolist()
    ).execute()

    print("\n[cyan]Filtrando ag√™ncias...[/cyan]")

    # Crit√©rios de filtragem
    initial_count = len(df)
    filtered_df = df[df[agency_column].astype(str).str.len() >= 4]
    filtered_df = filtered_df[filtered_df[agency_column].notnull()]

    final_count = len(filtered_df)
    removed_count = initial_count - final_count

    # Resumo da opera√ß√£o
    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Registros originais:[/white]    {initial_count:,}")
    print(f"[white]‚ñ∫ Registros removidos:[/white]    {removed_count:,}")
    print(f"[white]‚ñ∫ Registros restantes:[/white]   {final_count:,}")

    # Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo filtrado:"
    ).execute()

    # Salva o arquivo filtrado
    output_file = os.path.join(output_dir, f"filtro_agencias_{os.path.basename(file_path)}")

    try:
        filtered_df.to_excel(output_file, index=False)
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[bold red]\n")


def map_columns_and_merge():
    """Fun√ß√£o para mapear colunas de um modelo e preencher com dados de outro arquivo."""

    # Recebe o arquivo modelo
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Mapeamento de Colunas ‚ïê‚ïê‚ïó[/bold yellow]\n")
    model_file_path = inquirer.text(
        message="Digite o caminho do arquivo modelo (.xlsx):"
    ).execute()

    try:
        model_df = pd.read_excel(model_file_path)
        model_columns = model_df.columns.tolist()
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo modelo: {e}[/bold red]\n")
        return

    if not model_columns:
        print("[bold red]‚úó O arquivo modelo n√£o possui cabe√ßalhos![bold red]\n")
        return

    # Recebe o arquivo com dados
    data_file_path = inquirer.text(
        message="Digite o caminho do arquivo de dados (.xlsx):"
    ).execute()

    try:
        data_df = pd.read_excel(data_file_path)
        data_columns = data_df.columns.tolist()
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo de dados: {e}[/bold red]\n")
        return

    if not data_columns:
        print("[bold red]‚úó O arquivo de dados n√£o possui cabe√ßalhos![bold red]\n")
        return

    # Inicializa o DataFrame de sa√≠da com as mesmas colunas do modelo
    output_df = pd.DataFrame(columns=model_columns)

    # Mapeamento das colunas
    column_mapping = {}
    used_columns = set()
    print("\n[cyan]Mapeie as colunas do arquivo modelo com as do arquivo de dados:[/cyan]\n")

    for model_col in model_columns:
        available_columns = [col for col in data_columns if col not in used_columns] + ["Ignorar"]
        mapped_column = inquirer.select(
            message=f"Selecione a coluna correspondente para '{model_col}' no arquivo de dados:",
            choices=available_columns,
        ).execute()

        if mapped_column != "Ignorar":
            column_mapping[model_col] = mapped_column
            used_columns.add(mapped_column)

    # Preenchendo o DataFrame de sa√≠da com os dados mapeados
    for model_col, data_col in column_mapping.items():
        output_df[model_col] = data_df[data_col]

    # Exibindo resumo
    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Linhas no arquivo modelo:[/white]       {len(model_df):,}")
    print(f"[white]‚ñ∫ Linhas no arquivo de dados:[/white]    {len(data_df):,}")
    print(f"[white]‚ñ∫ Colunas no arquivo modelo:[/white]     {len(model_columns):,}")
    print(f"[white]‚ñ∫ Colunas no arquivo de dados:[/white]   {len(data_columns):,}")

    # Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo resultante:"
    ).execute()

    output_file = os.path.join(output_dir, f"resultado_{os.path.basename(model_file_path)}")

    try:
        output_df.to_excel(output_file, index=False)
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[bold red]\n")

def validate_address_number():
    """Valida n√∫meros de endere√ßo e preenche c√©lulas vazias com 0, converte para texto no final."""
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Valida√ß√£o de N√∫meros de Endere√ßo ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o caminho do arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[/bold red]\n")
        return

    # Seleciona a coluna de n√∫meros de endere√ßo
    column_name = inquirer.select(
        message="Selecione a coluna que cont√©m os n√∫meros de endere√ßo:",
        choices=df.columns.tolist()
    ).execute()

    print("\n[cyan]Validando n√∫meros de endere√ßo...[/cyan]")

    # Processando e preenchendo valores vazios
    for _ in track(range(100), description="[cyan]Processando...[/cyan]"):
        pass

    try:
        df[column_name] = df[column_name].fillna(0)
        df[column_name] = df[column_name].apply(lambda x: int(str(x).strip()) if str(x).strip().isdigit() else 0)
    except Exception as e:
        print(f"[bold red]‚úó Erro durante a valida√ß√£o: {e}[/bold red]\n")
        return

    # Convertendo todas as c√©lulas para texto
    df[column_name] = df[column_name].astype(str)

    # Exibindo resumo
    total_linhas = len(df)
    linhas_vazias = (df[column_name] == "0").sum()

    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Valida√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Total de linhas no arquivo:[/white] {total_linhas:,}")
    print(f"[white]‚ñ∫ Linhas vazias na coluna:[/white]   {linhas_vazias:,}")

    # Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo validado:"
    ).execute()

    output_file = os.path.join(output_dir, f"validated_address_numbers_{os.path.basename(file_path)}")

    try:
        df.to_excel(output_file, index=False)
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[bold red]\n")

def delete_rows_with_empty_cells():
    """Remove linhas de um arquivo Excel onde a c√©lula na coluna selecionada est√° vazia."""
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Remo√ß√£o de Linhas com C√©lulas Vazias ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o caminho do arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[/bold red]\n")
        return

    # Seleciona a coluna para verificar c√©lulas vazias
    column_name = inquirer.select(
        message="Selecione a coluna para verificar c√©lulas vazias:",
        choices=df.columns.tolist()
    ).execute()

    print("\n[cyan]Removendo linhas com c√©lulas vazias...[/cyan]")

    try:
        # Remove linhas com c√©lulas vazias na coluna selecionada
        initial_row_count = len(df)
        df = df.dropna(subset=[column_name])
        final_row_count = len(df)
        removed_rows = initial_row_count - final_row_count
    except Exception as e:
        print(f"[bold red]‚úó Erro durante a remo√ß√£o: {e}[/bold red]\n")
        return

    # Exibindo resumo
    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Remo√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Total de linhas no arquivo original:[/white] {initial_row_count:,}")
    print(f"[white]‚ñ∫ Linhas removidas:[/white]                 {removed_rows:,}")
    print(f"[white]‚ñ∫ Total de linhas no arquivo final:[/white] {final_row_count:,}")

    # Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo atualizado:"
    ).execute()

    output_file = os.path.join(output_dir, f"rows_removed_{os.path.basename(file_path)}")

    try:
        df.to_excel(output_file, index=False)
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[bold red]\n")

def format_benefit_file():
    """Formata as colunas de sexo e tipo_beneficio em um arquivo Excel."""
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Formata√ß√£o de Benef√≠cio ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[/bold red]\n")
        return

    # Seleciona a coluna de sexo
    sexo_column = inquirer.select(
        message="Selecione a coluna de sexo:",
        choices=df.columns.tolist()
    ).execute()

    # Seleciona a coluna de tipo_beneficio
    beneficio_column = inquirer.select(
        message="Selecione a coluna de tipo_beneficio:",
        choices=df.columns.tolist()
    ).execute()

    print("\n[cyan]Formatando dados...[/cyan]")

    # Formata a coluna de sexo
    for _ in track(range(50), description="[cyan]Formatando coluna de sexo...[/cyan]"):
        pass

    df[sexo_column] = df[sexo_column].replace({'M': 'Masculino', 'F': 'Feminino'})

    # Formata a coluna de tipo_beneficio
    for _ in track(range(50), description="[cyan]Formatando coluna de tipo_beneficio...[/cyan]"):
        pass

    df[beneficio_column] = df[beneficio_column].astype(str).str[:2]

    # Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo formatado:"
    ).execute()

    output_file = os.path.join(output_dir, f"format_benf_{os.path.basename(file_path)}")

    try:
        df.to_excel(output_file, index=False)
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[/bold red]\n")

def format_agency_column():
    """
    Formata uma coluna de ag√™ncia, removendo o √∫ltimo d√≠gito para ag√™ncias com dois ou mais d√≠gitos,
    substituindo valores vazios, nulos ou iguais a '0' por '1', e salvando o arquivo com prefixo 'agencia_format_'.
    """
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Formata√ß√£o de Ag√™ncias ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o caminho do arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[bold red]\n")
        return

    # Seleciona a coluna de ag√™ncia
    agency_column = inquirer.select(
        message="Selecione a coluna de ag√™ncia:",
        choices=df.columns.tolist()
    ).execute()

    print("\n[cyan]Formatando valores da coluna de ag√™ncia...[/cyan]")

    # Fun√ß√£o para formatar os valores da coluna de ag√™ncia
    def format_agency(value):
        if pd.isna(value) or str(value).strip() in ('', '0'):
            return '1'  # Substituir valores vazios, nulos ou iguais a 0 por '1'
        value = str(value).strip()  # Remove espa√ßos
        if len(value) > 1:  # Se o valor tiver dois ou mais d√≠gitos, remove o √∫ltimo d√≠gito
            return value[:-3]
        return value

    # Aplica a formata√ß√£o e conta altera√ß√µes
    total_rows = len(df)
    original_column = df[agency_column].astype(str).copy()  # Copia os valores originais como string
    df[agency_column] = df[agency_column].apply(format_agency)
    modified_rows = (original_column != df[agency_column]).sum()  # Conta as linhas modificadas

    # Resumo da opera√ß√£o
    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Formata√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Total de linhas no arquivo original:[/white] {total_rows:,}")
    print(f"[white]‚ñ∫ Linhas modificadas:[/white] {modified_rows:,}")

    # Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo atualizado:"
    ).execute()

    # Define o caminho do arquivo de sa√≠da
    output_file = os.path.join(output_dir, f"agencia_format_{os.path.basename(file_path)}")

    # Salva o arquivo atualizado
    try:
        df.to_excel(output_file, index=False)
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[bold red]\n")

def validate_and_format_cep():
    """Valida, verifica exist√™ncia e busca detalhes de CEPs usando a API OpenCEP."""
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Valida√ß√£o e Busca de CEP ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o caminho do arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[bold red]\n")
        return

    # Seleciona as colunas necess√°rias
    cep_column = inquirer.select(
        message="Selecione a coluna que cont√©m os CEPs:",
        choices=df.columns.tolist()
    ).execute()

    endereco_column = inquirer.select(
        message="Selecione a coluna de Endere√ßo:",
        choices=df.columns.tolist()
    ).execute()

    bairro_column = inquirer.select(
        message="Selecione a coluna de Bairro:",
        choices=df.columns.tolist()
    ).execute()

    cidade_column = inquirer.select(
        message="Selecione a coluna de Cidade:",
        choices=df.columns.tolist()
    ).execute()

    estado_column = inquirer.select(
        message="Selecione a coluna de Estado:",
        choices=df.columns.tolist()
    ).execute()

    print("\n[cyan]Validando CEPs...[/cyan]")

    # Valida√ß√£o inicial do CEP
    def validate_cep(value):
        if pd.isna(value):
            return None
        cep = str(value).strip().replace("-", "")
        if len(cep) != 8 or not cep.isdigit():
            return None
        return cep

    # Aplicar valida√ß√£o
    df[cep_column] = df[cep_column].apply(validate_cep)

    # Remove linhas com CEP inv√°lido
    initial_row_count = len(df)
    df_invalid = df[df[cep_column].isna()].copy()
    df = df.dropna(subset=[cep_column]).copy()

    print(f"[bold green]‚úì Linhas removidas devido a CEPs inv√°lidos: {len(df_invalid)}[/bold green]\n")

    # Fase 1: Verificar se o CEP existe
    print("[cyan]Verificando a exist√™ncia dos CEPs...[/cyan]")

    def check_cep_exists(cep):
        try:
            response = requests.get(f"https://opencep.com/v1/{cep}.json", timeout=5)
            if response.status_code == 200:
                data = response.json()
                return "erro" not in data  # Retorna True se o CEP existir
            return False
        except Exception as e:
            logging.warning(f"Erro ao verificar CEP {cep}: {e}")
            return False

    # Adiciona uma nova coluna para marcar CEPs existentes
    df["EXISTE"] = False
    for index in track(df.index, description="[cyan]Verificando CEPs...[/cyan]"):
        cep = df.at[index, cep_column]
        df.at[index, "EXISTE"] = check_cep_exists(cep)
        print(f"Verificando linha {index + 1}/{len(df)} - CEP: {cep}")

    # Fase 2: Obter detalhes dos CEPs existentes
    print("[cyan]Buscando detalhes dos CEPs existentes...[/cyan]")
    valid_indices = []

    def fetch_cep_details(cep):
        try:
            response = requests.get(f"https://opencep.com/v1/{cep}.json")
            if response.status_code == 200:
                return response.json()
        except Exception as e:
            logging.warning(f"Erro ao buscar detalhes do CEP {cep}: {e}")
            return None

    for index in track(df.index, description="[cyan]Processando CEPs existentes...[/cyan]"):
        if df.at[index, "EXISTE"]:
            cep = df.at[index, cep_column]
            address_data = fetch_cep_details(cep)
            if address_data:
                valid_indices.append(index)
                df.at[index, endereco_column] = address_data.get("logradouro", df.at[index, endereco_column])
                df.at[index, bairro_column] = address_data.get("bairro", df.at[index, bairro_column])
                df.at[index, cidade_column] = address_data.get("localidade", df.at[index, cidade_column])
                df.at[index, estado_column] = address_data.get("uf", df.at[index, estado_column])
                print(f"Detalhes obtidos para CEP: {cep}")
            else:
                print(f"Falha ao buscar detalhes para o CEP: {cep}")

    # Remove CEPs n√£o existentes do DataFrame
    df_invalid = pd.concat([df_invalid, df[~df["EXISTE"]]])
    df_valid = df.loc[valid_indices].copy()
    df.drop(columns=["EXISTE"], inplace=True)

    # Resumo final
    print("\n[bold green]‚ïî‚ïê‚ïê Resumo Final ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Total de linhas no arquivo original:[/white] {initial_row_count:,}")
    print(f"[white]‚ñ∫ CEPs v√°lidos encontrados e detalhados:[/white] {len(df_valid):,}")
    print(f"[white]‚ñ∫ Linhas removidas (CEPs inv√°lidos ou inexistentes):[/white] {len(df_invalid):,}")

    # Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar os arquivos:"
    ).execute()

    # Caminhos para os arquivos de sa√≠da
    valid_output_file = os.path.join(output_dir, f"cep_validos_{os.path.basename(file_path)}")
    invalid_output_file = os.path.join(output_dir, f"cep_invalidos_{os.path.basename(file_path)}")

    # Salva os arquivos
    try:
        df_valid.to_excel(valid_output_file, index=False)
        df_invalid.to_excel(invalid_output_file, index=False)
        print(f"\n[bold green]‚úì Arquivos salvos com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo com CEPs v√°lidos salvo em: {valid_output_file}[dim]")
        print(f"[dim]üìÅ Arquivo com CEPs inv√°lidos salvo em: {invalid_output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar os arquivos: {e}[bold red]\n")

def validador_de_bancos():
    """
    Valida colunas de banco, ag√™ncia e conta.
    Remove linhas que n√£o atendem aos crit√©rios:
    - Banco: 1 a 3 d√≠gitos
    - Ag√™ncia: 1 a 4 d√≠gitos
    - Conta: N√£o pode ter letras, espa√ßos ou estar vazia.
    """
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Valida√ß√£o de Banco ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o caminho do arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[bold red]\n")
        return

    # Seleciona as colunas necess√°rias
    banco_column = inquirer.select(
        message="Selecione a coluna de Banco:",
        choices=df.columns.tolist()
    ).execute()

    agencia_column = inquirer.select(
        message="Selecione a coluna de Ag√™ncia:",
        choices=df.columns.tolist()
    ).execute()

    conta_column = inquirer.select(
        message="Selecione a coluna de Conta:",
        choices=df.columns.tolist()
    ).execute()

    print("\n[cyan]Validando dados...[/cyan]")

    # Fun√ß√µes de valida√ß√£o
    def is_valid_banco(value):
        return str(value).isdigit() and 1 <= len(str(value)) <= 3

    def is_valid_agencia(value):
        return str(value).isdigit() and 1 <= len(str(value)) <= 4

    def is_valid_conta(value):
        return str(value).isdigit() and len(str(value)) > 0

    # Inicializa contadores
    initial_row_count = len(df)

    # Aplica valida√ß√£o para todas as colunas e filtra as linhas inv√°lidas
    df["VALIDO"] = df[banco_column].apply(is_valid_banco) & \
                   df[agencia_column].apply(is_valid_agencia) & \
                   df[conta_column].apply(is_valid_conta)

    df_invalid = df[~df["VALIDO"]].copy()  # Linhas inv√°lidas
    df = df[df["VALIDO"]].copy()           # Linhas v√°lidas

    # Remove a coluna auxiliar "VALIDO"
    df.drop(columns=["VALIDO"], inplace=True)
    df_invalid.drop(columns=["VALIDO"], inplace=True)

    # Resumo da valida√ß√£o
    linhas_invalidas = len(df_invalid)
    linhas_validas = len(df)

    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Valida√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Linhas originais:[/white]    {initial_row_count:,}")
    print(f"[white]‚ñ∫ Linhas v√°lidas:[/white]      {linhas_validas:,}")
    print(f"[white]‚ñ∫ Linhas inv√°lidas:[/white]    {linhas_invalidas:,}")

    # Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar os arquivos filtrados:"
    ).execute()

    # Adiciona prefixo aos nomes dos arquivos de sa√≠da
    valid_output_file = os.path.join(output_dir, f"filtrar_bank_validos_{os.path.basename(file_path)}")
    invalid_output_file = os.path.join(output_dir, f"filtrar_bank_invalidos_{os.path.basename(file_path)}")

    # Salva os arquivos
    try:
        df.to_excel(valid_output_file, index=False)
        df_invalid.to_excel(invalid_output_file, index=False)
        print(f"\n[bold green]‚úì Arquivos salvos com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo com dados v√°lidos salvo em: {valid_output_file}[dim]")
        print(f"[dim]üìÅ Arquivo com dados inv√°lidos salvo em: {invalid_output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar os arquivos: {e}[bold red]\n")

def validate_sex_column():
    """Valida a coluna de sexo, convertendo 'M' e 'F' para 'Masculino' e 'Feminino',
    removendo linhas com valores inv√°lidos."""
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Valida√ß√£o da Coluna de Sexo ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o caminho do arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[/bold red]\n")
        return

    # Seleciona a coluna de sexo
    column_name = inquirer.select(
        message="Selecione a coluna que cont√©m os valores de sexo:",
        choices=df.columns.tolist()
    ).execute()

    print("\n[cyan]Validando a coluna de sexo...[/cyan]")

    # Processando os valores
    valid_sex_values = {"M": "Masculino", "F": "Feminino"}
    try:
        df[column_name] = df[column_name].apply(lambda x: valid_sex_values.get(str(x).strip(), x))

        # Filtra as linhas v√°lidas
        valid_rows = df[column_name].isin(["Masculino", "Feminino"])
        filtered_df = df[valid_rows].copy()

        invalid_rows_count = len(df) - len(filtered_df)

    except Exception as e:
        print(f"[bold red]‚úó Erro durante a valida√ß√£o: {e}[/bold red]\n")
        return

    # Exibindo resumo
    total_linhas = len(df)
    linhas_validas = len(filtered_df)

    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Valida√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Total de linhas no arquivo:[/white] {total_linhas:,}")
    print(f"[white]‚ñ∫ Linhas v√°lidas:[/white] {linhas_validas:,}")
    print(f"[white]‚ñ∫ Linhas removidas:[/white] {invalid_rows_count:,}")

    # Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo validado:"
    ).execute()

    output_file = os.path.join(output_dir, f"validated_sex_column_{os.path.basename(file_path)}")

    try:
        filtered_df.to_excel(output_file, index=False)
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[bold red]\n")

def extract_ddd_and_number():
    """Fun√ß√£o para extrair DDD e n√∫mero de uma coluna de celular."""
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Extra√ß√£o de DDD e N√∫mero ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[/bold red]\n")
        return

    # Seleciona a coluna de n√∫meros de celular
    phone_column = inquirer.select(
        message="Selecione a coluna que cont√©m os n√∫meros de celular (DDD+N√∫mero):",
        choices=df.columns.tolist()
    ).execute()

    # Seleciona a coluna de sa√≠da para DDD
    ddd_column = inquirer.select(
        message="Selecione a coluna onde ser√° inserido o DDD extra√≠do:",
        choices=df.columns.tolist()
    ).execute()

    # Inicializa contadores
    total_registros = len(df)
    registros_validos = 0
    registros_invalidos = 0

    # Processa cada linha e separa o DDD do n√∫mero
    def process_phone(value):
        nonlocal registros_validos, registros_invalidos
        if pd.isna(value):
            registros_invalidos += 1
            return None, None

        value = str(value).strip()
        if len(value) == 11 and value.isdigit():
            registros_validos += 1
            return value[:2], value[2:]
        else:
            registros_invalidos += 1
            return None, None

    print("\n[cyan]Processando n√∫meros...[/cyan]")

    df[ddd_column], df[phone_column] = zip(*df[phone_column].apply(process_phone))

    # Exibe resumo da opera√ß√£o
    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Registros totais:[/white]    {total_registros:,}")
    print(f"[white]‚ñ∫ Registros v√°lidos:[/white]   {registros_validos:,}")
    print(f"[white]‚ñ∫ Registros inv√°lidos:[/white] {registros_invalidos:,}")

    # Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo atualizado:"
    ).execute()

    output_file = os.path.join(output_dir, f"extracted_number_ddd_{os.path.basename(file_path)}")

    try:
        df.to_excel(output_file, index=False)
        print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[bold red]\n")

def whitelist_blacklist_removal_num():
    """
    Remove (troca por '0') os n√∫meros de telefone do arquivo base (CPF + colunas de telefone)
    que aparecem em um segundo arquivo de blacklist (CPF + telefone_incorreto),
    convertendo sempre os arquivos Excel (.xlsx) para CSV,
    e gerando SEMPRE um arquivo final em CSV.

    Fluxo resumido:
      1) Recebe ARQUIVO BASE (pode ser .xlsx ou .csv).
         - Se .xlsx, converte para CSV tempor√°rio e trabalha com ele.
         - Pergunta coluna de CPF e colunas de telefone.
      2) Recebe ARQUIVO BLACKLIST (pode ser .xlsx ou .csv).
         - Se .xlsx, converte para CSV tempor√°rio.
         - Pergunta coluna de CPF e coluna de telefone incorreto.
      3) Para cada (CPF, telefone_incorreto) no arquivo de blacklist,
         se o telefone estiver em alguma coluna do base, troca por '0'.
      4) Gera um arquivo final SEMPRE em CSV, com prefixo 'tel_incorretos_removidos_'.
    """

    import os
    import pandas as pd
    from InquirerPy import inquirer
    from rich.console import Console
    console = Console()
    from pathlib import Path
    import uuid

    console.print("\n[bold yellow]‚ïî‚ïê‚ïê Remo√ß√£o de Telefones Incorretos por CPF (Sa√≠da CSV) ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # --------------------- Fun√ß√£o para converter XLSX -> CSV --------------------- #
    def convert_xlsx_to_csv(xlsx_path, output_dir=None):
        """
        Converte um arquivo XLSX para um CSV tempor√°rio usando sep=';'.
        Retorna o caminho do CSV gerado.
        Se output_dir n√£o for informado, gera no mesmo diret√≥rio do xlsx.
        """
        if output_dir is None:
            output_dir = os.path.dirname(xlsx_path)

        df = pd.read_excel(xlsx_path, engine="openpyxl", dtype=str)
        temp_name = f"{Path(xlsx_path).stem}_temp_{uuid.uuid4().hex[:6]}.csv"
        temp_path = os.path.join(output_dir, temp_name)
        df.to_csv(temp_path, index=False, sep=';', encoding='utf-8')
        return temp_path

    # --------------------- Fun√ß√£o auxiliar de fallback p/ ler CSV --------------------- #
    def load_csv_fallback(csv_path):
        """
        Tenta ler CSV com sep=';' e UTF-8 ‚Üí se falhar, sep=';' e latin-1
        ‚Üí se falhar, sep=',' e UTF-8 ‚Üí se falhar, ',' e latin-1.
        Retorna df com dtype=str e low_memory=False para evitar warnings.
        """
        # 1) tenta ; + utf-8
        try:
            try:
                return pd.read_csv(csv_path, sep=';', encoding='utf-8', dtype=str, low_memory=False)
            except UnicodeDecodeError:
                return pd.read_csv(csv_path, sep=';', encoding='latin-1', dtype=str, low_memory=False)
        except:
            # 2) tenta , + utf-8
            try:
                try:
                    return pd.read_csv(csv_path, sep=',', encoding='utf-8', dtype=str, low_memory=False)
                except UnicodeDecodeError:
                    return pd.read_csv(csv_path, sep=',', encoding='latin-1', dtype=str, low_memory=False)
            except Exception as e:
                raise e

    # --------------------- Passo 1: Carrega o ARQUIVO BASE --------------------- #
    base_file_path = inquirer.text(
        message="Digite o caminho do ARQUIVO BASE (XLSX ou CSV):"
    ).execute()

    if not os.path.isfile(base_file_path):
        console.print(f"[bold red]‚úó O caminho '{base_file_path}' n√£o √© um arquivo v√°lido![bold red]\n")
        return

    # Se for XLSX, converte para CSV tempor√°rio
    if base_file_path.lower().endswith(".xlsx"):
        console.print("[cyan]Convertendo arquivo base de XLSX para CSV tempor√°rio...[/cyan]")
        try:
            base_csv_path = convert_xlsx_to_csv(base_file_path)
        except Exception as e:
            console.print(f"[bold red]‚úó Erro ao converter XLSX para CSV: {e}[bold red]\n")
            return
    elif base_file_path.lower().endswith(".csv"):
        base_csv_path = base_file_path
    else:
        console.print("[bold red]‚úó Formato de arquivo base n√£o suportado (use .xlsx ou .csv)![bold red]")
        return

    # Tenta carregar base como CSV (fallback)
    try:
        base_df = load_csv_fallback(base_csv_path)
        if base_df.empty:
            console.print("[bold red]‚úó O arquivo base est√° vazio ou n√£o possui dados v√°lidos.[bold red]\n")
            return
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao carregar o arquivo base como CSV: {e}[bold red]\n")
        return

    # --------------------- Escolhe colunas no base --------------------- #
    cpf_base_col = inquirer.select(
        message="Selecione a coluna de CPF no arquivo base:",
        choices=base_df.columns.tolist()
    ).execute()

    # Pode haver v√°rias colunas de telefone
    phone_cols = []
    while True:
        remaining = [c for c in base_df.columns if c not in phone_cols and c != cpf_base_col]
        if not remaining:
            break

        question = inquirer.confirm(
            message="Deseja selecionar mais uma coluna de telefone no arquivo base?",
            default=True
        ).execute()

        if not question and not phone_cols:
            console.print("[bold red]‚úó √â preciso selecionar ao menos uma coluna de telefone![bold red]")
            return
        if not question:
            break

        chosen_phone = inquirer.select(
            message="Selecione a coluna de telefone:",
            choices=remaining
        ).execute()
        phone_cols.append(chosen_phone)

    if not phone_cols:
        console.print("[bold red]‚úó Nenhuma coluna de telefone foi selecionada, encerrando...[bold red]")
        return

    console.print("\n[cyan]Exibindo exemplo de valor em cada coluna de telefone (se houver dados)...[/cyan]")
    for col_ in phone_cols:
        example_val = None
        for _, val in base_df[col_].items():
            if pd.notna(val) and val.strip():
                example_val = val.strip()
                break
        if example_val:
            console.print(f" - [white]{col_}[/white]: [cyan]{example_val}[/cyan]")
        else:
            console.print(f" - [white]{col_}[/white]: [bold yellow]Nenhum valor preenchido[/bold yellow]")

    # --------------------- Passo 2: Carrega o ARQUIVO BLACKLIST --------------------- #
    blacklist_file_path = inquirer.text(
        message="Digite o caminho do arquivo de BLACKLIST (XLSX ou CSV):"
    ).execute()

    if not os.path.isfile(blacklist_file_path):
        console.print(f"[bold red]‚úó O caminho '{blacklist_file_path}' n√£o √© um arquivo v√°lido![bold red]\n")
        return

    # Se for XLSX, converte para CSV tempor√°rio
    if blacklist_file_path.lower().endswith(".xlsx"):
        console.print("[cyan]Convertendo arquivo blacklist de XLSX para CSV tempor√°rio...[/cyan]")
        try:
            black_csv_path = convert_xlsx_to_csv(blacklist_file_path)
        except Exception as e:
            console.print(f"[bold red]‚úó Erro ao converter XLSX para CSV: {e}[bold red]\n")
            return
    elif blacklist_file_path.lower().endswith(".csv"):
        black_csv_path = blacklist_file_path
    else:
        console.print("[bold red]‚úó Formato de arquivo blacklist n√£o suportado (use .xlsx ou .csv)![bold red]")
        return

    # Tenta carregar blacklist como CSV (fallback)
    try:
        black_df = load_csv_fallback(black_csv_path)
        if black_df.empty:
            console.print("[bold red]‚úó O arquivo de blacklist est√° vazio ou n√£o possui dados v√°lidos.[bold red]\n")
            return
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao carregar o arquivo de blacklist como CSV: {e}[bold red]\n")
        return

    # Escolhe colunas
    cpf_black_col = inquirer.select(
        message="Selecione a coluna de CPF no arquivo de blacklist:",
        choices=black_df.columns.tolist()
    ).execute()

    phone_black_col = inquirer.select(
        message="Selecione a coluna de TELEFONE incorreto no arquivo de blacklist:",
        choices=[c for c in black_df.columns if c != cpf_black_col]
    ).execute()

    # --------------------- 3) Monta dict CPF -> set(telefones incorretos) --------------------- #
    console.print("\n[cyan]Agrupando telefones incorretos por CPF...[/cyan]")
    from collections import defaultdict
    black_dict = defaultdict(set)

    for idx, row in black_df.iterrows():
        c = str(row[cpf_black_col]).strip()
        p = str(row[phone_black_col]).strip()
        if c and p:
            black_dict[c].add(p)

    console.print(f"[white]Total de CPFs na blacklist:[/white] {len(black_dict):,}")

    # --------------------- 4) Para cada linha do base, se (cpf, phone) -> '0' --------------------- #
    console.print("\n[cyan]Removendo telefones incorretos no arquivo base...[/cyan]")

    total_rows = len(base_df)
    replaced_count = 0

    for idx in range(total_rows):
        cpf_val = str(base_df.at[idx, cpf_base_col]).strip()
        if cpf_val in black_dict:
            phones_to_remove = black_dict[cpf_val]
            # Checa cada coluna de telefone
            for pc in phone_cols:
                val = base_df.at[idx, pc]
                if pd.notna(val):
                    val_str = str(val).strip()
                    if val_str in phones_to_remove:
                        base_df.at[idx, pc] = "0"
                        replaced_count += 1

    # --------------------- 5) Pergunta onde salvar e SALVA SEMPRE EM CSV --------------------- #
    console.print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    console.print(f"[white]‚ñ∫ Total de linhas no arquivo base:[/white] {total_rows:,}")
    console.print(f"[white]‚ñ∫ Telefones substitu√≠dos por '0':[/white] {replaced_count:,}")

    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo final (CSV):"
    ).execute()

    if not os.path.isdir(output_dir):
        console.print(f"[bold red]‚úó O caminho '{output_dir}' n√£o √© uma pasta v√°lida![bold red]\n")
        return

    final_file = os.path.join(output_dir, f"tel_incorretos_removidos_{Path(base_file_path).stem}.csv")

    console.print("\n[cyan]Salvando arquivo final em CSV...[/cyan]")
    try:
        base_df.to_csv(final_file, index=False, sep=';', encoding='utf-8')
        console.print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        console.print(f"[dim]üìÅ Arquivo final salvo em CSV: {final_file}[dim]\n")
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao salvar o arquivo final em CSV: {e}[bold red]\n")


def whitelist_blacklist_removal_cpf():
    """
    Remove linhas do arquivo base que possuem CPFs contidos no arquivo de blacklist.
    Suporta arquivos XLSX ou CSV, sempre carregando e salvando como string (dtype=str).
    Mant√©m o mesmo formato de sa√≠da (XLSX ou CSV) do arquivo base.
    """
    import os
    import pandas as pd
    from InquirerPy import inquirer
    from pathlib import Path
    from rich.progress import track

    print("\n[bold yellow]‚ïî‚ïê‚ïê Remo√ß√£o de Linhas com CPFs na Blacklist ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Fun√ß√£o auxiliar para carregar XLSX ou CSV como string
    def load_file_generic(file_path):
        if file_path.lower().endswith(".xlsx"):
            return pd.read_excel(file_path, engine="openpyxl", dtype=str)
        elif file_path.lower().endswith(".csv"):
            try:
                return pd.read_csv(file_path, sep=';', dtype=str)
            except:
                return pd.read_csv(file_path, sep=',', dtype=str)
        else:
            raise ValueError("Formato de arquivo n√£o suportado! Use .xlsx ou .csv.")

    # 1) Carrega o arquivo base
    base_file_path = inquirer.text(
        message="Digite o caminho do arquivo base (XLSX ou CSV):"
    ).execute()

    if not os.path.isfile(base_file_path):
        print(f"[bold red]‚úó O caminho '{base_file_path}' n√£o √© um arquivo v√°lido![bold red]\n")
        return

    try:
        base_df = load_file_generic(base_file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo base: {e}[bold red]\n")
        return

    if base_df.empty:
        print("[bold red]‚úó O arquivo base est√° vazio ou n√£o possui dados v√°lidos.[bold red]\n")
        return

    # Seleciona a coluna de CPF no arquivo base
    base_cpf_col = inquirer.select(
        message="Selecione a coluna de CPF no arquivo base:",
        choices=base_df.columns.tolist()
    ).execute()

    # 2) Carrega o arquivo de blacklist
    blacklist_file_path = inquirer.text(
        message="Digite o caminho do arquivo de blacklist (XLSX ou CSV):"
    ).execute()

    if not os.path.isfile(blacklist_file_path):
        print(f"[bold red]‚úó O caminho '{blacklist_file_path}' n√£o √© um arquivo v√°lido![bold red]\n")
        return

    try:
        blacklist_df = load_file_generic(blacklist_file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo de blacklist: {e}[bold red]\n")
        return

    if blacklist_df.empty:
        print("[bold red]‚úó O arquivo de blacklist est√° vazio ou n√£o possui dados v√°lidos.[bold red]\n")
        return

    # Seleciona a coluna de CPF no arquivo de blacklist
    blacklist_cpf_col = inquirer.select(
        message="Selecione a coluna de CPF no arquivo de blacklist:",
        choices=blacklist_df.columns.tolist()
    ).execute()

    print("\n[cyan]Removendo do arquivo base os CPFs presentes na blacklist...[/cyan]")

    # 3) Cria um conjunto com os CPFs da blacklist (padronizando tudo como string sem espa√ßos)
    black_set = set(blacklist_df[blacklist_cpf_col].astype(str).str.strip())

    initial_row_count = len(base_df)

    # 4) Marca quem N√ÉO est√° na blacklist como VALIDO
    base_df["VALIDO"] = ~base_df[base_cpf_col].astype(str).str.strip().isin(black_set)

    valid_df = base_df[base_df["VALIDO"]].drop(columns=["VALIDO"]).copy()    # Linhas v√°lidas
    invalid_df = base_df[~base_df["VALIDO"]].drop(columns=["VALIDO"]).copy() # Linhas removidas

    linhas_removidas = len(invalid_df)
    linhas_restantes = len(valid_df)

    # Exibe resumo da opera√ß√£o
    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Total de linhas no arquivo base:[/white] {initial_row_count:,}")
    print(f"[white]‚ñ∫ Linhas removidas (CPF na blacklist):[/white] {linhas_removidas:,}")
    print(f"[white]‚ñ∫ Linhas restantes:[/white] {linhas_restantes:,}")

    # 5) Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar os arquivos filtrados:"
    ).execute()

    if not os.path.isdir(output_dir):
        print(f"[bold red]‚úó O caminho '{output_dir}' n√£o √© uma pasta v√°lida![bold red]\n")
        return

    # 6) Define nomes dos arquivos de sa√≠da (mantendo extens√£o do base)
    base_stem = Path(base_file_path).stem
    ext = Path(base_file_path).suffix.lower()

    valid_output_file = os.path.join(output_dir, f"whitelist_{base_stem}{ext}")
    invalid_output_file = os.path.join(output_dir, f"blacklist_{base_stem}{ext}")

    # 7) Salva no mesmo formato do base
    def save_in_same_format(df_local, path_out):
        if ext == ".xlsx":
            df_local.to_excel(path_out, index=False, engine="openpyxl")
        elif ext == ".csv":
            df_local.to_csv(path_out, sep=';', index=False, encoding='utf-8')
        else:
            raise ValueError("Formato de arquivo n√£o suportado!")

    try:
        save_in_same_format(valid_df, valid_output_file)
        save_in_same_format(invalid_df, invalid_output_file)
        print(f"\n[bold green]‚úì Arquivos salvos com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo com CPFs v√°lidos salvo em: {valid_output_file}[dim]")
        print(f"[dim]üìÅ Arquivo com CPFs removidos salvo em: {invalid_output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar os arquivos: {e}[bold red]\n")


def filter_num_nine():
    """
    Formata n√∫meros de celular adicionando o d√≠gito '9' ap√≥s o DDD em n√∫meros de 12 d√≠gitos.
    Remove linhas com n√∫meros que n√£o possuem 12 ou 13 d√≠gitos.
    """
    print("\n[bold yellow]‚ïî‚ïê‚ïê Formata√ß√£o de N√∫meros com '9' ‚ïê‚ïê‚ïó[/bold yellow]\n")
    print("[bold cyan]Observa√ß√£o: Certifique-se de que os n√∫meros estejam no formato correto, come√ßando com '55' seguido do DDD e n√∫mero.[/bold cyan]\n")

    # Recebe o caminho do arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[bold red]\n")
        return

    # Seleciona a coluna de n√∫meros
    number_column = inquirer.select(
        message="Selecione a coluna de n√∫meros de celular:",
        choices=df.columns.tolist()
    ).execute()

    print("\n[cyan]Formatando n√∫meros...[/cyan]")

    # Fun√ß√£o para verificar e corrigir n√∫meros
    def format_number(value):
        try:
            value = str(value).strip()
            if len(value) == 12:  # N√∫mero com 12 d√≠gitos (faltando o 9)
                return value[:4] + "9" + value[4:]
            elif len(value) == 13:  # N√∫mero j√° no formato correto
                return value
            return None  # N√∫mero inv√°lido
        except Exception:
            return None

    # Aplica a formata√ß√£o e filtra n√∫meros inv√°lidos
    initial_row_count = len(df)
    df[number_column] = df[number_column].apply(format_number)

    df_invalid = df[df[number_column].isna()].copy()  # N√∫meros inv√°lidos
    df = df.dropna(subset=[number_column]).copy()     # N√∫meros v√°lidos

    # Resumo da formata√ß√£o
    linhas_invalidas = len(df_invalid)
    linhas_validas = len(df)

    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Formata√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Linhas originais:[/white] {initial_row_count:,}")
    print(f"[white]‚ñ∫ N√∫meros formatados:[/white] {linhas_validas:,}")
    print(f"[white]‚ñ∫ Linhas removidas (n√∫meros inv√°lidos):[/white] {linhas_invalidas:,}")

    # Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar os arquivos formatados:"
    ).execute()

    # Adiciona prefixo aos nomes dos arquivos de sa√≠da
    valid_output_file = os.path.join(output_dir, f"filtrer_num_nine_validos_{os.path.basename(file_path)}")
    invalid_output_file = os.path.join(output_dir, f"filtrer_num_nine_invalidos_{os.path.basename(file_path)}")

    # Salva os arquivos
    try:
        df.to_excel(valid_output_file, index=False)
        df_invalid.to_excel(invalid_output_file, index=False)
        print(f"\n[bold green]‚úì Arquivos salvos com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo com n√∫meros v√°lidos salvo em: {valid_output_file}[dim]")
        print(f"[dim]üìÅ Arquivo com n√∫meros inv√°lidos salvo em: {invalid_output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar os arquivos: {e}[bold red]\n")

def filter_back_age():
    """
    Valida banco, ag√™ncia e conta e remove linhas que atendem aos crit√©rios de remo√ß√£o:
    - Cont√©m letras
    - Cont√©m espa√ßos
    - Est√° vazio
    - √â igual a zero
    """
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Valida√ß√£o de Banco, Ag√™ncia e Conta ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o caminho do arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[bold red]\n")
        return

    # Seleciona as colunas necess√°rias
    banco_column = inquirer.select(
        message="Selecione a coluna de Banco:",
        choices=df.columns.tolist()
    ).execute()

    agencia_column = inquirer.select(
        message="Selecione a coluna de Ag√™ncia:",
        choices=df.columns.tolist()
    ).execute()

    conta_column = inquirer.select(
        message="Selecione a coluna de Conta:",
        choices=df.columns.tolist()
    ).execute()

    print("\n[cyan]Validando dados...[/cyan]")

    # Fun√ß√£o de valida√ß√£o
    def is_invalid(value):
        """Verifica se o valor cont√©m letras, espa√ßos, est√° vazio ou √© igual a zero."""
        if pd.isna(value) or str(value).strip() == "" or str(value).strip() == "0":
            return True
        if any(char.isalpha() for char in str(value)) or " " in str(value):
            return True
        return False

    # Aplica a valida√ß√£o e filtra as linhas inv√°lidas
    initial_row_count = len(df)
    df["VALIDO"] = ~(
        df[banco_column].apply(is_invalid) |
        df[agencia_column].apply(is_invalid) |
        df[conta_column].apply(is_invalid)
    )

    df_invalid = df[~df["VALIDO"]].copy()  # Linhas inv√°lidas
    df = df[df["VALIDO"]].copy()           # Linhas v√°lidas

    # Remove a coluna auxiliar "VALIDO"
    df.drop(columns=["VALIDO"], inplace=True)
    df_invalid.drop(columns=["VALIDO"], inplace=True)

    # Resumo da valida√ß√£o
    linhas_invalidas = len(df_invalid)
    linhas_validas = len(df)

    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Valida√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Linhas originais:[/white] {initial_row_count:,}")
    print(f"[white]‚ñ∫ Linhas v√°lidas:[/white]   {linhas_validas:,}")
    print(f"[white]‚ñ∫ Linhas inv√°lidas:[/white] {linhas_invalidas:,}")

    # Pergunta o diret√≥rio para salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar os arquivos filtrados:"
    ).execute()

    # Adiciona prefixo aos nomes dos arquivos de sa√≠da
    valid_output_file = os.path.join(output_dir, f"filter_back_age_validos_{os.path.basename(file_path)}")
    invalid_output_file = os.path.join(output_dir, f"filter_back_age_invalidos_{os.path.basename(file_path)}")

    # Salva os arquivos
    try:
        df.to_excel(valid_output_file, index=False)
        df_invalid.to_excel(invalid_output_file, index=False)
        print(f"\n[bold green]‚úì Arquivos salvos com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo com dados v√°lidos salvo em: {valid_output_file}[dim]")
        print(f"[dim]üìÅ Arquivo com dados inv√°lidos salvo em: {invalid_output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar os arquivos: {e}[bold red]\n")

def merge_ddd_number():
    """
    Une as colunas DDD e N√∫mero em uma nova coluna.
    - DDD deve ter 2 d√≠gitos.
    - N√∫mero deve ter 9 d√≠gitos.
    - Linhas fora desses crit√©rios s√£o exclu√≠das.
    """
    print("\n[bold yellow]‚ïî‚ïê‚ïê Unifica√ß√£o de Colunas DDD + N√∫mero ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o caminho do arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        # L√™ apenas o cabe√ßalho do arquivo para selecionar colunas
        columns = pd.read_excel(file_path, nrows=0).columns.tolist()
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o cabe√ßalho do arquivo: {e}[bold red]\n")
        return

    # Seleciona as colunas necess√°rias
    ddd_column = inquirer.select(
        message="Selecione a coluna do DDD:",
        choices=columns
    ).execute()

    number_column = inquirer.select(
        message="Selecione a coluna do n√∫mero:",
        choices=columns
    ).execute()

    print("\n[cyan]Unificando colunas DDD e N√∫mero...[/cyan]")

    try:
        # L√™ o arquivo completo
        df = pd.read_excel(file_path)

        # Filtros de valida√ß√£o
        def is_valid_ddd(value):
            return isinstance(value, str) and value.isdigit() and len(value) == 2

        def is_valid_number(value):
            return isinstance(value, str) and value.isdigit() and len(value) == 9

        # Aplica filtros de valida√ß√£o
        df["VALIDO"] = df[ddd_column].astype(str).apply(is_valid_ddd) & \
                       df[number_column].astype(str).apply(is_valid_number)

        df_valid = df[df["VALIDO"]].copy()  # Linhas v√°lidas
        df_invalid = df[~df["VALIDO"]].copy()  # Linhas inv√°lidas

        # Remove a coluna auxiliar "VALIDO"
        df_valid.drop(columns=["VALIDO"], inplace=True)
        df_invalid.drop(columns=["VALIDO"], inplace=True)

        # Cria a nova coluna unificada para linhas v√°lidas
        df_valid["DDD+N√∫mero"] = df_valid[ddd_column].astype(str).str.strip() + \
                                 df_valid[number_column].astype(str).str.strip()

    except Exception as e:
        print(f"[bold red]‚úó Erro ao processar o arquivo: {e}[bold red]\n")
        return

    # Pergunta o diret√≥rio para salvar os arquivos
    output_dir = inquirer.text(
        message="Digite o caminho para salvar os arquivos formatados:"
    ).execute()

    # Caminhos para os arquivos de sa√≠da
    valid_output_file = os.path.join(output_dir, f"merged_ddd_number_validos_{os.path.basename(file_path)}")
    invalid_output_file = os.path.join(output_dir, f"merged_ddd_number_invalidos_{os.path.basename(file_path)}")

    # Salva os arquivos
    try:
        df_valid.to_excel(valid_output_file, index=False)
        df_invalid.to_excel(invalid_output_file, index=False)
        print(f"\n[bold green]‚úì Arquivo salvo com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo com n√∫meros v√°lidos salvo em: {valid_output_file}[dim]")
        print(f"[dim]üìÅ Arquivo com n√∫meros inv√°lidos salvo em: {invalid_output_file}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar os arquivos: {e}[bold red]\n")

def format_numbers_with_prefix():
    """
    Adiciona o prefixo '55' a n√∫meros que tenham exatamente 11 d√≠gitos
    em uma ou mais colunas selecionadas. Mant√©m todas as linhas e
    s√≥ altera o valor da(s) coluna(s) escolhida(s).
    """

    import os
    import pandas as pd
    from InquirerPy import inquirer
    from pathlib import Path
    from rich.progress import track

    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Adi√ß√£o de Prefixo '55' a N√∫meros de 11 D√≠gitos ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # 1) Recebe caminho do arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo (XLSX ou CSV):"
    ).execute()

    if not os.path.isfile(file_path):
        print(f"[bold red]‚úó O caminho '{file_path}' n√£o √© um arquivo v√°lido![bold red]")
        return

    # Fun√ß√£o auxiliar para carregar XLSX ou CSV
    def load_file_generic(file_path):
        if file_path.lower().endswith(".xlsx"):
            return pd.read_excel(file_path, engine="openpyxl", dtype=str)
        elif file_path.lower().endswith(".csv"):
            # Tenta primeiro separador ;
            try:
                return pd.read_csv(file_path, sep=';', dtype=str)
            except:
                return pd.read_csv(file_path, sep=',', dtype=str)
        else:
            raise ValueError("Formato de arquivo n√£o suportado! Use .xlsx ou .csv.")

    # Carrega o DataFrame (tudo como string)
    try:
        df = load_file_generic(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar arquivo: {e}[/bold red]")
        return

    if df.empty:
        print("[bold red]‚úó O arquivo est√° vazio ou n√£o possui dados v√°lidos.[bold red]")
        return

    # 2) Usu√°rio seleciona colunas (m√∫ltiplas)
    print("\n[cyan]Selecione as colunas onde deseja adicionar o prefixo '55' (valores com 11 d√≠gitos)...[/cyan]")
    selected_columns = []
    while True:
        remaining_cols = [c for c in df.columns if c not in selected_columns]
        if not remaining_cols:
            break

        want_more = inquirer.confirm(
            message="Deseja selecionar mais uma coluna?",
            default=True
        ).execute()

        if not want_more and not selected_columns:
            print("[bold red]‚úó √â preciso selecionar ao menos uma coluna para continuar.[bold red]")
            return
        if not want_more:
            break

        chosen_col = inquirer.select(
            message="Selecione a coluna de n√∫meros:",
            choices=remaining_cols
        ).execute()
        selected_columns.append(chosen_col)

    if not selected_columns:
        print("[bold yellow]Nenhuma coluna foi selecionada. Encerrando...[bold yellow]")
        return

    # 3) Para cada coluna, exibimos um exemplo n√£o vazio para confirmar
    for col in selected_columns:
        example_val = None
        for idx, val in df[col].items():
            if pd.notna(val) and val.strip():
                example_val = val.strip()
                break

        if example_val:
            print(f"\n[cyan]Exemplo de valor na coluna '{col}':[/cyan] {example_val}")
            confirm_col = inquirer.confirm(
                message="Confirmar que esta coluna cont√©m n√∫meros de telefone?",
                default=True
            ).execute()
            if not confirm_col:
                print(f"[bold red]Removendo coluna '{col}' da lista de formata√ß√µes.[bold red]")
                selected_columns.remove(col)
        else:
            print(f"[bold yellow]A coluna '{col}' n√£o possui valores preenchidos para exemplificar.[bold yellow]")

    if not selected_columns:
        print("[bold yellow]Nenhuma coluna confirmada. Encerrando...[bold yellow]")
        return

    # 4) Aplica a formata√ß√£o (adicionando '55' a quem tiver 11 d√≠gitos)
    def add_55_prefix(value):
        if pd.isna(value):
            return value
        v = str(value).strip()
        # Se for exatamente 11 d√≠gitos
        if len(v) == 11 and v.isdigit():
            return '55' + v
        return v

    total_rows = len(df)
    changed_count = 0

    for col in selected_columns:
        for idx in track(df.index, description=f"[cyan]Formatando coluna '{col}'...[/cyan]"):
            old_val = df.at[idx, col]
            new_val = add_55_prefix(old_val)
            if new_val != old_val:
                df.at[idx, col] = new_val
                changed_count += 1

    # 5) Pergunta onde salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo formatado:"
    ).execute()

    if not os.path.isdir(output_dir):
        print(f"[bold red]‚úó O caminho '{output_dir}' n√£o √© uma pasta v√°lida![bold red]")
        return

    # Monta nome de sa√≠da (mantendo formato original)
    base_stem = Path(file_path).stem
    ext = Path(file_path).suffix
    output_name = f"num_format_{base_stem}{ext}"
    output_path = os.path.join(output_dir, output_name)

    try:
        if file_path.lower().endswith(".xlsx"):
            df.to_excel(output_path, index=False, engine="openpyxl")
        else:
            df.to_csv(output_path, sep=';', index=False, encoding='utf-8')
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[/bold red]")
        return

    # 6) Exibe resumo
    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Total de linhas no arquivo:[/white] {total_rows:,}")
    print(f"[white]‚ñ∫ Colunas de telefone formatadas:[/white] {', '.join(selected_columns)}")
    print(f"[white]‚ñ∫ N√∫meros convertidos para '55' + 11 d√≠gitos:[/white] {changed_count:,}")
    print(f"[dim]üìÅ Arquivo salvo em: {output_path}[/dim]\n")


def validar_numeros_celular():
    from rich.console import Console
    from rich.progress import Progress
    console = Console()

    """
    Valida n√∫meros de celular em uma coluna espec√≠fica.
    - N√∫meros v√°lidos: exatamente 11 d√≠gitos.
    - Separa n√∫meros v√°lidos e inv√°lidos em planilhas diferentes.
    - Gera arquivos contendo apenas CPFs com n√∫meros v√°lidos e inv√°lidos.
    """
    console.print("\n[bold yellow]‚ïî‚ïê‚ïê Valida√ß√£o de N√∫meros de Celular ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o caminho do arquivo Excel
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        # L√™ apenas o cabe√ßalho do arquivo para selecionar colunas
        columns = pd.read_excel(file_path, nrows=0).columns.tolist()
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao carregar o cabe√ßalho do arquivo: {e}[bold red]\n")
        return

    # Seleciona a coluna de n√∫meros de celular
    celular_column = inquirer.select(
        message="Selecione a coluna de n√∫meros de celular:",
        choices=columns
    ).execute()

    # Seleciona a coluna de CPF
    cpf_column = inquirer.select(
        message="Selecione a coluna de CPF:",
        choices=columns
    ).execute()

    try:
        # L√™ o arquivo Excel e mant√©m apenas as colunas selecionadas
        df = pd.read_excel(file_path, usecols=[cpf_column, celular_column], dtype=str)

        # Converte o DataFrame para CSV apenas com as colunas selecionadas
        csv_file_path = file_path.replace(".xlsx", "_cpf_celular.csv")
        df.to_csv(csv_file_path, index=False, sep=';', encoding='utf-8')
        console.print(f"[cyan]‚úì Arquivo convertido para CSV: {csv_file_path}[cyan]\n")
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[bold red]\n")
        return

    console.print("\n[cyan]Validando n√∫meros de celular...[/cyan]")

    try:
        # L√™ o arquivo CSV completo
        df = pd.read_csv(csv_file_path, sep=';', dtype=str)

        # Fun√ß√£o de valida√ß√£o para n√∫meros de celular
        def is_valid_number(value):
            if pd.isna(value):
                return False
            value = str(value).strip()
            return value.isdigit() and len(value) == 11

        # Aplica a valida√ß√£o com barra de progresso
        with Progress() as progress:
            task = progress.add_task("Validando n√∫meros", total=len(df))
            df["VALIDO"] = df[celular_column].apply(lambda x: is_valid_number(x))
            progress.update(task, advance=len(df))

        # Separa n√∫meros v√°lidos e inv√°lidos, mantendo apenas a coluna CPF
        df_validos = df[df["VALIDO"] == True][[cpf_column]].copy()
        df_invalidos = df[df["VALIDO"] == False][[cpf_column]].copy()

        # Resumo da valida√ß√£o
        linhas_validas = len(df_validos)
        linhas_invalidas = len(df_invalidos)

        console.print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Valida√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
        console.print(f"[white]‚ñ∫ CPFs com n√∫meros v√°lidos:[/white] {linhas_validas:,}")
        console.print(f"[white]‚ñ∫ CPFs com n√∫meros inv√°lidos:[/white] {linhas_invalidas:,}")

        # Pergunta o diret√≥rio para salvar os arquivos
        output_dir = inquirer.text(
            message="Digite o caminho para salvar os arquivos filtrados:"
        ).execute()

        # Caminhos para os arquivos de sa√≠da
        valid_output_file = os.path.join(output_dir, f"Valido_{os.path.basename(csv_file_path)}")
        invalid_output_file = os.path.join(output_dir, f"Invalido_{os.path.basename(csv_file_path)}")

        # Salva os arquivos com barra de progresso
        with Progress() as progress:
            task_save = progress.add_task("Salvando arquivos", total=2)

            try:
                df_validos.to_csv(valid_output_file, index=False, sep=';', encoding='utf-8')
                progress.update(task_save, advance=1)
                df_invalidos.to_csv(invalid_output_file, index=False, sep=';', encoding='utf-8')
                progress.update(task_save, advance=1)

                console.print(f"\n[bold green]‚úì Arquivos salvos com sucesso![bold green]")
                console.print(f"[dim]üìÅ Arquivo com n√∫meros v√°lidos salvo em: {valid_output_file}[dim]")
                console.print(f"[dim]üìÅ Arquivo com n√∫meros inv√°lidos salvo em: {invalid_output_file}[dim]\n")
            except Exception as e:
                console.print(f"[bold red]‚úó Erro ao salvar os arquivos: {e}[bold red]\n")
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao processar o arquivo: {e}[bold red]\n")



def formatar_numeros_para_11_digitos():
    """
    Formata n√∫meros de celular para 11 d√≠gitos.
    - N√∫meros com 12 d√≠gitos: remove o √∫ltimo d√≠gito (zero extra no final).
    - O cabe√ßalho do arquivo √© lido diretamente do XLSX para identificar as colunas.
    - O CSV √© usado para manipula√ß√£o dos dados e o arquivo final √© salvo em XLSX.
    """
    print("\n[bold yellow]‚ïî‚ïê‚ïê Formata√ß√£o de N√∫meros para 11 D√≠gitos ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # Recebe o caminho do arquivo Excel
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel (.xlsx):"
    ).execute()

    try:
        # L√™ apenas a primeira linha para obter o cabe√ßalho
        df_header = pd.read_excel(file_path, nrows=1, engine="openpyxl")
        header = df_header.columns.tolist()
        if not header:
            print("[bold red]‚úó O arquivo n√£o possui cabe√ßalho v√°lido.[bold red]\n")
            return
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o cabe√ßalho do arquivo: {e}[bold red]\n")
        return

    # Mapeia as colunas para suas posi√ß√µes (exemplo: A, B, C, etc.)
    column_positions = [f"{chr(65 + i)}" for i in range(len(header))]
    choices = [f"{col_positions} - {header[i]}" for i, col_positions in enumerate(column_positions)]

    # Usu√°rio seleciona a coluna com base na posi√ß√£o
    selected_column_choice = inquirer.select(
        message="Selecione a coluna de n√∫meros de celular:",
        choices=choices
    ).execute()

    # Extrai o √≠ndice da coluna selecionada
    column_index = choices.index(selected_column_choice)
    column_name = header[column_index]

    try:
        # L√™ apenas a segunda linha do arquivo para validar o conte√∫do
        df_sample = pd.read_excel(file_path, nrows=2, engine="openpyxl")
        second_row_value = df_sample.iloc[1, column_index]
        print(f"\n[cyan]Conte√∫do da c√©lula A2 (coluna '{column_name}'): {second_row_value}[cyan]\n")

        confirm = inquirer.confirm(
            message=f"Essa √© a coluna correta para '{column_name}'?",
            default=True
        ).execute()

        if not confirm:
            print("[bold red]‚úó Opera√ß√£o cancelada pelo usu√°rio.[bold red]\n")
            return

    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar a segunda linha do arquivo: {e}[bold red]\n")
        return

    print("\n[cyan]Convertendo arquivo para CSV para otimizar a manipula√ß√£o...[/cyan]")

    try:
        # Converte o arquivo completo para CSV
        csv_file_path = file_path.replace(".xlsx", ".csv")
        df = pd.read_excel(file_path, engine="openpyxl")
        df.to_csv(csv_file_path, index=False, encoding='utf-8')
        print(f"[cyan]‚úì Arquivo convertido para CSV: {csv_file_path}[cyan]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao converter o arquivo para CSV: {e}[bold red]\n")
        return

    print("\n[cyan]Formatando n√∫meros de celular...[/cyan]")

    try:
        # L√™ o CSV completo
        df = pd.read_csv(csv_file_path, dtype=str)

        # Fun√ß√£o para formatar n√∫meros
        def format_number(value):
            value = str(value).strip()
            if value.isdigit() and len(value) == 12:
                return value[:-1]  # Remove o √∫ltimo d√≠gito
            return value  # Retorna o valor original

        # Aplica a formata√ß√£o na coluna selecionada
        df[column_name] = df[column_name].apply(format_number)

        # Pergunta o diret√≥rio para salvar o arquivo formatado
        output_dir = inquirer.text(
            message="Digite o caminho para salvar o arquivo formatado:"
        ).execute()

        # Caminho do arquivo de sa√≠da em CSV
        formatted_csv_path = os.path.join(output_dir, f"formatado_11_digitos_{os.path.basename(csv_file_path)}")

        # Salva o arquivo formatado como CSV
        df.to_csv(formatted_csv_path, index=False, encoding='utf-8')
        print(f"[cyan]‚úì Arquivo formatado salvo como CSV: {formatted_csv_path}[cyan]\n")

        # Converte o CSV final para XLSX
        final_xlsx_path = formatted_csv_path.replace(".csv", ".xlsx")
        df.to_excel(final_xlsx_path, index=False)
        print(f"\n[bold green]‚úì Arquivo final salvo como XLSX:[bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {final_xlsx_path}[dim]\n")

    except Exception as e:
        print(f"[bold red]‚úó Erro ao processar o arquivo: {e}[bold red]\n")


def remover_duplicatas_cpfs():
    """
    Recebe um arquivo XLSX ou CSV, seleciona a coluna de CPF, normaliza e remove duplicatas.
    Mant√©m a primeira ocorr√™ncia de cada CPF, ignorando as linhas subsequentes duplicadas.
    Agora com fallback de encoding para CSV.
    """

    import os
    import pandas as pd
    from InquirerPy import inquirer
    from rich.console import Console
    console = Console()

    console.print("\n[bold yellow]‚ïî‚ïê‚ïê Remo√ß√£o de Duplicatas por CPF ‚ïê‚ïê‚ïó[/bold yellow]\n")

    def load_file_generic(file_path):
        """
        Carrega XLSX ou CSV (tentando ; depois ,) sempre como string (dtype=str).
        Se for CSV, tenta utf-8 primeiro. Se falhar, tenta latin-1.
        """
        if file_path.lower().endswith(".xlsx"):
            return pd.read_excel(file_path, engine="openpyxl", dtype=str)
        elif file_path.lower().endswith(".csv"):
            # Tentar com UTF-8
            try:
                # Primeiro ; depois ,
                try:
                    return pd.read_csv(file_path, sep=';', dtype=str, encoding='utf-8')
                except UnicodeDecodeError:
                    return pd.read_csv(file_path, sep=';', dtype=str, encoding='latin-1')
            except Exception:
                # Se ainda falhar, tentamos sep=','
                try:
                    return pd.read_csv(file_path, sep=',', dtype=str, encoding='utf-8')
                except UnicodeDecodeError:
                    return pd.read_csv(file_path, sep=',', dtype=str, encoding='latin-1')
        else:
            raise ValueError("Formato de arquivo n√£o suportado. Use .xlsx ou .csv.")

    # 1) Recebe o caminho do arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo (.xlsx ou .csv):"
    ).execute()

    if not os.path.isfile(file_path):
        console.print(f"[bold red]‚úó O caminho '{file_path}' n√£o √© um arquivo v√°lido![bold red]\n")
        return

    # 2) Tenta carregar
    try:
        df = load_file_generic(file_path)
        if df.empty:
            console.print("[bold red]‚úó O arquivo est√° vazio ou n√£o cont√©m dados v√°lidos.[bold red]\n")
            return
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[bold red]\n")
        return

    # 3) Seleciona a coluna de CPF
    cpf_column = inquirer.select(
        message="Selecione a coluna de CPF no arquivo:",
        choices=df.columns.tolist()
    ).execute()

    console.print("\n[cyan]Normalizando CPFs...[/cyan]")

    try:
        # Remove tudo que n√£o for d√≠gito e for√ßa 11 d√≠gitos com zfill
        df[cpf_column] = (
            df[cpf_column]
            .astype(str)
            .str.replace(r'\D', '', regex=True)
            .str.zfill(11)
        )

        # Remove duplicatas mantendo a primeira ocorr√™ncia
        df_deduplicated = df.drop_duplicates(subset=[cpf_column], keep='first')

    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao normalizar ou remover duplicatas: {e}[bold red]\n")
        return

    # Resumo da opera√ß√£o
    total_linhas = len(df)
    total_linhas_unicas = len(df_deduplicated)
    duplicatas_removidas = total_linhas - total_linhas_unicas

    console.print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Remo√ß√£o de Duplicatas ‚ïê‚ïê‚ïó[/bold green]")
    console.print(f"[white]‚ñ∫ Total de linhas no arquivo original:[/white] {total_linhas:,}")
    console.print(f"[white]‚ñ∫ Linhas √∫nicas (sem duplicatas):[/white]      {total_linhas_unicas:,}")
    console.print(f"[white]‚ñ∫ Duplicatas removidas:[/white]              {duplicatas_removidas:,}")

    # 4) Pergunta onde salvar o arquivo final
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo sem duplicatas:"
    ).execute()

    if not os.path.isdir(output_dir):
        console.print(f"[bold red]‚úó O caminho '{output_dir}' n√£o √© uma pasta v√°lida![bold red]\n")
        return

    # Define o caminho de sa√≠da
    base_name = os.path.basename(file_path)  # ex: "dados.xlsx"
    output_file = os.path.join(output_dir, f"sem_duplicatas_{base_name}")

    console.print("\n[cyan]Salvando arquivo final...[/cyan]")
    try:
        if file_path.lower().endswith(".xlsx"):
            df_deduplicated.to_excel(output_file, index=False, engine="openpyxl")
        else:
            # CSV, usaremos sep=';' e utf-8 ao salvar
            df_deduplicated.to_csv(output_file, index=False, sep=';', encoding='utf-8')
        console.print(f"\n[bold green]‚úì Arquivo salvo com sucesso![bold green]")
        console.print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[bold red]\n")

def remover_duplicatas_phones():
    """
    Remove duplicatas com base em uma coluna de telefone.
    1) Carrega XLSX ou CSV como string (fallback de encoding).
    2) Usu√°rio seleciona a coluna de telefone.
    3) Mostra a primeira linha n√£o vazia como exemplo p/ confirmar.
    4) Remove duplicatas mantendo a primeira ocorr√™ncia.
    5) Exibe resumo e salva o resultado.
    """

    import os
    import pandas as pd
    from InquirerPy import inquirer
    from rich.console import Console
    console = Console()

    console.print("\n[bold yellow]‚ïî‚ïê‚ïê Remo√ß√£o de Duplicatas por Telefone ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # --------------------- Fun√ß√£o auxiliar p/ carregar XLSX ou CSV --------------------- #
    def load_file_generic(file_path):
        """
        Carrega XLSX ou CSV (tentando ; depois ,) sempre como string (dtype=str).
        Se for CSV, tenta utf-8 primeiro. Se der UnicodeDecodeError, tenta latin-1.
        """
        if file_path.lower().endswith(".xlsx"):
            return pd.read_excel(file_path, engine="openpyxl", dtype=str)
        elif file_path.lower().endswith(".csv"):
            # Tenta com UTF-8 + sep=';'
            try:
                try:
                    return pd.read_csv(file_path, sep=';', dtype=str, encoding='utf-8')
                except UnicodeDecodeError:
                    return pd.read_csv(file_path, sep=';', dtype=str, encoding='latin-1')
            except Exception:
                # Se ainda falhar, tentamos sep=','
                try:
                    try:
                        return pd.read_csv(file_path, sep=',', dtype=str, encoding='utf-8')
                    except UnicodeDecodeError:
                        return pd.read_csv(file_path, sep=',', dtype=str, encoding='latin-1')
                except Exception as e:
                    raise e
        else:
            raise ValueError("Formato de arquivo n√£o suportado. Use .xlsx ou .csv.")

    # 1) Recebe o caminho do arquivo
    file_path = inquirer.text(
        message="Digite o caminho do arquivo (.xlsx ou .csv):"
    ).execute()

    if not os.path.isfile(file_path):
        console.print(f"[bold red]‚úó O caminho '{file_path}' n√£o √© um arquivo v√°lido![bold red]\n")
        return

    # 2) Carrega o arquivo
    try:
        df = load_file_generic(file_path)
        if df.empty or df.columns.empty:
            console.print("[bold red]‚úó O arquivo est√° vazio ou n√£o cont√©m dados v√°lidos.[bold red]\n")
            return
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[bold red]\n")
        return

    # 3) Usu√°rio seleciona a coluna de telefone
    phone_col = inquirer.select(
        message="Selecione a coluna de telefone no arquivo:",
        choices=df.columns.tolist()
    ).execute()

    # Mostra a primeira linha n√£o vazia como exemplo
    example_value = None
    for _, val in df[phone_col].items():
        if pd.notna(val) and val.strip():
            example_value = val.strip()
            break

    if example_value:
        console.print(f"\n[cyan]Exemplo de valor encontrado na coluna '{phone_col}':[/cyan] {example_value}")
        confirm_col = inquirer.confirm(
            message="Confirma que esta √© realmente a coluna de telefone?",
            default=True
        ).execute()
        if not confirm_col:
            console.print("[bold red]Opera√ß√£o cancelada, coluna n√£o confirmada como telefone.[bold red]\n")
            return
    else:
        console.print(f"[bold yellow]A coluna '{phone_col}' n√£o possui valores preenchidos para exemplificar.[bold yellow]")

    console.print("\n[cyan]Removendo duplicatas com base na coluna selecionada...[/cyan]")

    try:
        # Converte a coluna em string e strip
        df[phone_col] = df[phone_col].astype(str).str.strip()

        # Remove duplicatas, mantendo a 1¬™ ocorr√™ncia
        df_deduplicated = df.drop_duplicates(subset=[phone_col], keep='first')

    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao remover duplicatas: {e}[bold red]\n")
        return

    total_linhas = len(df)
    total_unicas = len(df_deduplicated)
    removidas = total_linhas - total_unicas

    console.print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Remo√ß√£o de Duplicatas ‚ïê‚ïê‚ïó[/bold green]")
    console.print(f"[white]‚ñ∫ Total de linhas no arquivo original:[/white] {total_linhas:,}")
    console.print(f"[white]‚ñ∫ Linhas √∫nicas (sem duplicatas):[/white]      {total_unicas:,}")
    console.print(f"[white]‚ñ∫ Duplicatas removidas:[/white]              {removidas:,}")

    # 4) Pergunta onde salvar o arquivo final
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo sem duplicatas:"
    ).execute()

    if not os.path.isdir(output_dir):
        console.print(f"[bold red]‚úó O caminho '{output_dir}' n√£o √© uma pasta v√°lida![bold red]\n")
        return

    # Define o caminho de sa√≠da
    base_name = os.path.basename(file_path)
    output_file = os.path.join(output_dir, f"sem_duplicatas_{base_name}")

    console.print("\n[cyan]Salvando arquivo final...[/cyan]")
    try:
        if file_path.lower().endswith(".xlsx"):
            df_deduplicated.to_excel(output_file, index=False, engine="openpyxl")
        else:
            df_deduplicated.to_csv(output_file, index=False, sep=';', encoding='utf-8')
        console.print(f"\n[bold green]‚úì Arquivo salvo com sucesso![bold green]")
        console.print(f"[dim]üìÅ Arquivo salvo em: {output_file}[dim]\n")
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao salvar o arquivo: {e}[bold red]\n")
        return



def unify_data_multiple_search_by_cpf_csv():
    """
    Unifica dados de um arquivo base (XLSX ou CSV) e m√∫ltiplos arquivos de pesquisa,
    combinando por CPF, gerando SEMPRE arquivos finais em CSV.

    Fluxo:
      1) Recebe caminho do arquivo base e seleciona a coluna de CPF.
      2) Normaliza os CPFs p/ 11 d√≠gitos.
      3) Pergunta se quer adicionar 1..N arquivos de pesquisa.
      4) Cada arquivo de pesquisa tamb√©m XLSX ou CSV; ao carregar:
         - Seleciona a coluna de CPF.
         - Normaliza CPFs.
         - Constr√≥i dict CPF->linha (primeira ocorr√™ncia).
         - Tenta casar esses CPFs com os ainda n√£o encontrados.
      5) Gera 2 arquivos CSV no fim:
         - 'cpf_corresp_{NOME_BASE}.csv': CPFs encontrados + colunas do arquivo de pesquisa
         - 'semnada_{NOME_BASE}.csv': CPFs n√£o encontrados em lugar nenhum
    """
    import os
    import pandas as pd
    from InquirerPy import inquirer

    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Unifica√ß√£o M√∫ltipla por CPF (Sa√≠da CSV) ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # 1) Carrega arquivo base
    base_file_path = inquirer.text(
        message="Digite o caminho do arquivo base (XLSX ou CSV):"
    ).execute()

    def load_any_file_to_df(file_path):
        """
        Carrega XLSX ou CSV para um DataFrame (for√ßando string).
        Se for CSV, tenta primeiro ; depois ,.
        """
        if file_path.lower().endswith(".xlsx"):
            return pd.read_excel(file_path, engine="openpyxl", dtype=str)
        elif file_path.lower().endswith(".csv"):
            try:
                return pd.read_csv(file_path, sep=';', dtype=str)
            except:
                return pd.read_csv(file_path, sep=',', dtype=str)
        else:
            raise ValueError("Formato de arquivo n√£o suportado! Use .xlsx ou .csv.")

    # Tenta carregar
    try:
        base_df = load_any_file_to_df(base_file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar arquivo base: {e}[/bold red]\n")
        return

    if base_df.empty:
        print("[bold red]‚úó O arquivo base est√° vazio ou n√£o possui dados v√°lidos.[/bold red]\n")
        return

    # Seleciona a coluna de CPF no arquivo base
    base_cpf_column = inquirer.select(
        message="Selecione a coluna de CPF no arquivo base:",
        choices=base_df.columns.tolist()
    ).execute()

    # Fun√ß√£o de normalizar CPFs
    def normalize_cpf(cpf):
        digits = "".join(ch for ch in str(cpf) if ch.isdigit())
        return digits.zfill(11)

    print("[cyan]Normalizando CPFs do arquivo base...[/cyan]")
    base_df[base_cpf_column] = base_df[base_cpf_column].apply(normalize_cpf)

    # Monta conjunto com todos os CPFs n√£o encontrados ainda
    unmatched_cpfs = set(base_df[base_cpf_column].unique())

    # Lista (de dicion√°rios) das linhas correspondidas
    matched_rows = []

    # 2) Loop para adicionar arquivos de pesquisa
    while True:
        add_more = inquirer.confirm(
            message="Deseja adicionar um arquivo de pesquisa?",
            default=True
        ).execute()

        if not add_more:
            break

        pesquisa_path = inquirer.text(
            message="Digite o caminho do arquivo de pesquisa (XLSX ou CSV):"
        ).execute()

        # Carrega o arquivo de pesquisa
        try:
            pesquisa_df = load_any_file_to_df(pesquisa_path)
        except Exception as e:
            print(f"[bold red]‚úó Erro ao carregar arquivo de pesquisa: {e}[/bold red]\n")
            continue

        if pesquisa_df.empty:
            print("[bold red]‚úó O arquivo de pesquisa est√° vazio ou n√£o possui dados v√°lidos.[/bold red]\n")
            continue

        pesquisa_cpf_col = inquirer.select(
            message="Selecione a coluna de CPF no arquivo de pesquisa:",
            choices=pesquisa_df.columns.tolist()
        ).execute()

        # Normaliza CPF
        print(f"[cyan]Normalizando CPFs do arquivo: {pesquisa_path}[/cyan]")
        pesquisa_df[pesquisa_cpf_col] = pesquisa_df[pesquisa_cpf_col].apply(normalize_cpf)

        # Cria dicion√°rio CPF->linha (primeira ocorr√™ncia)
        dict_pesquisa = {}
        for idx, row_ in pesquisa_df.iterrows():
            cpf_val = row_[pesquisa_cpf_col]
            if cpf_val not in dict_pesquisa:
                dict_pesquisa[cpf_val] = row_

        # Agora, percorre apenas CPFs ainda n√£o encontrados
        still_unmatched = list(unmatched_cpfs)

        for cpf_ in still_unmatched:
            if cpf_ in dict_pesquisa:
                # Monta dict => CPF + colunas do arquivo de pesquisa
                matched_dict = {"CPF": cpf_}
                for col in pesquisa_df.columns:
                    if col != pesquisa_cpf_col:
                        matched_dict[col] = dict_pesquisa[cpf_][col]

                matched_rows.append(matched_dict)
                unmatched_cpfs.remove(cpf_)

        if not unmatched_cpfs:
            print("[bold green]Todos os CPFs j√° foram encontrados![/bold green]")
            break

    # 3) Monta DF final de correspond√™ncias
    if matched_rows:
        # Descobre colunas que apareceram
        all_cols = set()
        for dic in matched_rows:
            all_cols.update(dic.keys())
        all_cols = list(all_cols)

        matched_df = pd.DataFrame(matched_rows, columns=all_cols)
        # Se quiser CPF na frente
        if "CPF" in all_cols:
            col_sem_cpf = [c for c in all_cols if c != "CPF"]
            matched_df = matched_df[["CPF"] + col_sem_cpf]
    else:
        matched_df = pd.DataFrame(columns=["CPF"])

    # 4) Monta DF de n√£o encontrados
    if unmatched_cpfs:
        unmatched_df = pd.DataFrame(list(unmatched_cpfs), columns=["CPF"])
    else:
        unmatched_df = pd.DataFrame(columns=["CPF"])

    # 5) Pergunta onde salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar os arquivos de sa√≠da (em CSV):"
    ).execute()

    # Extrai s√≥ o "nome" base do arquivo sem extens√£o
    from pathlib import Path
    base_stem = Path(base_file_path).stem  # ex: se for "dados.xlsx", vira "dados"
    
    matched_file_name = os.path.join(output_dir, f"cpf_corresp_{base_stem}.csv")
    unmatched_file_name = os.path.join(output_dir, f"semnada_{base_stem}.csv")

    # 6) Salva TUDO como CSV
    try:
        matched_df.to_csv(matched_file_name, index=False, sep=';', encoding='utf-8')
        unmatched_df.to_csv(unmatched_file_name, index=False, sep=';', encoding='utf-8')
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar arquivos de sa√≠da: {e}[/bold red]\n")
        return

    # 7) Resumo
    total_base_cpfs = len(base_df)
    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Total de CPFs no arquivo base:[/white] {total_base_cpfs:,}")
    print(f"[white]‚ñ∫ Correspond√™ncias encontradas:[/white]   {len(matched_df):,}")
    print(f"[white]‚ñ∫ Sem correspond√™ncia:[/white]            {len(unmatched_df):,}")
    print(f"[white]‚ñ∫ Arquivos de pesquisa usados:[/white]    (depende de quantos adicionados)")

    print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![/bold green]")
    print(f"[dim]üìÅ Arquivo com correspond√™ncias salvo em: {matched_file_name}[/dim]")
    print(f"[dim]üìÅ Arquivo sem correspond√™ncia salvo em:  {unmatched_file_name}[/dim]\n")



def validate_multiple_phone_columns_simple_split():
    """
    Gera dois arquivos:
      1) Arquivo com todas as linhas onde a PRIMEIRA coluna de telefone √© v√°lida
      2) Arquivo com todas as linhas onde a PRIMEIRA coluna de telefone √© inv√°lida

    Valida√ß√£o de n√∫mero:
      - Remove caracteres n√£o num√©ricos
      - Deve ter exatamente 11 d√≠gitos
    """

    import os
    import pandas as pd
    from InquirerPy import inquirer
    from rich import print

    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Separa√ß√£o de Linhas por Telefone (Coluna 1) ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # 1) Recebe o caminho do arquivo (XLSX ou CSV)
    file_path = inquirer.text(
        message="Digite o caminho do arquivo Excel ou CSV:"
    ).execute()

    # Fun√ß√£o auxiliar para carregar XLSX ou CSV com fallback de encoding
    def load_file_generic(fp):
        if fp.lower().endswith(".xlsx"):
            return pd.read_excel(fp, engine="openpyxl", dtype=str)  # for√ßa leitura como string
        elif fp.lower().endswith(".csv"):
            # Tentamos primeiro com sep=';' e encoding='utf-8'
            try:
                try:
                    return pd.read_csv(fp, sep=';', dtype=str, encoding='utf-8')
                except UnicodeDecodeError:
                    # Se falhar, tentamos latin-1
                    return pd.read_csv(fp, sep=';', dtype=str, encoding='latin-1')
            except:
                # Se ainda falhar, tentamos sep=',' e repetimos encoding
                try:
                    try:
                        return pd.read_csv(fp, sep=',', dtype=str, encoding='utf-8')
                    except UnicodeDecodeError:
                        return pd.read_csv(fp, sep=',', dtype=str, encoding='latin-1')
                except Exception as e:
                    raise e
        else:
            raise ValueError("Formato de arquivo n√£o suportado! Use .xlsx ou .csv.")

    # Tenta carregar o arquivo
    try:
        df = load_file_generic(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[/bold red]\n")
        return

    if df.empty or df.columns.empty:
        print("[bold red]‚úó O arquivo n√£o possui cabe√ßalhos ou est√° vazio.[/bold red]\n")
        return

    all_columns = df.columns.tolist()

    # 2) Deixa o usu√°rio selecionar UMA OU MAIS colunas, mas s√≥ a primeira influenciar√° a divis√£o
    selected_columns = []
    while True:
        remaining_columns = [col for col in all_columns if col not in selected_columns]
        if not remaining_columns:
            break

        should_continue = inquirer.confirm(
            message="Deseja selecionar mais uma coluna de telefone?",
            default=True
        ).execute()

        if not should_continue and not selected_columns:
            print("[bold red]‚úó √â preciso selecionar pelo menos uma coluna para prosseguir.[/bold red]")
            return

        if not should_continue:
            break

        chosen_column = inquirer.select(
            message="Selecione a coluna de telefone:",
            choices=remaining_columns
        ).execute()

        selected_columns.append(chosen_column)

    # Se o usu√°rio n√£o selecionou nada, encerra
    if not selected_columns:
        return

    print("\n[cyan]Separando linhas v√°lidas e inv√°lidas com base na PRIMEIRA coluna selecionada...[/cyan]")

    # 3) Define fun√ß√£o para verificar se o n√∫mero √© v√°lido (remover n√£o num√©ricos e ter 11 d√≠gitos)
    def is_valid_phone(value):
        if pd.isna(value):
            return False
        clean = "".join(ch for ch in str(value) if ch.isdigit())
        return len(clean) == 11

    # 4) Cria uma m√°scara booleana: se a PRIMEIRA coluna de telefone for v√°lida => True
    first_phone_col = selected_columns[0]
    mask_valid = df[first_phone_col].apply(is_valid_phone)

    # 5) Separa em dois DataFrames
    df_valid = df[mask_valid].copy()
    df_invalid = df[~mask_valid].copy()

    # Exibe estat√≠sticas
    total_rows = len(df)
    valid_count = len(df_valid)
    invalid_count = len(df_invalid)

    print(f"[cyan]‚Üí Coluna principal de telefone usada: [bold]{first_phone_col}[/bold][/cyan]\n")

    # 6) Pergunta diret√≥rio de sa√≠da
    output_dir = inquirer.text(
        message="Digite o caminho para salvar os arquivos de sa√≠da:"
    ).execute()

    if not os.path.isdir(output_dir):
        print(f"[bold red]‚úó O caminho '{output_dir}' n√£o √© uma pasta v√°lida.[/bold red]\n")
        return

    # Gera nomes de sa√≠da, mudando somente o prefixo
    base_name = os.path.basename(file_path)
    valid_file = os.path.join(output_dir, f"val_mult_phone_valid_{base_name}")
    invalid_file = os.path.join(output_dir, f"val_mult_phone_invalid_{base_name}")

    # 7) Salva cada DataFrame no formato original (XLSX ou CSV)
    try:
        if file_path.lower().endswith(".xlsx"):
            df_valid.to_excel(valid_file, index=False, engine="openpyxl")
            df_invalid.to_excel(invalid_file, index=False, engine="openpyxl")
        else:
            # CSV => salvamos com ; e utf-8
            df_valid.to_csv(valid_file, index=False, sep=';', encoding='utf-8')
            df_invalid.to_csv(invalid_file, index=False, sep=';', encoding='utf-8')
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar os arquivos: {e}[/bold red]\n")
        return

    # 8) Exibe um resumo
    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Opera√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Total de linhas no arquivo:[/white]      {total_rows:,}")
    print(f"[white]‚ñ∫ Linhas com n√∫mero V√ÅLIDO (coluna {first_phone_col}):[/white] {valid_count:,}")
    print(f"[white]‚ñ∫ Linhas com n√∫mero INV√ÅLIDO (coluna {first_phone_col}):[/white] {invalid_count:,}")
    print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
    print(f"[dim]üìÅ Arquivo com v√°lidos:   {valid_file}[dim]")
    print(f"[dim]üìÅ Arquivo com inv√°lidos: {invalid_file}[dim]\n")


def apply_blacklist_phones():
    """
    Aplica uma blacklist de celulares por CPF.
    
    L√≥gica:
      1) Recebe um arquivo base (XLSX ou CSV).
         - Usu√°rio seleciona coluna de CPF e de numero_celular.
      2) Recebe um arquivo blacklist (XLSX ou CSV).
         - Usu√°rio seleciona coluna de CPF e de numero_celular.
      3) Para cada linha no arquivo de blacklist => se (CPF, numero) constar no base => 
         substitui o n√∫mero no base por '0'.
    """
    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Aplica√ß√£o de Blacklist de Celulares ‚ïê‚ïê‚ïó[/bold yellow]\n")

    import os
    import pandas as pd
    from InquirerPy import inquirer

    # --------------------- Fun√ß√£o auxiliar de carregamento --------------------- #
    def load_file_generic(file_path):
        """
        Carrega XLSX ou CSV (tentando ; depois ,) e retorna DataFrame com strings.
        """
        if file_path.lower().endswith(".xlsx"):
            return pd.read_excel(file_path, engine="openpyxl", dtype=str)
        elif file_path.lower().endswith(".csv"):
            try:
                return pd.read_csv(file_path, sep=';', dtype=str)
            except:
                return pd.read_csv(file_path, sep=',', dtype=str)
        else:
            raise ValueError("Formato de arquivo n√£o suportado! Use .xlsx ou .csv.")

    # --------------------- Normaliza√ß√£o auxiliar --------------------- #
    def normalize_cpf(cpf):
        """Remove tudo que n√£o seja d√≠gito e zera √† esquerda para 11 caracteres."""
        digits = "".join(ch for ch in str(cpf) if ch.isdigit())
        return digits.zfill(11)

    def normalize_phone(phone):
        """Remove tudo que n√£o seja d√≠gito. (Opcional, se quiser unificar.)"""
        digits = "".join(ch for ch in str(phone) if ch.isdigit())
        return digits

    # --------------------- Passo 1: Carrega arquivo base --------------------- #
    base_file_path = inquirer.text(
        message="Digite o caminho do arquivo base (XLSX ou CSV):"
    ).execute()

    try:
        base_df = load_file_generic(base_file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar arquivo base: {e}[/bold red]\n")
        return

    if base_df.empty:
        print("[bold red]‚úó O arquivo base est√° vazio ou n√£o possui dados v√°lidos.[/bold red]\n")
        return

    # Seleciona as colunas de CPF e celular
    base_cpf_col = inquirer.select(
        message="Selecione a coluna de CPF no arquivo base:",
        choices=base_df.columns.tolist()
    ).execute()

    base_phone_col = inquirer.select(
        message="Selecione a coluna de n√∫mero de celular no arquivo base:",
        choices=base_df.columns.tolist()
    ).execute()

    # Normaliza CPF e telefone no base (se desejar unificar)
    print("[cyan]Normalizando dados do arquivo base...[/cyan]")
    base_df[base_cpf_col] = base_df[base_cpf_col].apply(normalize_cpf)
    base_df[base_phone_col] = base_df[base_phone_col].apply(normalize_phone)

    # --------------------- Passo 2: Carrega arquivo blacklist --------------------- #
    blacklist_file_path = inquirer.text(
        message="Digite o caminho do arquivo de blacklist (XLSX ou CSV):"
    ).execute()

    try:
        black_df = load_file_generic(blacklist_file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar arquivo de blacklist: {e}[/bold red]\n")
        return

    if black_df.empty:
        print("[bold red]‚úó O arquivo blacklist est√° vazio ou n√£o possui dados v√°lidos.[/bold red]\n")
        return

    # Seleciona as colunas de CPF e celular no blacklist
    black_cpf_col = inquirer.select(
        message="Selecione a coluna de CPF no arquivo de blacklist:",
        choices=black_df.columns.tolist()
    ).execute()

    black_phone_col = inquirer.select(
        message="Selecione a coluna de n√∫mero de celular no arquivo de blacklist:",
        choices=black_df.columns.tolist()
    ).execute()

    # Normaliza CPF e telefone no blacklist (se desejar unificar)
    print("[cyan]Normalizando dados do arquivo blacklist...[/cyan]")
    black_df[black_cpf_col] = black_df[black_cpf_col].apply(normalize_cpf)
    black_df[black_phone_col] = black_df[black_phone_col].apply(normalize_phone)

    # --------------------- Passo 3: Cria estrutura para localizar combina√ß√µes (CPF, phone) --------------------- #
    print("[cyan]Criando conjunto de blacklist (CPF, phone)...[/cyan]")
    black_set = set()
    for idx, row_ in black_df.iterrows():
        c = row_[black_cpf_col]
        p = row_[black_phone_col]
        # Evita adicionar linhas com CPF vazio ou phone vazio, se quiser
        if c and p:
            black_set.add((c, p))

    print(f"[white]Total de combina√ß√µes (CPF, phone) na blacklist:[/white] {len(black_set):,}\n")

    # --------------------- Passo 4: Aplica blacklist no base --------------------- #
    print("[cyan]Comparando base com a blacklist...[/cyan]")
    from rich.progress import track

    total_rows = len(base_df)
    replaced_count = 0

    # Percorre cada linha da base; se (CPF, phone) estiver na blacklist => substitui por "0"
    for idx in track(base_df.index, description="[cyan]Processando base...[/cyan]"):
        cpf_val = base_df.at[idx, base_cpf_col]
        phone_val = base_df.at[idx, base_phone_col]
        if (cpf_val, phone_val) in black_set:
            # Substitui por '0'
            base_df.at[idx, base_phone_col] = "0"
            replaced_count += 1

    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Blacklist ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Linhas analisadas no arquivo base:[/white] {total_rows:,}")
    print(f"[white]‚ñ∫ Telefones substitu√≠dos por '0':[/white]   {replaced_count:,}")

    # --------------------- Passo 5: Pergunta onde salvar arquivo final --------------------- #
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo atualizado:"
    ).execute()

    # Define um nome final
    import os
    from pathlib import Path
    base_stem = Path(base_file_path).stem  # ex: "arquivo_base" se "arquivo_base.xlsx"

    # Vamos manter o mesmo formato do arquivo base
    base_ext = Path(base_file_path).suffix.lower()

    # Nome do arquivo final
    final_name = f"blacklist_aplicado_{base_stem}{base_ext}"
    final_path = os.path.join(output_dir, final_name)

    # --------------------- Salvar no mesmo formato do base --------------------- #
    try:
        if base_ext == ".xlsx":
            base_df.to_excel(final_path, index=False, engine="openpyxl")
        else:
            # pressupondo CSV
            base_df.to_csv(final_path, index=False, sep=';', encoding='utf-8')
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar arquivo final: {e}[/bold red]")
        return

    # --------------------- Conclus√£o --------------------- #
    print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![/bold green]")
    print(f"[dim]üìÅ Arquivo final salvo em: {final_path}[/dim]\n")

def merge_folder_files_to_csv():
    """
    1) Pergunta se o usu√°rio quer unificar arquivos XLSX ou CSV em uma pasta.
    2) Detecta colunas monet√°rias olhando a segunda linha (se existir) do primeiro arquivo n√£o-vazio.
    3) Carrega cada arquivo como string (com fallback de encoding para CSV), converte colunas monet√°rias, e mescla.
    4) Salva em um √∫nico CSV final "merged_files.csv" no diret√≥rio de sa√≠da.
    """

    import os
    import pandas as pd
    import csv
    from InquirerPy import inquirer
    from pathlib import Path
    from rich.progress import track
    from rich import print

    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Convers√£o e Mesclagem de Arquivos (Auto Monet√°rias) ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # ---------------------------------------------------------------------------
    # 1) Escolher se quer unir XLSX ou CSV
    # ---------------------------------------------------------------------------
    file_type = inquirer.select(
        message="Selecione o tipo de arquivo para unificar:",
        choices=[
            ("XLSX", ".xlsx"),
            ("CSV", ".csv")
        ]
    ).execute()

    ext_to_unify = file_type  # ".xlsx" ou ".csv"

    # Pergunta o caminho da pasta
    folder_path = inquirer.text(
        message=f"Digite o caminho da pasta que cont√©m os arquivos {ext_to_unify}:"
    ).execute()

    if not os.path.isdir(folder_path):
        print(f"[bold red]‚úó O caminho '{folder_path}' n√£o √© uma pasta v√°lida![/bold red]\n")
        return

    # Lista os arquivos com a extens√£o escolhida
    all_files = [f for f in os.listdir(folder_path) if f.lower().endswith(ext_to_unify)]
    if not all_files:
        print(f"[bold red]‚úó N√£o h√° arquivos {ext_to_unify} na pasta '{folder_path}'![bold red]\n")
        return

    # Pergunta onde salvar o CSV final
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o CSV final unificado:"
    ).execute()

    if not os.path.isdir(output_dir):
        print(f"[bold red]‚úó O caminho '{output_dir}' n√£o √© uma pasta v√°lida![/bold red]\n")
        return

    print("\n[cyan]Detectando colunas monet√°rias com base no primeiro arquivo n√£o-vazio...[/cyan]\n")

    # ---------------------------------------------------------------------------
    # Fun√ß√£o auxiliar para ler CSV com fallback (utf-8 -> latin-1)
    # ---------------------------------------------------------------------------
    def load_csv_fallback(file_path, as_str=False):
        """
        Tenta ler CSV primeiro com sep=';' e encoding='utf-8'.
        Se falhar, tenta sep=';' e encoding='latin-1'.
        Se ainda falhar, tenta sep=',' e encoding='utf-8' e depois latin-1.
        Usa low_memory=False para evitar DtypeWarning.
        Se as_str=True, for√ßa dtype=str.
        """
        import pandas as pd

        dtype_option = str if as_str else None

        # 1) tentamos sep=';' + utf-8
        try:
            try:
                return pd.read_csv(file_path, sep=';', encoding='utf-8',
                                   low_memory=False, dtype=dtype_option)
            except UnicodeDecodeError:
                return pd.read_csv(file_path, sep=';', encoding='latin-1',
                                   low_memory=False, dtype=dtype_option)
        except:
            # 2) se falhar, tentamos sep=',' e repetimos encodings
            try:
                try:
                    return pd.read_csv(file_path, sep=',', encoding='utf-8',
                                       low_memory=False, dtype=dtype_option)
                except UnicodeDecodeError:
                    return pd.read_csv(file_path, sep=',', encoding='latin-1',
                                       low_memory=False, dtype=dtype_option)
            except Exception as e:
                raise e

    # ---------------------------------------------------------------------------
    # Fun√ß√£o para detectar colunas monet√°rias (sem dtype=str)
    # ---------------------------------------------------------------------------
    def detect_monetary_columns_any(file_path):
        """
        Se for XLSX -> l√™ normal (sem dtype=str).
        Se for CSV  -> tenta load_csv_fallback(file_path, as_str=False).
        Retorna: (df_detect, monetary_cols)
          - df_detect: DataFrame carregado (ou None)
          - monetary_cols: lista de colunas consideradas monet√°rias
        """
        import pandas as pd

        if file_path.lower().endswith(".xlsx"):
            # Tenta ler normal (convers√£o autom√°tica de tipos)
            df_temp = pd.read_excel(file_path, engine="openpyxl")
        else:
            # CSV sem dtype=str => Pandas far√° convers√£o de tipos
            df_temp = load_csv_fallback(file_path, as_str=False)

        if df_temp is None or df_temp.empty:
            return None, []

        # Se tiver menos de 2 linhas, usamos index=0
        if len(df_temp) < 2:
            row_idx = 0
        else:
            row_idx = 1

        monetary_cols = []
        for col in df_temp.columns:
            try:
                val = df_temp[col].iloc[row_idx]
            except:
                continue

            # Tenta converter para float
            try:
                float_val = float(val)
                # Se der certo, marcamos como monet√°rio
                monetary_cols.append(col)
            except:
                pass

        return df_temp, monetary_cols

    # ---------------------------------------------------------------------------
    # Detectamos o primeiro arquivo que n√£o esteja vazio
    # ---------------------------------------------------------------------------
    first_file = None
    df_first_detect = None
    monetary_columns = []

    for f in all_files:
        fpath = os.path.join(folder_path, f)
        try:
            tmp_df, tmp_monetary = detect_monetary_columns_any(fpath)
            if tmp_df is not None and not tmp_df.empty:
                first_file = f
                df_first_detect = tmp_df
                monetary_columns = tmp_monetary
                break
        except:
            continue

    if not first_file or df_first_detect is None or df_first_detect.empty:
        print("[bold red]‚úó Todos os arquivos est√£o vazios ou inv√°lidos![bold red]")
        return

    print("[cyan]‚Üí Colunas monet√°rias detectadas (pela 2¬™ linha quando poss√≠vel):[/cyan]")
    for c_ in monetary_columns:
        print(f" - {c_}")

    print("\n[cyan]Convertendo e mesclando arquivos agora...[/cyan]")

    # ---------------------------------------------------------------------------
    # Fun√ß√£o que converte valor monet√°rio: substitui '.' por ',' e envolve em aspas
    # ---------------------------------------------------------------------------
    def convert_to_monetary(value) -> str:
        import pandas as pd
        if pd.isna(value) or value is None:
            return '""'
        val_str = str(value)
        # Troca ponto por v√≠rgula
        val_str = val_str.replace('.', ',')
        # Envolve em aspas
        return f"\"{val_str}\""

    # ---------------------------------------------------------------------------
    # Fun√ß√£o para carregar como string
    # ---------------------------------------------------------------------------
    def load_as_string(file_path):
        """
        Carrega XLSX ou CSV for√ßando tudo como string, com fallback.
        """
        import pandas as pd

        if file_path.lower().endswith(".xlsx"):
            # XLSX com dtype=str
            return pd.read_excel(file_path, engine="openpyxl", dtype=str)
        else:
            # CSV com fallback, as_str=True
            return load_csv_fallback(file_path, as_str=True)

    # ---------------------------------------------------------------------------
    # L√™ o primeiro arquivo como string e aplica convers√£o monet√°ria
    # ---------------------------------------------------------------------------
    first_path = os.path.join(folder_path, first_file)
    df_first_str = load_as_string(first_path)
    if df_first_str.empty:
        print(f"[bold red]‚úó O primeiro arquivo '{first_file}' est√° vazio ap√≥s leitura como string.[bold red]")
        return

    for col in monetary_columns:
        if col in df_first_str.columns:
            df_first_str[col] = df_first_str[col].apply(convert_to_monetary)

    master_df = df_first_str.copy()
    master_columns = master_df.columns.tolist()

    # ---------------------------------------------------------------------------
    # Processar os demais arquivos
    # ---------------------------------------------------------------------------
    remaining_files = [x for x in all_files if x != first_file]

    for f_ in track(remaining_files, description="[cyan]Processando arquivos subsequentes...[/cyan]"):
        fpath = os.path.join(folder_path, f_)
        try:
            df_str = load_as_string(fpath)
        except Exception as e:
            print(f"[bold red]‚úó Erro ao carregar '{f_}': {e}[bold red]")
            continue

        if df_str.empty:
            print(f"[bold yellow]Arquivo '{f_}' est√° vazio. Ignorando...[/bold yellow]")
            continue

        # Aplica convers√£o monet√°ria
        for col in monetary_columns:
            if col in df_str.columns:
                df_str[col] = df_str[col].apply(convert_to_monetary)

        # Reindexa e concatena
        df_str = df_str.reindex(columns=master_columns)
        master_df = pd.concat([master_df, df_str], ignore_index=True)

        # (Opcional) Salva CSV individual
        csv_stem = Path(f_).stem
        csv_path = os.path.join(folder_path, f"{csv_stem}.csv")
        try:
            df_str.to_csv(
                csv_path,
                index=False,
                sep=';',
                encoding='utf-8',
                quoting=csv.QUOTE_NONE,
                escapechar='\\'
            )
        except Exception as e:
            print(f"[bold red]‚úó Erro ao salvar CSV individual '{csv_path}': {e}[bold red]")

    # ---------------------------------------------------------------------------
    # Salva CSV final unificado
    # ---------------------------------------------------------------------------
    if master_df.empty:
        print("\n[bold red]‚úó Nenhum dado v√°lido ap√≥s processar todos os arquivos![bold red]")
        return

    final_csv_name = "merged_files.csv"
    final_csv_path = os.path.join(output_dir, final_csv_name)

    try:
        master_df.to_csv(
            final_csv_path,
            index=False,
            sep=';',
            encoding='utf-8',
            quoting=csv.QUOTE_NONE,
            escapechar='\\'
        )
        print(f"\n[bold green]‚úì Arquivo unificado gerado com sucesso![bold green]")
        print(f"[dim]üìÅ Arquivo salvo em: {final_csv_path}[dim]\n")
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar arquivo unificado: {e}[bold red]\n")



def remove_55_prefix_from_phone_columns():
    """
    1) Recebe caminho de um arquivo (XLSX ou CSV).
    2) Usu√°rio seleciona uma ou mais colunas de telefone.
    3) Para cada coluna, pegamos a primeira linha preenchida como exemplo e perguntamos se √© realmente telefone.
    4) Perguntamos se √© para remover o '55' dos n√∫meros que tiverem 13 d√≠gitos e comecem com '55'.
    5) Faz a formata√ß√£o, removendo o '55' no in√≠cio de cada telefone que atenda √†s condi√ß√µes.
    6) Salva o arquivo final.
    """

    import os
    import pandas as pd
    from InquirerPy import inquirer
    from pathlib import Path
    from rich.progress import track

    print("\n[bold yellow]‚ïî‚ïê‚ïê Iniciando Remo√ß√£o de Prefixo '55' das Colunas de Telefone ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # --------------------- Fun√ß√£o auxiliar de carregamento --------------------- #
    def load_file_generic(file_path):
        """
        Carrega XLSX ou CSV (tentando ; depois ,) e retorna DataFrame com strings.
        """
        if file_path.lower().endswith(".xlsx"):
            return pd.read_excel(file_path, engine="openpyxl", dtype=str)
        elif file_path.lower().endswith(".csv"):
            # Tenta ler com separador ; depois ,
            try:
                return pd.read_csv(file_path, sep=';', dtype=str)
            except:
                return pd.read_csv(file_path, sep=',', dtype=str)
        else:
            raise ValueError("Formato de arquivo n√£o suportado! Use .xlsx ou .csv.")

    # --------------------- Passo 1: Recebe o caminho do arquivo --------------------- #
    file_path = inquirer.text(
        message="Digite o caminho do arquivo (XLSX ou CSV):"
    ).execute()

    if not os.path.isfile(file_path):
        print(f"[bold red]‚úó O caminho '{file_path}' n√£o √© um arquivo v√°lido![bold red]")
        return

    # Carrega o arquivo
    try:
        df = load_file_generic(file_path)
    except Exception as e:
        print(f"[bold red]‚úó Erro ao carregar o arquivo: {e}[bold red]")
        return

    if df.empty:
        print("[bold red]‚úó O arquivo est√° vazio ou n√£o possui dados v√°lidos.[bold red]")
        return

    # Passo 2: Seleciona as colunas de telefone (m√∫ltiplas)
    print("\n[cyan]Selecione as colunas que cont√™m n√∫meros de telefone...[/cyan]\n")
    phone_cols = []
    while True:
        # Exibe as colunas ainda n√£o escolhidas
        remaining_cols = [c for c in df.columns if c not in phone_cols]
        if not remaining_cols:
            break

        want_more = inquirer.confirm(
            message="Deseja selecionar mais uma coluna de telefone?",
            default=True
        ).execute()

        if not want_more and not phone_cols:
            print("[bold red]‚úó √â preciso selecionar ao menos uma coluna para continuar.[bold red]")
            return
        if not want_more:
            break

        chosen_col = inquirer.select(
            message="Selecione a coluna de telefone:",
            choices=remaining_cols
        ).execute()
        phone_cols.append(chosen_col)

    # Se n√£o escolheu nada, encerra
    if not phone_cols:
        return

    # Passo 3: Para cada coluna, pegamos a primeira linha n√£o vazia como exemplo e confirmamos
    for col in phone_cols:
        example_value = None
        for idx, val in df[col].items():
            if pd.notna(val) and val.strip():
                example_value = val.strip()
                break

        # Se n√£o achou nenhum valor
        if not example_value:
            print(f"[bold yellow]A coluna '{col}' n√£o possui valores preenchidos para mostrar exemplo.[bold yellow]")
        else:
            # Pergunta ao usu√°rio se esse valor confere
            print(f"\n[cyan]Exemplo encontrado na coluna '{col}':[/cyan] {example_value}")
            confirm_col = inquirer.confirm(
                message="Confirma que esta coluna √© realmente de telefone?",
                default=True
            ).execute()
            if not confirm_col:
                # Se o usu√°rio negar, podemos remover a coluna da lista
                print(f"[bold red]Removendo coluna '{col}' da lista de telefones.[bold red]")
                phone_cols.remove(col)

    # Se n√£o sobrou nada
    if not phone_cols:
        print("[bold yellow]Nenhuma coluna de telefone confirmada. Encerrando...[bold yellow]")
        return

    # Passo 4: Pergunta se √© para remover '55' (prefixo) dos n√∫meros com 13 d√≠gitos que come√ßam com '55'
    remove_55 = inquirer.confirm(
        message="Deseja remover o '55' (prefixo) dos n√∫meros que tiverem 13 d√≠gitos e iniciarem com '55'?",
        default=True
    ).execute()

    if not remove_55:
        print("[bold yellow]Nada a ser feito, pois o usu√°rio optou por n√£o remover.[bold yellow]")
        return

    # Passo 5: Faz a formata√ß√£o e remove '55' se o tamanho √© 13 e come√ßa com '55'
    def remove_55_prefix(value):
        if pd.isna(value):
            return value
        v = str(value).strip()
        # Se tiver 13 d√≠gitos e come√ßar com '55'
        if len(v) == 13 and v.startswith('55'):
            return v[2:]  # remove os 2 primeiros caracteres
        return v

    # Aplica a formata√ß√£o
    total_rows = len(df)
    changed_count = 0

    for col in phone_cols:
        for idx in track(df.index, description=f"[cyan]Removendo '55' na coluna '{col}'...[/cyan]"):
            old_val = df.at[idx, col]
            new_val = remove_55_prefix(old_val)
            if new_val != old_val:
                df.at[idx, col] = new_val
                changed_count += 1

    print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Formata√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    print(f"[white]‚ñ∫ Colunas de telefone tratadas:[/white] {phone_cols}")
    print(f"[white]‚ñ∫ Total de linhas no arquivo:[/white]     {total_rows:,}")
    print(f"[white]‚ñ∫ Substitui√ß√µes aplicadas:[/white]       {changed_count:,}")

    # Passo 6: Pergunta onde salvar
    output_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo final:"
    ).execute()

    if not os.path.isdir(output_dir):
        print(f"[bold red]‚úó O caminho '{output_dir}' n√£o √© uma pasta v√°lida![bold red]")
        return

    import os
    from pathlib import Path
    base_stem = Path(file_path).stem
    ext = Path(file_path).suffix.lower()

    final_name = f"{base_stem}_remov55{ext}"
    final_path = os.path.join(output_dir, final_name)

    # Salva com o mesmo formato do arquivo original
    try:
        if ext == ".xlsx":
            df.to_excel(final_path, index=False, engine="openpyxl")
        else:
            # sup√µe CSV
            df.to_csv(final_path, index=False, sep=';', encoding='utf-8')
    except Exception as e:
        print(f"[bold red]‚úó Erro ao salvar arquivo final: {e}[/bold red]")
        return

    print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
    print(f"[dim]üìÅ Arquivo final salvo em: {final_path}[dim]\n")

def check_phone_correctness_by_cpf():
    """
    1) Carrega um ARQUIVO BASE (XLSX ou CSV):
       - Seleciona a coluna de CPF
       - Seleciona >=1 colunas de telefone
    2) Carrega um ARQUIVO REFER√äNCIA (XLSX ou CSV):
       - Seleciona a coluna de CPF
       - Seleciona a coluna de telefone
       * O mesmo CPF pode aparecer v√°rias vezes, cada vez com um telefone diferente.
    3) Gera tr√™s arquivos CSV:
       - found_matched.csv:   CPF existe no arquivo 2 e ALGUM telefone do base coincide com um telefone do set do CPF
       - found_mismatch.csv:  CPF existe no arquivo 2, mas NENHUM telefone do base coincide com o set do CPF
       - not_found.csv:       CPF n√£o existe no arquivo 2
    """

    import os
    import pandas as pd
    from pathlib import Path
    from InquirerPy import inquirer
    from rich.console import Console
    console = Console()

    console.print("\n[bold yellow]‚ïî‚ïê‚ïê Confer√™ncia de Telefones por CPF (V√°rias Linhas no Arquivo 2) ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # ---------------------------------------------------------
    # Fun√ß√£o para converter XLSX -> CSV tempor√°rio se necess√°rio
    # ---------------------------------------------------------
    import uuid
    def convert_xlsx_to_csv(xlsx_path, output_dir=None):
        if output_dir is None:
            output_dir = os.path.dirname(xlsx_path)
        df_xlsx = pd.read_excel(xlsx_path, engine="openpyxl", dtype=str)
        temp_name = f"{Path(xlsx_path).stem}_temp_{uuid.uuid4().hex[:6]}.csv"
        temp_path = os.path.join(output_dir, temp_name)
        df_xlsx.to_csv(temp_path, index=False, sep=';', encoding='utf-8')
        return temp_path

    # ---------------------------------------------------------
    # Fun√ß√£o fallback p/ carregar CSV (utf-8 -> latin-1)
    # ---------------------------------------------------------
    def load_csv_fallback(csv_path):
        try:
            try:
                return pd.read_csv(csv_path, sep=';', encoding='utf-8', dtype=str, low_memory=False)
            except UnicodeDecodeError:
                return pd.read_csv(csv_path, sep=';', encoding='latin-1', dtype=str, low_memory=False)
        except:
            try:
                try:
                    return pd.read_csv(csv_path, sep=',', encoding='utf-8', dtype=str, low_memory=False)
                except UnicodeDecodeError:
                    return pd.read_csv(csv_path, sep=',', encoding='latin-1', dtype=str, low_memory=False)
            except Exception as e:
                raise e

    # ---------------------------------------------------------
    # 1) Carrega o ARQUIVO BASE
    # ---------------------------------------------------------
    base_path = inquirer.text(
        message="Digite o caminho do ARQUIVO BASE (XLSX ou CSV):"
    ).execute()

    if not os.path.isfile(base_path):
        console.print(f"[bold red]‚úó O caminho '{base_path}' n√£o √© um arquivo v√°lido![bold red]\n")
        return

    # Converte XLSX -> CSV, se necess√°rio
    if base_path.lower().endswith(".xlsx"):
        console.print("[cyan]Convertendo ARQUIVO BASE de XLSX -> CSV tempor√°rio...[/cyan]")
        try:
            base_csv = convert_xlsx_to_csv(base_path)
        except Exception as e:
            console.print(f"[bold red]‚úó Erro ao converter XLSX para CSV: {e}[bold red]\n")
            return
    elif base_path.lower().endswith(".csv"):
        base_csv = base_path
    else:
        console.print("[bold red]‚úó Formato do arquivo base n√£o suportado (use .xlsx ou .csv)![bold red]")
        return

    # Carrega CSV base com fallback
    try:
        base_df = load_csv_fallback(base_csv)
        if base_df.empty:
            console.print("[bold red]‚úó O arquivo base est√° vazio ou n√£o tem dados v√°lidos.[bold red]\n")
            return
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao carregar CSV base: {e}[bold red]\n")
        return

    # Pergunta a coluna de CPF
    cpf_base_col = inquirer.select(
        message="Selecione a coluna de CPF no arquivo base:",
        choices=base_df.columns.tolist()
    ).execute()

    # Seleciona >=1 colunas de telefone
    phone_cols = []
    while True:
        remaining = [c for c in base_df.columns if c not in phone_cols and c != cpf_base_col]
        if not remaining:
            break

        wants_more = inquirer.confirm(
            message="Deseja selecionar mais uma coluna de telefone no arquivo base?",
            default=True
        ).execute()
        if not wants_more and not phone_cols:
            console.print("[bold red]‚úó √â preciso ao menos uma coluna de telefone![bold red]")
            return
        if not wants_more:
            break

        chosen_phone = inquirer.select(
            message="Selecione a coluna de telefone:",
            choices=remaining
        ).execute()
        phone_cols.append(chosen_phone)

    if not phone_cols:
        console.print("[bold red]‚úó Nenhuma coluna de telefone selecionada. Encerrando...[bold red]")
        return

    # ---------------------------------------------------------
    # 2) Carrega o ARQUIVO 2 (que pode ter v√°rias linhas p/ mesmo CPF)
    # ---------------------------------------------------------
    ref_path = inquirer.text(
        message="Digite o caminho do ARQUIVO 2 (XLSX ou CSV), contendo CPF + TELEFONE (pode repetir o CPF):"
    ).execute()

    if not os.path.isfile(ref_path):
        console.print(f"[bold red]‚úó O caminho '{ref_path}' n√£o √© um arquivo v√°lido![bold red]\n")
        return

    # Converte XLSX -> CSV, se necess√°rio
    if ref_path.lower().endswith(".xlsx"):
        console.print("[cyan]Convertendo ARQUIVO 2 de XLSX -> CSV tempor√°rio...[/cyan]")
        try:
            ref_csv = convert_xlsx_to_csv(ref_path)
        except Exception as e:
            console.print(f"[bold red]‚úó Erro ao converter XLSX para CSV: {e}[bold red]\n")
            return
    elif ref_path.lower().endswith(".csv"):
        ref_csv = ref_path
    else:
        console.print("[bold red]‚úó Formato do arquivo 2 n√£o suportado![bold red]")
        return

    # Carrega CSV ref com fallback
    try:
        ref_df = load_csv_fallback(ref_csv)
        if ref_df.empty:
            console.print("[bold red]‚úó O arquivo 2 est√° vazio ou n√£o tem dados v√°lidos.[bold red]\n")
            return
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao carregar CSV ref: {e}[bold red]\n")
        return

    # Escolhe colunas do ref
    cpf_ref_col = inquirer.select(
        message="Selecione a coluna de CPF no arquivo 2:",
        choices=ref_df.columns.tolist()
    ).execute()

    phone_ref_col = inquirer.select(
        message="Selecione a coluna de TELEFONE no arquivo 2:",
        choices=[c for c in ref_df.columns if c != cpf_ref_col]
    ).execute()

    # ---------------------------------------------------------
    # 3) Monta dict: CPF -> set({todos os telefones testados})
    # ---------------------------------------------------------
    console.print("\n[cyan]Mapeando CPF -> conjunto de telefones no arquivo 2...[/cyan]")
    from collections import defaultdict
    ref_dict = defaultdict(set)

    for _, row in ref_df.iterrows():
        c = str(row[cpf_ref_col]).strip()
        p = str(row[phone_ref_col]).strip()
        if c and p:
            ref_dict[c].add(p)

    console.print(f"[white]Total de CPFs no arquivo 2:[/white] {len(ref_dict):,}")

    # ---------------------------------------------------------
    # 4) Classifica cada linha do base em 3 grupos
    # ---------------------------------------------------------
    console.print("\n[cyan]Verificando correspond√™ncias CPF + telefone...[/cyan]")

    found_matched_rows = []
    found_mismatch_rows = []
    not_found_rows = []

    for index, row in base_df.iterrows():
        base_cpf = str(row[cpf_base_col]).strip()
        if base_cpf not in ref_dict:
            not_found_rows.append(row)
        else:
            # Monta set com todos os phones no base (para essa linha)
            phone_set_base = set()
            for pc in phone_cols:
                val = row[pc]
                if pd.notna(val):
                    phone_set_base.add(val.strip())

            # Intersect com ref_dict[base_cpf]
            if phone_set_base.intersection(ref_dict[base_cpf]):
                # Se houver interse√ß√£o, found_matched
                found_matched_rows.append(row)
            else:
                # found_mismatch
                found_mismatch_rows.append(row)

    console.print(f"[white]Total linhas no base:[/white] {len(base_df):,}")

    console.print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Classifica√ß√£o ‚ïê‚ïê‚ïó[/bold green]")
    console.print(f"[white]‚ñ∫ found_matched  :[/white] {len(found_matched_rows):,}")
    console.print(f"[white]‚ñ∫ found_mismatch :[/white] {len(found_mismatch_rows):,}")
    console.print(f"[white]‚ñ∫ not_found     :[/white] {len(not_found_rows):,}")

    # Converte cada lista de rows para DataFrame
    matched_df = pd.DataFrame(found_matched_rows, columns=base_df.columns)
    mismatch_df = pd.DataFrame(found_mismatch_rows, columns=base_df.columns)
    notfound_df = pd.DataFrame(not_found_rows, columns=base_df.columns)

    # ---------------------------------------------------------
    # 5) Pergunta onde salvar e salva 3 CSVs
    # ---------------------------------------------------------
    out_dir = inquirer.text(
        message="Digite o caminho para salvar os 3 arquivos CSV (found_matched, found_mismatch, not_found):"
    ).execute()

    if not os.path.isdir(out_dir):
        console.print(f"[bold red]‚úó O caminho '{out_dir}' n√£o √© uma pasta v√°lida![bold red]\n")
        return

    base_stem = Path(base_path).stem

    matched_file  = os.path.join(out_dir, f"{base_stem}_found_matched.csv")
    mismatch_file = os.path.join(out_dir, f"{base_stem}_found_mismatch.csv")
    notfound_file = os.path.join(out_dir, f"{base_stem}_not_found.csv")

    console.print("\n[cyan]Salvando arquivos CSV finais...[/cyan]")
    try:
        matched_df.to_csv(matched_file, index=False, sep=';', encoding='utf-8')
        mismatch_df.to_csv(mismatch_file, index=False, sep=';', encoding='utf-8')
        notfound_df.to_csv(notfound_file, index=False, sep=';', encoding='utf-8')
        console.print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        console.print(f"[dim]üìÅ found_matched:   {matched_file}[dim]")
        console.print(f"[dim]üìÅ found_mismatch:  {mismatch_file}[dim]")
        console.print(f"[dim]üìÅ not_found:       {notfound_file}[dim]\n")
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao salvar os arquivos finais: {e}[bold red]\n")

def remove_upag_blacklist():
    """
    Remove (exclui) todas as linhas do ARQUIVO BASE cuja UPAG apare√ßa
    em um ARQUIVO BLACKLIST de UPAGs.

    Fluxo:
    1) Recebe ARQUIVO BASE (XLSX ou CSV):
       - Se for XLSX, converte para CSV tempor√°rio.
       - Carrega CSV com fallback (utf-8 -> latin-1).
       - Usu√°rio seleciona a coluna "UPAG".

    2) Recebe ARQUIVO BLACKLIST (XLSX ou CSV):
       - Se for XLSX, converte para CSV tempor√°rio.
       - Carrega CSV com fallback.
       - Usu√°rio seleciona a coluna "UPAG" tamb√©m.

    3) Gera um CSV final:
       - Remove todas as linhas do BASE que tenham UPAG presente
         no conjunto de UPAGs da blacklist.
    """

    import os
    import pandas as pd
    from InquirerPy import inquirer
    from rich.console import Console
    from pathlib import Path
    import uuid

    console = Console()

    console.print("\n[bold yellow]‚ïî‚ïê‚ïê Remo√ß√£o de UPAGs em Blacklist ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # ---------------------------------------------------------------------------
    # 1) Fun√ß√£o para converter XLSX ‚Üí CSV (tempor√°rio)
    # ---------------------------------------------------------------------------
    def convert_xlsx_to_csv(xlsx_path, output_dir=None):
        if output_dir is None:
            output_dir = os.path.dirname(xlsx_path)
        df_xlsx = pd.read_excel(xlsx_path, engine="openpyxl", dtype=str)
        temp_name = f"{Path(xlsx_path).stem}_temp_{uuid.uuid4().hex[:6]}.csv"
        temp_path = os.path.join(output_dir, temp_name)
        df_xlsx.to_csv(temp_path, index=False, sep=';', encoding='utf-8')
        return temp_path

    # ---------------------------------------------------------------------------
    # 2) Fun√ß√£o de fallback para ler CSV (utf-8 -> latin-1)
    # ---------------------------------------------------------------------------
    def load_csv_fallback(csv_path):
        """
        Tenta ler CSV:
          - sep=';' + utf-8 ‚Üí se falhar, sep=';' + latin-1
          - se falhar, sep=',' + utf-8 ‚Üí se falhar, sep=',' + latin-1
        Retorna df (dtype=str, low_memory=False).
        """
        import pandas as pd
        try:
            try:
                return pd.read_csv(csv_path, sep=';', encoding='utf-8', dtype=str, low_memory=False)
            except UnicodeDecodeError:
                return pd.read_csv(csv_path, sep=';', encoding='latin-1', dtype=str, low_memory=False)
        except:
            try:
                try:
                    return pd.read_csv(csv_path, sep=',', encoding='utf-8', dtype=str, low_memory=False)
                except UnicodeDecodeError:
                    return pd.read_csv(csv_path, sep=',', encoding='latin-1', dtype=str, low_memory=False)
            except Exception as e:
                raise e

    # ---------------------------------------------------------------------------
    # 3) Carrega o ARQUIVO BASE
    # ---------------------------------------------------------------------------
    base_file = inquirer.text(
        message="Digite o caminho do ARQUIVO BASE (XLSX ou CSV):"
    ).execute()

    if not os.path.isfile(base_file):
        console.print(f"[bold red]‚úó O caminho '{base_file}' n√£o √© um arquivo v√°lido![bold red]\n")
        return

    # Se for XLSX, converte
    if base_file.lower().endswith(".xlsx"):
        console.print("[cyan]Convertendo arquivo base de XLSX -> CSV tempor√°rio...[/cyan]")
        try:
            base_csv = convert_xlsx_to_csv(base_file)
        except Exception as e:
            console.print(f"[bold red]‚úó Erro ao converter XLSX para CSV: {e}[bold red]\n")
            return
    elif base_file.lower().endswith(".csv"):
        base_csv = base_file
    else:
        console.print("[bold red]‚úó Formato do arquivo base n√£o suportado (use .xlsx ou .csv)![bold red]")
        return

    # Tenta carregar
    try:
        base_df = load_csv_fallback(base_csv)
        if base_df.empty:
            console.print("[bold red]‚úó O arquivo base est√° vazio ou n√£o cont√©m dados v√°lidos.[bold red]\n")
            return
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao carregar CSV base: {e}[bold red]\n")
        return

    # Usu√°rio seleciona a coluna de UPAG
    upag_base_col = inquirer.select(
        message="Selecione a coluna de UPAG no arquivo base:",
        choices=base_df.columns.tolist()
    ).execute()

    # ---------------------------------------------------------------------------
    # 4) Carrega o ARQUIVO BLACKLIST
    # ---------------------------------------------------------------------------
    blacklist_file = inquirer.text(
        message="Digite o caminho do ARQUIVO BLACKLIST (XLSX ou CSV):"
    ).execute()

    if not os.path.isfile(blacklist_file):
        console.print(f"[bold red]‚úó O caminho '{blacklist_file}' n√£o √© um arquivo v√°lido![bold red]\n")
        return

    if blacklist_file.lower().endswith(".xlsx"):
        console.print("[cyan]Convertendo arquivo blacklist de XLSX -> CSV tempor√°rio...[/cyan]")
        try:
            black_csv = convert_xlsx_to_csv(blacklist_file)
        except Exception as e:
            console.print(f"[bold red]‚úó Erro ao converter XLSX para CSV: {e}[bold red]\n")
            return
    elif blacklist_file.lower().endswith(".csv"):
        black_csv = blacklist_file
    else:
        console.print("[bold red]‚úó Formato do arquivo blacklist n√£o suportado (use .xlsx ou .csv)![bold red]")
        return

    # Tenta carregar blacklist
    try:
        blacklist_df = load_csv_fallback(black_csv)
        if blacklist_df.empty:
            console.print("[bold red]‚úó O arquivo de blacklist est√° vazio ou n√£o cont√©m dados v√°lidos.[bold red]\n")
            return
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao carregar CSV blacklist: {e}[bold red]\n")
        return

    upag_black_col = inquirer.select(
        message="Selecione a coluna de UPAG no arquivo de blacklist:",
        choices=blacklist_df.columns.tolist()
    ).execute()

    # ---------------------------------------------------------------------------
    # 5) Cria um set com as UPAGs da blacklist
    # ---------------------------------------------------------------------------
    console.print("\n[cyan]Criando conjunto de UPAGs da blacklist...[/cyan]")
    black_upags = set()

    for idx, row in blacklist_df.iterrows():
        val = str(row[upag_black_col]).strip()
        if val:
            black_upags.add(val)

    console.print(f"[white]Total de UPAGs na blacklist:[/white] {len(black_upags):,}")

    # ---------------------------------------------------------------------------
    # 6) Filtra o base_df removendo UPAGs que constam na blacklist
    # ---------------------------------------------------------------------------
    console.print("[cyan]Removendo linhas do arquivo base que tenham UPAG na blacklist...[/cyan]")
    initial_count = len(base_df)

    # Marca as linhas que **n√£o** est√£o na blacklist => VALIDO
    base_df["VALIDO"] = ~base_df[upag_base_col].astype(str).str.strip().isin(black_upags)

    valid_df = base_df[base_df["VALIDO"]].drop(columns=["VALIDO"]).copy()
    invalid_df = base_df[~base_df["VALIDO"]].drop(columns=["VALIDO"]).copy()

    linhas_removidas = len(invalid_df)
    linhas_restantes = len(valid_df)

    console.print("\n[bold green]‚ïî‚ïê‚ïê Resumo da Remo√ß√£o por UPAG ‚ïê‚ïê‚ïó[/bold green]")
    console.print(f"[white]‚ñ∫ Total de linhas no arquivo base:[/white] {initial_count:,}")
    console.print(f"[white]‚ñ∫ Linhas removidas (UPAG na blacklist):[/white] {linhas_removidas:,}")
    console.print(f"[white]‚ñ∫ Linhas restantes:[/white] {linhas_restantes:,}")

    # ---------------------------------------------------------------------------
    # 7) Pergunta onde salvar o arquivo final
    # ---------------------------------------------------------------------------
    out_dir = inquirer.text(
        message="Digite o caminho para salvar o arquivo FINAL (CSV):"
    ).execute()

    if not os.path.isdir(out_dir):
        console.print(f"[bold red]‚úó O caminho '{out_dir}' n√£o √© uma pasta v√°lida![bold red]\n")
        return

    # Gera o nome do arquivo final CSV
    base_stem = Path(base_file).stem
    final_name = f"sem_blacklist_upag_{base_stem}.csv"
    final_path = os.path.join(out_dir, final_name)

    console.print("\n[cyan]Salvando arquivo final em CSV...[/cyan]")
    try:
        valid_df.to_csv(final_path, index=False, sep=';', encoding='utf-8')
        console.print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
        console.print(f"[dim]üìÅ Arquivo final salvo em: {final_path}[dim]\n")
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao salvar o arquivo final em CSV: {e}[bold red]\n")

def select_common_columns_and_reduce():
    """
    1) Recebe uma pasta contendo m√∫ltiplos arquivos (XLSX ou CSV).
    2) Para cada arquivo:
       - Se for XLSX, converte para CSV.
       - L√™ como CSV (fallback).
       - Coleta o conjunto de colunas.
    3) Faz a intersec√ß√£o de colunas em todos os arquivos.
    4) Usu√°rio seleciona quais colunas (entre as comuns) deseja manter.
    5) Cria uma subpasta "only_selected_cols" (ou outro nome) para salvar.
    6) Gera CSVs finais de cada arquivo com apenas as colunas selecionadas.
    """

    import os
    import pandas as pd
    from InquirerPy import inquirer
    from pathlib import Path
    import uuid
    from rich.console import Console
    console = Console()

    console.print("\n[bold yellow]‚ïî‚ïê‚ïê Sele√ß√£o de Colunas Comuns em V√°rios Arquivos ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # --------------------- Fun√ß√£o para converter XLSX -> CSV tempor√°rio --------------------- #
    def convert_xlsx_to_csv(xlsx_path, out_dir=None):
        """
        Converte um arquivo XLSX para CSV (sep=';', encoding='utf-8'),
        retorna o caminho do CSV gerado.
        """
        if out_dir is None:
            out_dir = os.path.dirname(xlsx_path)
        df_xlsx = pd.read_excel(xlsx_path, engine="openpyxl", dtype=str)
        temp_name = f"{Path(xlsx_path).stem}_temp_{uuid.uuid4().hex[:6]}.csv"
        temp_path = os.path.join(out_dir, temp_name)
        df_xlsx.to_csv(temp_path, index=False, sep=';', encoding='utf-8')
        return temp_path

    # --------------------- Fun√ß√£o de fallback p/ carregar CSV (utf-8 -> latin-1) --------------------- #
    def load_csv_fallback(csv_path):
        """
        Tenta ler CSV:
          - sep=';' + utf-8 ‚Üí se falhar, sep=';' + latin-1
          - se falhar, sep=',' + utf-8 ‚Üí se falhar, sep=',' + latin-1
        Retorna df com dtype=str, low_memory=False para evitar warnings.
        """
        try:
            try:
                return pd.read_csv(csv_path, sep=';', encoding='utf-8', dtype=str, low_memory=False)
            except UnicodeDecodeError:
                return pd.read_csv(csv_path, sep=';', encoding='latin-1', dtype=str, low_memory=False)
        except:
            try:
                try:
                    return pd.read_csv(csv_path, sep=',', encoding='utf-8', dtype=str, low_memory=False)
                except UnicodeDecodeError:
                    return pd.read_csv(csv_path, sep=',', encoding='latin-1', dtype=str, low_memory=False)
            except Exception as e:
                raise e

    # --------------------- Pergunta a pasta contendo os arquivos --------------------- #
    folder_path = inquirer.text(
        message="Digite o caminho da pasta contendo os arquivos (XLSX ou CSV):"
    ).execute()

    if not os.path.isdir(folder_path):
        console.print(f"[bold red]‚úó O caminho '{folder_path}' n√£o √© uma pasta v√°lida![bold red]\n")
        return

    # Lista todos os arquivos XLSX ou CSV
    all_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.xlsx') or f.lower().endswith('.csv')]
    if not all_files:
        console.print(f"[bold red]‚úó N√£o foram encontrados arquivos XLSX ou CSV em '{folder_path}'![bold red]\n")
        return

    console.print(f"[cyan]‚Üí Encontrados {len(all_files)} arquivos na pasta.[/cyan]\n")

    # Vamos percorrer cada arquivo e convert√™-lo (se XLSX) e carreg√°-lo como CSV
    common_columns = None
    file_csv_map = {}  # Map original_file -> csv_file_path (ap√≥s convers√£o)

    # 1) Converte e encontra colunas
    for idx, fname in enumerate(all_files, 1):
        full_path = os.path.join(folder_path, fname)

        # Verifica se XLSX ou CSV
        if fname.lower().endswith(".xlsx"):
            console.print(f"[cyan]({idx}/{len(all_files)}) Convertendo '{fname}' para CSV tempor√°rio...[/cyan]")
            try:
                csv_path = convert_xlsx_to_csv(full_path)
            except Exception as e:
                console.print(f"[bold red]‚úó Erro ao converter '{fname}': {e}[bold red]")
                continue
        else:
            # √â CSV
            csv_path = full_path

        # Carrega CSV com fallback
        try:
            df_temp = load_csv_fallback(csv_path)
        except Exception as e:
            console.print(f"[bold red]‚úó Erro ao carregar '{fname}' como CSV: {e}[bold red]")
            continue

        if df_temp.empty:
            console.print(f"[bold yellow]Arquivo '{fname}' est√° vazio. Ignorando...[bold yellow]")
            continue

        # Pega as colunas e faz intersec√ß√£o
        cols_set = set(df_temp.columns.tolist())
        if common_columns is None:
            common_columns = cols_set
        else:
            common_columns = common_columns.intersection(cols_set)

        file_csv_map[fname] = csv_path

        console.print(f" - Colunas no arquivo '{fname}': [dim]{len(cols_set)} colunas[/dim]. "
                      f"[dim]Arquivo CSV (temp) em: {csv_path}[/dim]")

    # Se n√£o conseguimos processar nada ou se common_columns for vazio, encerramos
    if not file_csv_map:
        console.print("[bold red]‚úó Nenhum arquivo v√°lido foi processado. Encerrando...[bold red]")
        return

    if not common_columns:
        console.print("[bold red]‚úó N√£o h√° colunas em comum entre os arquivos processados![bold red]")
        return

    console.print(f"\n[cyan]‚Üí Colunas comuns em TODOS os arquivos:[/cyan]")
    for col in sorted(common_columns):
        console.print(f" - {col}")

    # 2) Usu√°rio seleciona colunas a manter (de entre as colunas comuns)
    selected_cols = inquirer.checkbox(
        message="Selecione as colunas que deseja manter (use espa√ßo para marcar):",
        choices=sorted(list(common_columns))
    ).execute()

    if not selected_cols:
        console.print("[bold red]‚úó √â preciso selecionar ao menos uma coluna para manter![bold red]")
        return

    # 3) Criamos uma subpasta para os arquivos de sa√≠da
    subfolder_name = "only_selected_cols"
    output_dir = os.path.join(folder_path, subfolder_name)
    try:
        os.makedirs(output_dir, exist_ok=True)
        console.print(f"\n[cyan]Subpasta para sa√≠da: '{output_dir}'[/cyan]")
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao criar subpasta '{output_dir}': {e}[bold red]")
        return

    # 4) Para cada arquivo, recarregamos seu CSV (fallback) e salvamos com as colunas selecionadas
    from rich.progress import track
    for fname in track(file_csv_map.keys(), description="[cyan]Gerando arquivos finais...[/cyan]"):
        csv_path = file_csv_map[fname]
        try:
            df_csv = load_csv_fallback(csv_path)
        except Exception as e:
            console.print(f"[bold red]‚úó Erro ao recarregar '{fname}' (CSV): {e}[bold red]")
            continue

        # Filtra para manter apenas as colunas selecionadas
        # Observa√ß√£o: se faltarem colunas (caso uma falte), podemos reindexar ou descartar
        missing_in_this_file = [c for c in selected_cols if c not in df_csv.columns]
        if missing_in_this_file:
            console.print(f"[bold yellow]Aviso: No arquivo '{fname}' faltam as colunas: {missing_in_this_file}.[bold yellow]")
        df_csv_reduced = df_csv.reindex(columns=selected_cols, fill_value='')

        # Gera o nome de sa√≠da
        out_name = f"{Path(fname).stem}_reduced.csv"
        out_path = os.path.join(output_dir, out_name)

        try:
            df_csv_reduced.to_csv(out_path, index=False, sep=';', encoding='utf-8')
        except Exception as e:
            console.print(f"[bold red]‚úó Erro ao salvar '{out_name}': {e}[bold red]")
            continue

    console.print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
    console.print(f"[dim]Arquivos finais salvos em: {output_dir}[dim]\n")

def deduplicate_cpfs_across_files():
    """
    Deduplica CPFs em m√∫ltiplos arquivos (XLS[X|B], XLS, ou CSV), removendo duplicatas
    dentro de cada arquivo individualmente primeiro, e depois mantendo o CPF somente
    no arquivo mais recente, removendo-o dos arquivos mais antigos.

    Fluxo:
      1) Usu√°rio seleciona a pasta e a extens√£o dos arquivos (XLSX, XLSB, XLS, CSV).
      2) Lista os arquivos com essa extens√£o.
      3) Garante que todos tenham colunas em comum e obt√©m a interse√ß√£o.
      4) Usu√°rio seleciona a coluna de CPF (entre as colunas comuns).
      5) Cada arquivo passa por remo√ß√£o de duplicatas internas (mant√©m a 1¬™ ocorr√™ncia do CPF).
      6) Usu√°rio define a prioridade dos arquivos (1 = mais recente, maior = mais antigo).
      7) Processamos os arquivos em ordem crescente (do mais recente ao mais antigo), removendo CPFs repetidos.
      8) Os arquivos resultantes s√£o salvos em CSV dentro de uma subpasta `dedup_priority`.
    """

    import os
    import pandas as pd
    from InquirerPy import inquirer
    from pathlib import Path
    import uuid
    from rich.console import Console

    console = Console()

    console.print("\n[bold yellow]‚ïî‚ïê‚ïê Deduplica√ß√£o de CPFs entre m√∫ltiplos arquivos ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # 1) Escolha da pasta e extens√£o dos arquivos
    folder_path = inquirer.text(
        message="Digite o caminho da pasta com os arquivos:"
    ).execute()

    if not os.path.isdir(folder_path):
        console.print(f"[bold red]‚úó O caminho '{folder_path}' n√£o √© uma pasta v√°lida![bold red]\n")
        return

    # Pergunta qual extens√£o ser√° filtrada
    file_ext = inquirer.select(
        message="Selecione a extens√£o dos arquivos para deduplica√ß√£o:",
        choices=[".xlsx", ".xlsb", ".xls", ".csv"]
    ).execute()

    # Lista apenas arquivos dessa extens√£o
    all_files = [f for f in os.listdir(folder_path) if f.lower().endswith(file_ext)]
    if not all_files:
        console.print(f"[bold red]‚úó N√£o h√° arquivos com extens√£o '{file_ext}' na pasta '{folder_path}'![bold red]")
        return

    console.print(f"[cyan]‚Üí Encontrados {len(all_files)} arquivos com extens√£o '{file_ext}'.[/cyan]\n")

    # 2) Fun√ß√µes auxiliares --------------------------------------------------------

    def convert_excel_to_csv(excel_path, out_dir=None):
        """ Converte arquivos Excel (XLS, XLSX, XLSB) para CSV. """
        if out_dir is None:
            out_dir = os.path.dirname(excel_path)
        df_excel = pd.read_excel(excel_path, engine="openpyxl", dtype=str)
        temp_name = f"{Path(excel_path).stem}_temp_{uuid.uuid4().hex[:6]}.csv"
        temp_path = os.path.join(out_dir, temp_name)
        df_excel.to_csv(temp_path, index=False, sep=';', encoding='utf-8')
        return temp_path

    def load_csv_fallback(csv_path):
        """ Tenta carregar CSV, com diferentes delimitadores e encodings. """
        try:
            try:
                return pd.read_csv(csv_path, sep=';', encoding='utf-8', dtype=str, low_memory=False)
            except UnicodeDecodeError:
                return pd.read_csv(csv_path, sep=';', encoding='latin-1', dtype=str, low_memory=False)
        except:
            try:
                try:
                    return pd.read_csv(csv_path, sep=',', encoding='utf-8', dtype=str, low_memory=False)
                except UnicodeDecodeError:
                    return pd.read_csv(csv_path, sep=',', encoding='latin-1', dtype=str, low_memory=False)
            except Exception as e:
                raise e

    # 3) Convers√£o de arquivos Excel e detec√ß√£o de colunas comuns ----------------------

    common_columns = None
    file_csv_map = {}

    for idx, fname in enumerate(all_files, 1):
        original_path = os.path.join(folder_path, fname)
        console.print(f"[cyan]({idx}/{len(all_files)}) Preparando '{fname}'...[/cyan]")

        # Se for CSV, mant√©m; se for Excel, converte
        if file_ext == ".csv":
            csv_path = original_path
        else:
            try:
                csv_path = convert_excel_to_csv(original_path)
            except Exception as e:
                console.print(f"[bold red]‚úó Erro ao converter '{fname}' para CSV: {e}[bold red]")
                continue

        # Carregar para identificar colunas
        try:
            df_temp = load_csv_fallback(csv_path)
        except Exception as e:
            console.print(f"[bold red]‚úó Erro ao carregar CSV '{fname}': {e}[bold red]")
            continue

        if df_temp.empty or df_temp.columns.empty:
            console.print(f"[bold yellow]Aviso: '{fname}' est√° vazio ou sem colunas. Ignorando...[bold yellow]")
            continue

        cols_set = set(df_temp.columns)
        if common_columns is None:
            common_columns = cols_set
        else:
            common_columns = common_columns.intersection(cols_set)

        file_csv_map[fname] = csv_path
        console.print(f" ‚Üí {len(cols_set)} colunas no arquivo.")

    if not file_csv_map:
        console.print("[bold red]‚úó Nenhum arquivo p√¥de ser processado. Encerrando...[bold red]")
        return

    if not common_columns:
        console.print("[bold red]‚úó N√£o h√° colunas em comum entre todos os arquivos![bold red]")
        return

    console.print("\n[cyan]Colunas em comum detectadas:[/cyan]")
    for c_ in sorted(common_columns):
        console.print(f" - {c_}")

    # 4) Usu√°rio seleciona a coluna de CPF
    cpf_col = inquirer.select(
        message="Selecione a coluna de CPF (entre as colunas comuns):",
        choices=sorted(list(common_columns))
    ).execute()

    # 5) Remo√ß√£o de duplicatas dentro de cada arquivo individualmente ----------------
    console.print("\n[cyan]Removendo duplicatas dentro de cada arquivo...[/cyan]")
    
    file_dedup_map = {}
    for fname, csv_path in file_csv_map.items():
        try:
            df_temp = load_csv_fallback(csv_path)
            df_temp = df_temp.drop_duplicates(subset=[cpf_col], keep="first")  # Mant√©m a primeira ocorr√™ncia
            file_dedup_map[fname] = df_temp
        except Exception as e:
            console.print(f"[bold red]‚úó Erro ao remover duplicatas em '{fname}': {e}[bold red]")

    # 6) Usu√°rio define prioridades (1 = mais recente, maior = mais antigo) ----------
    file_list = list(file_dedup_map.keys())
    order_map = {}

    console.print("\n[cyan]Defina a prioridade dos arquivos (1 = mais recente, maior = mais antigo):[/cyan]")
    for fname in file_list:
        order_num = inquirer.text(
            message=f"Prioridade do arquivo '{fname}'? (1=mais recente, maior=mais antigo)"
        ).execute()
        try:
            order_val = int(order_num)
        except:
            order_val = 999999  # fallback
        order_map[fname] = order_val

    file_list_sorted = sorted(file_list, key=lambda x: order_map[x])

    # 7) Removendo CPFs duplicados entre arquivos na ordem definida -------------------
    console.print("\n[cyan]Removendo CPFs repetidos entre arquivos...[/cyan]")
    seen_cpfs = set()
    final_dfs = {}

    for fname in file_list_sorted:
        df_temp = file_dedup_map[fname]
        df_temp = df_temp[~df_temp[cpf_col].astype(str).isin(seen_cpfs)]
        seen_cpfs.update(df_temp[cpf_col].unique())
        final_dfs[fname] = df_temp

    # 8) Salvar arquivos finais na subpasta `dedup_priority` -------------------------
    subfolder_name = "dedup_priority"
    output_dir = os.path.join(folder_path, subfolder_name)
    os.makedirs(output_dir, exist_ok=True)

    for fname in file_list_sorted:
        out_df = final_dfs[fname]
        out_df.to_csv(os.path.join(output_dir, f"{Path(fname).stem}_dedup.csv"), index=False, sep=';', encoding='utf-8')

    console.print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]\n")



def unify_csv_in_chunks_1m_lines():
    """
    1) Recebe uma pasta contendo apenas arquivos CSV.
    2) Descobre a interse√ß√£o de colunas (colunas em comum em todos os arquivos).
    3) Concatena todos os arquivos (apenas as colunas comuns).
    4) Divide em arquivos CSV de at√© 1.000.000 linhas cada.
    5) Salva em uma subpasta 'unified_csv_1m' dentro da pasta original.
    """

    import os
    import pandas as pd
    import csv
    from InquirerPy import inquirer
    from pathlib import Path
    import chardet
    from rich.console import Console
    console = Console()

    console.print("\n[bold yellow]‚ïî‚ïê‚ïê Unificar CSVs em Blocos de 1 Milh√£o de Linhas ‚ïê‚ïê‚ïó[/bold yellow]\n")

    # 1) Recebe a pasta
    folder_path = inquirer.text(
        message="Digite o caminho da pasta contendo APENAS arquivos CSV:"
    ).execute()

    if not os.path.isdir(folder_path):
        console.print(f"[bold red]‚úó O caminho '{folder_path}' n√£o √© uma pasta v√°lida![bold red]\n")
        return

    # Lista os arquivos CSV
    all_files = [f for f in os.listdir(folder_path) if f.lower().endswith(".csv")]
    if not all_files:
        console.print(f"[bold red]‚úó N√£o h√° arquivos CSV na pasta '{folder_path}'![bold red]\n")
        return

    console.print(f"[cyan]‚Üí Encontrados {len(all_files)} arquivos CSV na pasta.[/cyan]\n")

    # ---------------------------------------------------------------------------
    # 2) Descobrir colunas comuns (lendo s√≥ o cabe√ßalho de cada CSV).
    # ---------------------------------------------------------------------------
    def load_csv_header(csv_path):
        """Tenta ler somente o cabe√ßalho (primeira linha) para descobrir colunas."""
        with open(csv_path, "rb") as f:
            raw = f.read(2048)
            enc_guess = chardet.detect(raw)
            encoding_used = enc_guess["encoding"] if enc_guess["confidence"] > 0.5 else "utf-8"

        import csv
        with open(csv_path, "r", encoding=encoding_used, newline='') as f:
            reader = csv.reader(f, delimiter=';')
            header = next(reader, None)
            if not header:  # Tentar delimiter=',' se falhar
                f.seek(0)
                reader = csv.reader(f, delimiter=',')
                header = next(reader, None)
            return header if header else []

    common_columns = None
    for idx, fname in enumerate(all_files, 1):
        csv_path = os.path.join(folder_path, fname)
        console.print(f"[cyan]({idx}/{len(all_files)}) Lendo cabe√ßalho de '{fname}'...[/cyan]")

        header_cols = load_csv_header(csv_path)
        if not header_cols:
            console.print(f"[bold yellow]Arquivo '{fname}' est√° vazio ou sem cabe√ßalho.[/bold yellow]")
            continue

        cols_set = set(header_cols)
        if common_columns is None:
            common_columns = cols_set
        else:
            common_columns = common_columns.intersection(cols_set)

    if not common_columns:
        console.print("[bold red]‚úó N√£o h√° colunas em comum entre todos os arquivos CSV![/bold red]")
        return

    console.print(f"\n[cyan]‚Üí Colunas em comum detectadas: {len(common_columns)}[/cyan]")
    sorted_common_cols = sorted(common_columns)
    for c_ in sorted_common_cols:
        console.print(f" - {c_}")

    # ---------------------------------------------------------------------------
    # 3) Ler todos os arquivos CSV com fallback e concatenar apenas as colunas comuns.
    # ---------------------------------------------------------------------------
    console.print("\n[cyan]Lendo todos os arquivos (apenas colunas comuns) e unificando...[/cyan]")
    all_data = []
    total_lines = 0

    def fallback_read_csv_with_subset(path, usecols):
        """
        Tenta ler CSV com ; ou , e codifica√ß√£o utf-8 ou latin-1, usando apenas as colunas 'usecols'.
        For√ßa dtype=str para tratar tudo como texto.
        """
        # Tenta ; + utf-8
        try:
            try:
                return pd.read_csv(path, sep=';', encoding='utf-8', dtype=str, low_memory=False, usecols=usecols)
            except UnicodeDecodeError:
                return pd.read_csv(path, sep=';', encoding='latin-1', dtype=str, low_memory=False, usecols=usecols)
        except:
            # Tenta , + utf-8
            try:
                try:
                    return pd.read_csv(path, sep=',', encoding='utf-8', dtype=str, low_memory=False, usecols=usecols)
                except UnicodeDecodeError:
                    return pd.read_csv(path, sep=',', encoding='latin-1', dtype=str, low_memory=False, usecols=usecols)
            except Exception as e:
                raise e

    for idx, fname in enumerate(all_files, 1):
        csv_path = os.path.join(folder_path, fname)
        console.print(f"[cyan]({idx}/{len(all_files)}) Unificando '{fname}'...[/cyan]")
        try:
            df_temp = fallback_read_csv_with_subset(csv_path, usecols=sorted_common_cols)
        except Exception as e:
            console.print(f"[bold red]‚úó Erro ao ler '{fname}' (colunas comuns): {e}[/bold red]")
            continue

        lines_now = len(df_temp)
        total_lines += lines_now
        console.print(f" ‚Üí Linhas lidas: {lines_now:,}")

        all_data.append(df_temp)

    if not all_data:
        console.print("[bold red]‚úó Nenhum dado foi carregado. Encerrando...[bold red]")
        return

    df_unified = pd.concat(all_data, ignore_index=True)
    del all_data  # Libera mem√≥ria

    console.print(f"[cyan]DataFrame unificado possui {len(df_unified):,} linhas e {len(df_unified.columns):,} colunas.[/cyan]")

    # ---------------------------------------------------------------------------
    # 4) Dividir df_unified em blocos de 1 milh√£o de linhas e salvar
    # ---------------------------------------------------------------------------
    chunk_size = 1_000_000
    total_rows = len(df_unified)

    subfolder_name = "unified_csv_1m"
    output_dir = os.path.join(folder_path, subfolder_name)
    try:
        os.makedirs(output_dir, exist_ok=True)
        console.print(f"\n[cyan]Subpasta criada/aberta: {output_dir}[/cyan]")
    except Exception as e:
        console.print(f"[bold red]‚úó Erro ao criar subpasta '{output_dir}': {e}[/bold red]")
        return

    num_chunks = (total_rows // chunk_size) + (1 if total_rows % chunk_size else 0)
    console.print(f"[cyan]Gerando {num_chunks} arquivos de at√© {chunk_size:,} linhas cada...[/cyan]\n")

    start_idx = 0
    for chunk_index in range(num_chunks):
        end_idx = start_idx + chunk_size
        df_chunk = df_unified.iloc[start_idx:end_idx].copy()

        chunk_name = f"unified_chunk_{chunk_index + 1}.csv"
        chunk_path = os.path.join(output_dir, chunk_name)

        # QUOTE_NONE -> n√£o coloca aspas em campos
        # Nenhuma c√©lula ser√° envolvida por aspas mesmo que contenha caracteres especiais
        # Substituir escapechar se desejar (evitar perda de dados).
        df_chunk.to_csv(
            chunk_path,
            index=False,
            sep=';',
            encoding='utf-8',
            quoting=csv.QUOTE_NONE,
            escapechar='\\'
        )
        console.print(f"[green]‚úì Salvo: {chunk_path} com {len(df_chunk):,} linhas.[/green]")

        start_idx = end_idx

    console.print(f"\n[bold green]‚úì Processo conclu√≠do com sucesso![bold green]")
    console.print(f"[dim]Arquivos finais em: {output_dir}[dim]\n")




def main():
    while True:
        choice = inquirer.select(
            message="Selecione uma categoria:",
            choices=[
                Choice("1", "Filtros √önicos"),
                Choice("2", "Filtros M√∫ltiplos"),
                Choice("3", "Remo√ß√µes"),
                Choice("4", "Adi√ß√µes/Unifica√ß√µes"),
                Choice("5", "Formata√ß√µes"),
                Choice("6", "Mapeamento de Colunas"),
                Choice("7", "Formata√ß√£o de Datas"),
                Choice("8", "Buscar e Validar CEPs"),
                Choice("9", "Sair")
            ]
        ).execute()

        if choice == "1":
            filtros_unicos()
        elif choice == "2":
            filtros_multiplos()
        elif choice == "3":
            remocoes()
        elif choice == "4":
            adicoes_unificacoes()
        elif choice == "5":
            formatacoes()
        elif choice == "6":
            map_columns_and_merge()
        elif choice == "7":
            formatar_coluna_data()
        elif choice == "8":
            validate_and_format_cep()
        elif choice == "9":
            print("Programa encerrado!")
            break

def filtros_unicos():
    while True:
        choice = inquirer.select(
            message="Selecione um filtro √∫nico:",
            choices=[
                Choice("1", "Filtrar Excel (√∫nico)"),
                Choice("2", "Filtrar valores num√©ricos"),
                Choice("3", "Extra√ß√£o de DDD e N√∫meros"),
                Choice("4", "Filtrar Ag√™ncias"),
                Choice("5", "Validador de Bancos"),
                Choice("6", "Validador Banco, Ag√™ncia e Conta"),
                Choice("7", "Validar N√∫meros de Celular (simples)"),
                Choice("8", "Validar v√°rias colunas de celular (nova fun√ß√£o)"),  # <-- Nova op√ß√£o
                Choice("9", "Voltar")
            ]
        ).execute()

        if choice == "1":
            filter_single_excel()
        elif choice == "2":
            filter_numeric()
        elif choice == "3":
            extract_ddd_and_number()
        elif choice == "4":
            filter_agencies()
        elif choice == "5":
            validador_de_bancos()
        elif choice == "6":
            filter_back_age()
        elif choice == "7":
            validar_numeros_celular()
        elif choice == "8":
            validate_multiple_phone_columns_simple_split()  # <-- Chama a nova fun√ß√£o
        elif choice == "9":
            break



def filtros_multiplos():
    while True:
        choice = inquirer.select(
            message="Selecione um filtro m√∫ltiplo:",
            choices=[
                Choice("1", "Filtrar Excel (m√∫ltiplo)"),
                Choice("2", "Selecionar colunas comuns e reduzir [NOVO]"),
                Choice("3", "Deduplicar CPFs entre arquivos [NOVO]"), 
                Choice("4", "Unificar CSVs em blocos de 1 milh√£o [NOVO]"),  # <-- Nova fun√ß√£o
                Choice("5", "Voltar")
            ]
        ).execute()

        if choice == "1":
            filter_multiple_excel()
        elif choice == "2":
            select_common_columns_and_reduce()  # Fun√ß√£o j√° existente
        elif choice == "3":
            deduplicate_cpfs_across_files()     # Fun√ß√£o j√° existente
        elif choice == "4":
            unify_csv_in_chunks_1m_lines()      # <-- Chamada da nova fun√ß√£o
        elif choice == "5":
            break


def remocoes():
    while True:
        choice = inquirer.select(
            message="Selecione uma remo√ß√£o:",
            choices=[
                Choice("1", "Filtrar CPF - Remo√ß√£o"),
                Choice("2", "Filtrar e remover por nome"),
                Choice("3", "Remover n√∫meros fixos e c√©lulas vazias"),
                Choice("4", "Remover Linhas com C√©lulas Vazias"),
                Choice("5", "Remover N√∫meros (por CPF) da Blacklist [NOVA FUN√á√ÉO]"),
                Choice("6", "Remover CPFs da Blacklist (CPF)"),
                Choice("7", "Remover Duplicatas por CPF"),
                Choice("8", "Aplicar Blacklist de Celulares (CPF)"),
                Choice("9", "Remover Duplicatas por Telefone [NOVO]"),
                Choice("10", "Remover Linhas com UPAG da Blacklist [NOVO]"),  # <-- Nova op√ß√£o
                Choice("11", "Voltar")
            ]
        ).execute()

        if choice == "1":
            filter_cpf_removal()
        elif choice == "2":
            filter_remove_by_name()
        elif choice == "3":
            filter_phone_numbers_csv()
        elif choice == "4":
            delete_rows_with_empty_cells()
        elif choice == "5":
            whitelist_blacklist_removal_num()
        elif choice == "6":
            whitelist_blacklist_removal_cpf()  # remove CPFs da blacklist
        elif choice == "7":
            remover_duplicatas_cpfs()
        elif choice == "8":
            apply_blacklist_phones()
        elif choice == "9":
            remover_duplicatas_phones()
        elif choice == "10":
            remove_upag_blacklist()  # <-- Chamada da nova fun√ß√£o
        elif choice == "11":
            break





def adicoes_unificacoes():
    while True:
        choice = inquirer.select(
            message="Selecione uma adi√ß√£o ou unifica√ß√£o:",
            choices=[
                Choice("1", "Unificar arquivos Excel"),
                Choice("2", "Unificar arquivos Excel com base no CPF"),
                Choice("3", "Adicionar dados de CPFs entre arquivos"),
                Choice("4", "Unificar todas as planilhas em uma pasta"),
                Choice("5", "Unificar colunas DDD e N√∫mero"),
                Choice("6", "Unificar dados (sem duplicar CPFs) [NOVA OP√á√ÉO]"),
                Choice("7", "Mesclar XLSX da pasta em um CSV [NOVA FUN√á√ÉO]"),
                Choice("8", "Voltar")
            ]
        ).execute()

        if choice == "1":
            unify_excel_files()
        elif choice == "2":
            unify_excel_files_with_cpf()
        elif choice == "3":
            dois_unify_excel_files_with_cpf()
        elif choice == "4":
            unifique_one()
        elif choice == "5":
            merge_ddd_number()
        elif choice == "6":
            unify_data_multiple_search_by_cpf_csv()
        elif choice == "7":
            merge_folder_files_to_csv()  # <-- Chamada para a nova fun√ß√£o
        elif choice == "8":
            break

def formatacoes():
    while True:
        choice = inquirer.select(
            message="Selecione uma formata√ß√£o:",
            choices=[
                Choice("1", "Ajustar CPFs para 11 d√≠gitos"),
                Choice("2", "Formatar coluna de valores para padr√£o monet√°rio"),
                Choice("3", "Formatar N√∫meros com Prefixo '55'"),
                Choice("4", "Filtrar e formatar RGs"),
                Choice("5", "Formatar Benef√≠cios"),
                Choice("6", "Validar N√∫mero de Endere√ßo"),
                Choice("7", "Validar Coluna de Sexo"),
                Choice("8", "Formatar Coluna de Ag√™ncia"),
                Choice("9", "Formatar N√∫meros de Celular sem '9'"),
                Choice("10", "Formatar N√∫meros de Celular para 11 D√≠gitos"),
                Choice("11", "Adicionar Coluna de Idade"),
                Choice("12", "Remover prefixo '55' de colunas de telefone"),
                Choice("13", "Verificar Telefone x CPF [novo]"),  # <-- Nova op√ß√£o
                Choice("14", "Voltar")
            ]
        ).execute()

        if choice == "1":
            adjust_cpfs_to_11_digits()
        elif choice == "2":
            format_values_to_money()
        elif choice == "3":
            format_numbers_with_prefix()
        elif choice == "4":
            filter_and_format_rgs()
        elif choice == "5":
            format_benefit_file()
        elif choice == "6":
            validate_address_number()
        elif choice == "7":
            validate_sex_column()
        elif choice == "8":
            format_agency_column()
        elif choice == "9":
            filter_num_nine()
        elif choice == "10":
            formatar_numeros_para_11_digitos()
        elif choice == "11":
            adicionar_coluna_idade()
        elif choice == "12":
            remove_55_prefix_from_phone_columns()
        elif choice == "13":
            # Aqui chamamos a nova fun√ß√£o, por ex.:
            check_phone_correctness_by_cpf()  # <-- Nova chamada
        elif choice == "14":
            break




if __name__ == "__main__":
    main()